{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configs\n",
    "LLM_URL = \"http://localhost:12239/v1\" \n",
    "LLM_AK = \"empty\"\n",
    "LLM_NAME = \"base\"  \n",
    "EMBED_MODEL_PATH = \"../../resources/open_models/bge-large-zh-v1.5\" \n",
    "DATA_PATH = \"../../resources/data/LiHua-World/data/\"  # 数据路径\n",
    "QUERY_PATH = \"../../resources/data/LiHua-World/qa/query_set.csv\"  # 查询路径\n",
    "WORKING_DIR = \"../../resources/data/rag_outputs\" # 工作目录\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:minirag:Logger initialized for working directory: ../../resources/data/rag_outputs\n",
      "INFO:minirag:Load KV llm_response_cache with 20 data\n",
      "INFO:minirag:Load KV full_docs with 5 data\n",
      "INFO:minirag:Load KV text_chunks with 5 data\n",
      "INFO:minirag:Loaded graph from ../../resources/data/rag_outputs/graph_chunk_entity_relation.graphml with 7 nodes, 5 edges\n",
      "INFO:nano-vectordb:Load (5, 1024) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1024, 'metric': 'cosine', 'storage_file': '../../resources/data/rag_outputs/vdb_entities.json'} 5 data\n",
      "INFO:nano-vectordb:Load (5, 1024) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1024, 'metric': 'cosine', 'storage_file': '../../resources/data/rag_outputs/vdb_entities_name.json'} 5 data\n",
      "INFO:nano-vectordb:Load (4, 1024) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1024, 'metric': 'cosine', 'storage_file': '../../resources/data/rag_outputs/vdb_relationships.json'} 4 data\n",
      "INFO:nano-vectordb:Load (5, 1024) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1024, 'metric': 'cosine', 'storage_file': '../../resources/data/rag_outputs/vdb_chunks.json'} 5 data\n"
     ]
    }
   ],
   "source": [
    "## 初始化\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from dataclasses import asdict\n",
    "\n",
    "from tqdm import trange\n",
    "from minirag.prompt import PROMPTS\n",
    "from minirag import MiniRAG, QueryParam\n",
    "from minirag.utils import EmbeddingFunc, list_of_list_to_csv\n",
    "from minirag.llm import openai_complete_if_cache, hf_embedding\n",
    "\n",
    "import sys; sys.path.append(\"../..\")\n",
    "from utils.rag import prompts,retrieval,get_keyword\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import nest_asyncio; nest_asyncio.apply() # 在notebook中使用async所需\n",
    "\n",
    "PROMPTS.update(prompts) \n",
    "\n",
    "# 设置日志级别\n",
    "logging.basicConfig(format=\"%(levelname)s:%(message)s\", level=logging.INFO)\n",
    "\n",
    "embed_tokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL_PATH, model_max_length=512) \n",
    "embed_model = AutoModel.from_pretrained(EMBED_MODEL_PATH)\n",
    "\n",
    "async def llm_model_func(\n",
    "    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs\n",
    ") -> str:\n",
    "    return await openai_complete_if_cache(\n",
    "        model=LLM_NAME, api_key=LLM_AK, base_url=LLM_URL,\n",
    "        prompt=prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "os.makedirs(WORKING_DIR,exist_ok=True)\n",
    "\n",
    "rag = MiniRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=llm_model_func, llm_model_max_token_size=1000, llm_model_name=LLM_NAME,\n",
    "    embedding_func=EmbeddingFunc(\n",
    "        embedding_dim=embed_model.config.hidden_size,\n",
    "        max_token_size=embed_model.config.max_position_embeddings,\n",
    "        func=partial(hf_embedding, embed_model=embed_model, tokenizer=embed_tokenizer)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建索引\n",
    "def find_txt_files(root_path):\n",
    "    txt_files = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                txt_files.append(os.path.join(root, file))\n",
    "    return txt_files\n",
    "\n",
    "WEEK_LIST = find_txt_files(DATA_PATH)\n",
    "for WEEK in WEEK_LIST[:5]:\n",
    "    id = WEEK_LIST.index(WEEK)\n",
    "    print(f\"{id}/{len(WEEK_LIST)}\")\n",
    "    with open(WEEK) as f:\n",
    "        content = f.read()\n",
    "        rag.insert(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:12239/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PERSON'] ['LiHua', 'The Rings of Power'] [['\"THE APARTMENT\"', 0.44848663, '\"The apartment is the specific location that has a broken water tab.\"|>\"specific location, issue location\"'], ['\"LIHUA\"', 0.41985768, '\"LiHua is a person initiating communication about Wi-Fi password and house rules.\"<SEP>\"LiHua is a person who reaches out to AdamSmith for the Wi-Fi password and house rules.\"<SEP>\"LiHua is a traveler who has arrived in the city and is planning a lunch meeting with WolfgangSchulz.\"<SEP>\"LiHua is the person who communicates a problem and thanks Adam for help when they offer to assist.\"<SEP>\"LiHua is trying to communicate a problem with a water tab to Adam Smith, indicating her proactive nature and request for assistance.\"<SEP>\"LiHua is the second person in the text who responds to the appointment confirmation from AdamSmith and makes arrangements to be ready for the plumber.\"<SEP>\"LiHua is an individual checking in with AdamSmith about the move-in timing and confirming a visit date along with time.\"<SEP>\"LiHua is a person who confirms the arrival time with Adam Smith and is ready for the service, and who asks for any further assistance needed.\"<SEP>\"LiHua is a person who confirms the plumber\\'s arrival time with Adam Smith and indicates readiness for the service.\"'], ['\"ADAMSMITH\"', 0.3666009, '\"AdamSmith is a person who communicates with Li Hua to confirm the plumber\\'s arrival time for fixing a water tap.\"<SEP>\"AdamSmith is an individual who replies to LiHua\\'s request for move-in details and shares a visit plan along with welcoming LiHua when they arrive.\"<SEP>\"AdamSmith provides the Wi-Fi password and house rules to LiHua.\"<SEP>\"AdamSmith responds to LiHua\\'s message by arranging for the repair and keeping her updated.\"|>\"responsiveness, communication\"<SEP>\"AdamSmith responds to LiHua\\'s request for help by arranging for repairs, showing his responsiveness and willingness to assist.\"'], ['\"WOLFGANGSCHULZ\"', 0.35257992, '\"WolfgangSchulz is a person who is looking forward to a lunch meeting with LiHua and planning a nice spot to hang out.\"<SEP>\"WolfgangSchulz is a person who is planning a lunch spot for a lunch meeting with LiHua and looking forward to it.\"']] ['chunk-9c8ecadc93d34075b0da1706d7d270a9', 'chunk-d3c725aafc6ec8ccdfa23550e3e8855f'] 根据提供的数据表格，我们无法找到任何关于LiHua和《The Rings of Power》（指亚马逊网络服务公司制作的影视作品《权力的游戏 第一部》）的相关信息。因此，对于LiHua在《The Rings of Power》中可能的行为或预见无法做出准确的回答。\n",
      "\n",
      "数据中包含以下涉及LiHua的条目，这些条目属于沟通情景：\n",
      "\n",
      "- LiHua是试图为水表问题联系AdamSmith，并寻求帮助的问题提出者和反馈者。\n",
      "- LiHua也是试图与AdamSmith确认预约以快速迎接家庭维修的专业人士，并表达对她自行准备充足的服务员的期待。\n",
      "- LiHua还是与AdamSmith确认水表划拨解决后，寻求进一步帮助的人。\n",
      "\n",
      "并未提及《The Rings of Power》或李华在该作品中的角色或表现。因此，不能回答李华为《The Rings of Power》预测或预期会发生什么。\n"
     ]
    }
   ],
   "source": [
    "## example\n",
    "query = \"What does LiHua predict will happen in \\\"The Rings of Power\\\"?\"\n",
    "type_kw,ent_kw = await get_keyword(query,rag.chunk_entity_relation_graph,asdict(rag))\n",
    "ent_recall, chunk_recall = await retrieval(\n",
    "    query,type_kw,ent_kw, \n",
    "    rag.chunk_entity_relation_graph,rag.entity_name_vdb,rag.relationships_vdb,rag.chunks_vdb,\n",
    ")\n",
    "sys_prompt = PROMPTS['sys_prompt_for_rag_answer'].format(\n",
    "        entities_context=list_of_list_to_csv([[\"entity\", \"score\", \"description\"]]+ent_recall), \n",
    "        text_units_context=list_of_list_to_csv([[\"id\", \"content\"]]+chunk_recall)\n",
    "    )\n",
    "response = await llm_model_func(query, system_prompt=sys_prompt)\n",
    "print(type_kw,ent_kw,ent_recall,chunk_recall,response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrivals)"
   ]
  }
 ],
 "metadata": {
  "fileId": "2a9aae82-8ee1-4004-a5a7-13cae40dba29",
  "filePath": "/mlx_devbox/users/jiaxinghua/playground/01_workspace/MiniRAG/RAG.ipynb",
  "kernelspec": {
   "display_name": "finbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
