{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/JXH/01_apps/miniforge3/envs/finbot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------using 8*GPUs----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/JXH/01_apps/miniforge3/envs/finbot/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:37: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 4 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">                                    Benchmark Dataset Version: AIR-Bench_24.</span><span style=\"color: #008080; text-decoration-color: #008080; background-color: #000080; font-weight: bold\">05</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">                                     </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37;44m                                    \u001b[0m\u001b[1;37;44mBenchmark Dataset Version: AIR-Bench_24.\u001b[0m\u001b[1;36;44m05\u001b[0m\u001b[1;37;44m                                     \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">             Task Type: qa | Domain: finance | Language: zh | Dataset Name: default | Splits: [</span><span style=\"color: #008000; text-decoration-color: #008000; background-color: #000080\">'dev'</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; background-color: #000080; font-weight: bold\">]              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37;44m             \u001b[0m\u001b[1;37;44mTask Type: qa | Domain: finance | Language: zh | Dataset Name: default | Splits: \u001b[0m\u001b[1;37;44m[\u001b[0m\u001b[32;44m'dev'\u001b[0m\u001b[1;37;44m]\u001b[0m\u001b[1;37;44m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 978/978 [00:00<00:00, 3.58kB/s]\n",
      "Inference Embeddings: 100%|██████████| 1/1 [00:05<00:00,  5.07s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.30s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.17s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.16s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.28s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.28s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.28s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.19s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.17s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:17<00:00,  3.53s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.38s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.28s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:18<00:00,  3.63s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.28s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.30s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.20s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.32s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.21s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.18s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.23s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.24s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.22s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:15<00:00,  3.17s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.30s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n",
      "Inference Embeddings: 100%|██████████| 5/5 [00:16<00:00,  3.29s/it]\n",
      "Inference Embeddings: 100%|██████████| 3/3 [00:08<00:00,  2.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─────────────────────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Evaluation Summary</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─────────────────────────────────────────────── \u001b[0m\u001b[1;31mEvaluation Summary\u001b[0m\u001b[92m ────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                           Retriever: bge-large-zh-v1.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m                                           \u001b[0m\u001b[37mRetriever: bge-large-zh-v1.\u001b[0m\u001b[1;36m5\u001b[0m\u001b[37m                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                                Search Top K: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m                                                \u001b[0m\u001b[37mSearch Top K: \u001b[0m\u001b[1;36m1000\u001b[0m\u001b[37m                                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                        Output directory: .</span><span style=\"color: #800080; text-decoration-color: #800080\">/results/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">search</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m                                        \u001b[0m\u001b[37mOutput directory: .\u001b[0m\u001b[35m/results/\u001b[0m\u001b[95msearch\u001b[0m\u001b[37m                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 463/463 [00:00<00:00, 1.77kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ./results/eval_dev_results.md\n"
     ]
    }
   ],
   "source": [
    "from mteb.evaluation.evaluators import RetrievalEvaluator\n",
    "from typing import Any, Dict\n",
    "from air_benchmark import AIRBench, Retriever\n",
    "from FlagEmbedding import FlagModel\n",
    "import os\n",
    "\n",
    "## 开启代理以连接huggingface下载数据集\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "\n",
    "class FlagEmbeddingModel:\n",
    "    def __init__(self, model_path: str, **kwargs):\n",
    "        self.model_name = os.path.basename(model_path)\n",
    "        self.model = FlagModel(\n",
    "            model_name_or_path=model_path, \n",
    "            query_instruction_for_retrieval=\"为这个句子生成表示以用于检索相关文章：\",\n",
    "            use_fp16=True\n",
    "        ) \n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.model_name\n",
    "    \n",
    "    def encode_corpus(self, corpus, **kwargs):\n",
    "        input_texts = corpus\n",
    "        if isinstance(corpus[0], dict):\n",
    "            input_texts = [\n",
    "                \"{} {}\".format(doc.get(\"title\", \"\"), doc.get(\"text\", \"\")).strip()\n",
    "                for doc in corpus\n",
    "            ]\n",
    "        return self.encode(input_texts, **kwargs)\n",
    "    \n",
    "    def encode_queries(self, queries, **kwargs):\n",
    "        input_texts = queries\n",
    "        if isinstance(queries[0], dict):\n",
    "            input_texts = [doc.get(\"text\", \"\").strip() for doc in queries]\n",
    "        return self.encode(input_texts, **kwargs)\n",
    "\n",
    "    def encode(self, sentences, **kwargs):\n",
    "        embeddings = self.model.encode(sentences)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class EmbeddingModelRetriever(Retriever):\n",
    "    def __init__(self, embedding_model, search_top_k: int = 1000, **kwargs):\n",
    "        self.embedding_model = embedding_model\n",
    "        super().__init__(search_top_k)\n",
    "        self.retriever = RetrievalEvaluator(\n",
    "            retriever=self.embedding_model,\n",
    "            k_values=[self.search_top_k],\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.embedding_model)\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        corpus: Dict[str, Dict[str, Any]],\n",
    "        queries: Dict[str, str],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        search_results = self.retriever(corpus=corpus, queries=queries)\n",
    "        return search_results\n",
    "\n",
    "\n",
    "embedding_model = FlagEmbeddingModel('../resources/open_models/bge-large-zh-v1.5')\n",
    "\n",
    "evaluation = AIRBench(\n",
    "    benchmark_version=\"AIR-Bench_24.05\",\n",
    "    task_types=[\"qa\"],    # choose a single task for demo purpose\n",
    "    domains=[\"finance\"],           # choose a single domain for demo purpose\n",
    "    languages=[\"zh\"],           # choose a single language for demo purpose\n",
    "    splits=[\"dev\"],            # choose a single split for demo purpose\n",
    "    cache_dir=\"../resources/data/raw\"\n",
    ")\n",
    "\n",
    "retriever = EmbeddingModelRetriever(\n",
    "    embedding_model, \n",
    "    search_top_k=1000,\n",
    "    corpus_chunk_size=10000,  # change to 10_000_000 when encoding the large corpus to avoid multiple tqdm bars\n",
    ")\n",
    "\n",
    "evaluation.run(\n",
    "    retriever,\n",
    "    output_dir='./results/search',\n",
    "    overwrite=True,\n",
    ")\n",
    "    \n",
    "# compute metrics for dev set\n",
    "evaluation.evaluate_dev(\n",
    "    benchmark_version=\"AIR-Bench_24.05\",\n",
    "    search_results_save_dir='./results/search',\n",
    "    output_method=\"markdown\",\n",
    "    output_path='./results/eval_dev_results.md',\n",
    "    metrics=[\"ndcg_at_10\", \"recall_at_10\"],\n",
    "    cache_dir=\"../resources/data/raw\"\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
