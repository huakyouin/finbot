{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 实验输入输出\n",
    "import pandas as pd\n",
    "eval_df = pd.read_json(\"../resources/data/cleaned/Dataset-of-financial-news-sentiment-classification.jsonl\", lines=True)\n",
    "eval_df = eval_df[eval_df['split'] == 'test'].reset_index()\n",
    "pred_path =  \"results/情感提取-qwen2_5_3B-sft.xlsx\"\n",
    "eval_output_path = \"results/情感提取-qwen2_5_3B-sft-eval.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字节跳动成立于2012年。\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "test_model = OpenAI(base_url=\"http://localhost:12234/v1\",api_key=\"empty\")\n",
    "test_model_name = \"lora\" \n",
    "\n",
    "## warm up\n",
    "chat_completion = test_model.chat.completions.create(\n",
    "    model=test_model_name,\n",
    "    temperature=0.1, top_p=0.9, \n",
    "    messages=[{\"role\": \"user\",\"content\": \"字节跳动是什么时候成立的？\"}],\n",
    ")\n",
    "print(chat_completion.choices[0].message.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(pred_path):\n",
    "    print(\"结果文件已经存在，跳过预测。\")\n",
    "else:\n",
    "    print(\"预测...\")\n",
    "    for i, row in eval_df.iterrows():\n",
    "        input_msg = [dict(role=\"system\",content=\"判断以下文本情绪属于积极还是消极。\"),dict(role=\"user\",content=row['text'])]\n",
    "        chat_completion = test_model.chat.completions.create(model=test_model_name,temperature=0.1, top_p=1, messages=input_msg)\n",
    "        pred = chat_completion.choices[0].message.content\n",
    "        eval_df.loc[i,\"prediction\"] = pred\n",
    "        print(f\"{i} pred: {pred}\")\n",
    "    eval_df.to_excel(pred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM评估综述 https://blog.csdn.net/m0_59164304/article/details/142148468\n",
    "# Deep-Eval简介 https://blog.csdn.net/lovechris00/article/details/143783278\n",
    "# Deep-Eval官网 https://docs.confident-ai.com/docs/getting-started\n",
    "import pandas as pd\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric,GEval\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "from deepeval.dataset import EvaluationDataset\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "class LLM(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_url,\n",
    "        model_name,\n",
    "        openai_api_key,\n",
    "    ):\n",
    "        self.model = ChatOpenAI(base_url=base_url,model_name=model_name,openai_api_key=openai_api_key)\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Custom vllm Server Model\"\n",
    "\n",
    "judger = LLM(base_url=\"http://localhost:12235/v1\",model_name='judger',openai_api_key=\"empty\")\n",
    "\n",
    "correctness_metric = GEval(\n",
    "    name=\"Correctness\",\n",
    "    criteria=\"\\\n",
    "    Determine whether the actual output correctly reflects the sentiment (positive or negative) based on the expected output. \\\n",
    "    If the actual output is ambiguous or does not clearly indicate a positive or negative sentiment, it is considered incorrect. \\\n",
    "    Specifically, the output is correct if: (1) it is '1' or a clear positive sentiment expression and the expected output is '1', or (2) it is '0' or a clear negative sentiment expression and the expected output is '0'. \\\n",
    "    Any other output, including ambiguous expressions, is considered incorrect.\\\n",
    "    \",\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n",
    ")\n",
    "\n",
    "pred_df = pd.read_excel(pred_path)\n",
    "testcases=pred_df.apply(lambda row: \n",
    "    LLMTestCase(input=row['instruction']+row['input'],actual_output=row['prediction'],expected_output=row['output']),\n",
    "    axis=1\n",
    ")\n",
    "predset = EvaluationDataset(test_cases=testcases)\n",
    "start_time = time.time()  # 开始计时\n",
    "results = evaluate(predset, [correctness_metric], ignore_errors=True, write_cache=False)\n",
    "end_time = time.time()  # 结束计时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.evaluate import aggregate_metric_pass_rates\n",
    "with open(eval_output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"Execution time: {end_time - start_time:.2f} seconds\\n\")\n",
    "    final_output = aggregate_metric_pass_rates(results.test_results)\n",
    "    f.write(str(final_output)+'\\n')\n",
    "    for test_result in results.test_results:\n",
    "        output = \"=\" * 70 + \"\\n\"\n",
    "        output += f\"Test Case: {test_result.name}\\n\"\n",
    "        output += f\"is success: {test_result.success}\\n\"\n",
    "        output += f\"metrics: {test_result.metrics_data}\\n\\n\"\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 实验输入输出\n",
    "import pandas as pd\n",
    "eval_df = pd.read_json(\"../resources/data/Dataset-of-financial-news-sentiment-classification.jsonl\", lines=True)\n",
    "eval_df = eval_df[eval_df['split'] == 'test'].reset_index()\n",
    "pred_path =  \"results/情感提取-FinBert.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.models import *\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_dir = \"../resources/open_models/FinBert\"\n",
    "ckpt_dir = '../resources/ckpts/finbert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = BaseModel.from_name(\"bert_classifier\")(model_dir,2)\n",
    "model.load(ckpt_dir)\n",
    "\n",
    "if os.path.exists(pred_path):\n",
    "    print(\"结果文件已经存在，跳过预测。\")\n",
    "else:\n",
    "    print(\"预测...\")\n",
    "    seqs = eval_df['text'].to_list()\n",
    "    input_tokens = tokenizer(seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    eval_df['prediction'] = model.pred(input_tokens)\n",
    "    eval_df.to_excel(pred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_df = pd.read_excel(pred_path)\n",
    "match = pred_df['prediction'] == pred_df['label']\n",
    "accuracy = match.mean() * 100\n",
    "print(f\"Acc: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
