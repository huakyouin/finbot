time usage: 22min
{'Correctness (GEval)': 0.3258333333333333}
======================================================================
Test Case: test_case_13
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少来源信息和引言中的具体机构名称，降低了准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中遗漏了乌克兰官员协助俄罗斯的关键信息，这降低了准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_19
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as specific price increases and product types mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_0
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes minor additional details not present in expected output, but does not contradict any facts and maintains relevance.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_30
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少崔莹卸任华安相关基金的信息，以及基金规模等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_9
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中沪指的涨幅略有不同，且缺少创业板指的具体涨幅和其他重要板块的表现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_21
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits details about the inflation rate adjustment and the formal submission process outlined in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_8
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含浙江排名第三的信息，且省略了国家统计局的来源，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_4
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_27
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_24
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '林业碳汇项目' and '战略合作伙伴关系', leading to less accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_11
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于预计发送旅客数量的重要信息，且没有提及春运期间的具体旅客预测数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_12
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于至少20%的人感染新冠病毒的重要细节，仅提到了日均新增病例数。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_15
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于CES展会的信息及其对输入病例的影响，且没有提及病例主要来自美国的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_18
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the percentage reduction and does not mention the specific percentage (19.67%) from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_25
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about restoring confidence in the economy and contradicts the expected output by focusing solely on the investment policy concept.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_23
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只包含了累计确诊病例数，而忽略了新增确诊病例数和新增死亡人数这两个重要细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_10
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits information about planned rescue by New Zealand, Fiji and others, and does not match the brevity and inclusiveness of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_28
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出的主要信息一致，但预期输出更简洁。实际输出未包含来电显示费用存在的背景信息，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_17
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含预期输出中的市场冲击即将发生的暗示，且语言较为简略，未能完全传达预期输出的全部信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_14
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了股票跌幅的信息，但比预期输出多了关于股票跌幅的内容，虽然提供了更多信息，但未完全遵循预期输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_7
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by stating a forecast for rate hikes and balance sheet reduction, while the expected output suggests no change in interest rates.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_5
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但表述略有不同，略显简略，未提及中药股走弱及部分板块的具体表现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_22
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了关于应对气候变化的内容，但忽略了内阁会议的具体讨论内容和其他重要细节，且比预期输出详细，但未完全遵循预期的重点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the dense release of A股年报业绩预告 and the specific investment opportunities in sectors like securities and livestock, which were present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_16
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details such as the strategy's suspicion about the market peak before the Fed's actions and the advice on early-stage investment during the Fed's rate hike cycle.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_29
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了中俄贸易额突破1400亿美元的信息，但遗漏了中国连续12年稳居俄罗斯第一大贸易伙伴国这一关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_6
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the critical information that the pandemic has not ended, and it is vague about the future of the virus, which aligns partially with expected output but lacks crucial details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_20
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了额外的信息，如通胀预期上调和价格涨至40年高位，但主要信息与预期输出不符，且缺乏预期输出中的机构前瞻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_31
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits specific details about the medical team and their tasks but does not contradict any facts in the expected output. The length is concise without being penalized for lack of detail.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_26
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output includes specific details like '56条' which are not present in expected output, but omits the timing and gradual nature mentioned. The length is slightly longer without adding substantial value.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出的内容基本一致，但将'今年'替换为了'2022年'，实际输出没有显著增加额外信息，仅存在细微的时间表述差异。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_36
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了所有重要细节，但语言稍显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_35
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及新增银行的具体名称和数量，且信息量远少于预期输出，缺乏关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_51
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了认购金额和复牌日期的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_33
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output omits important details from the expected output and introduces new information not aligned with the main focus of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_41
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了华润万象生活与招商银行的协议细节及总额230亿元的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_45
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少关键细节，如地理位置和物种具体信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_42
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了预期输出中关于加快油气等资源先进开采技术开发应用的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_40
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含全部重要细节，如恢复运营的公交线路站点，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_34
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但额外增加了具体的投资建议，虽然这增加了信息量，但并未显著偏离预期内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_43
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了总投资的具体数字的强调方式，与预期输出相比，缺少了对总投资3.1万亿的强调。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_55
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific location and the name of the disease, which are important details in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_32
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出遗漏了预期输出中的重要细节，如'不断丰富工具箱'和'适时加强宏观审慎管理和预期引导'，仅提到了部分信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_46
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了IMF的具体预测内容，仅提及了总裁的言论，缺少了预期输出中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_52
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details like the type of sports popular and the price increase, focusing only on the increase in booking volume.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_50
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the detail that it was the '首个综合性' (first comprehensive) policy, reducing accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_39
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提及了美元兑日元的上涨和避险买盘减弱，但遗漏了美国股指期货反弹和市场对美联储利率决策的预期等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_44
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了补助资金的具体金额1931.289万元中的小数点后三位，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_59
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键信息，但比预期输出多了一些描述，虽然没有引入新的事实错误，但是略微冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_62
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于基金规模和全球最大的描述，且未提及这是全球最大的基础设施投资基金。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_56
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中缺少了'业绩快报'这一重要信息，且未明确报告期为2021年。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_53
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了石油泄漏的具体桶数和受影响的海滩数量等重要信息，且没有完全反映秘鲁政府宣布进入环境紧急状态的原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_37
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了对机构的描述，改为更加通用的表达而未明确指出为机构分析，且使用了不同的词汇表达，尽管没有引入事实错误但不完全符合预期输出的要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_57
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中省略了关于瑞幸咖啡需要满足的法规要求及面临的具体障碍等重要细节，且标题未能准确反映新闻的核心观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_47
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及合约的具体月份和期货交易，且称交易员认为是现货市场不匹配，这与预期输出中强调的期货合约到期导致的价格暴涨不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_38
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中虽然指出了多地首套房按揭贷款利率降至4.9%，但遗漏了房贷利率跟随LPR下调这一关键信息，并且没有提到有银行下调上浮基点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_48
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及密接员工核酸检测结果为阴性的重要信息，且未完全反映联想新春活动的细节和要求核酸阴性后返工的要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_63
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the source '证券日报' and incorrectly attributes the statement to '中信证券', which are important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_49
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比略显简略，但未遗漏关键财务数据。实际输出未提及净利润的绝对增长值和原材料价格上升趋势，略逊于预期输出的细节丰富度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_58
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by mentioning a different organization (澳新银行) and a different prediction, instead of reporting on the economic forecast from Deloitte Access Economics as expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_61
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits the fact that it is the first year of operation for the Chongqing-Europe train, and incorrectly implies it refers to a specific year instead of the inaugural year.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_66
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了来源信息，但没有引入事实错误或忽略关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_73
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual Output omits specific contract details and new fees for each commodity, which are present in Expected Output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_64
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含预期输出中的关键信息，如超越日元和成为全球第四大活跃货币，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_69
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output incorrectly includes individuals (杨文蔚、刘琪) not mentioned in expected output, adding unnecessary details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_54
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific information about the cases in Tianjin and other regions as mentioned in the expected output. Additionally, it does not mention the total number of cases being 56, which includes both domestic and foreign cases.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_60
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的时间段不符，实际输出为收盘评论，而预期输出为上午评论。同时，实际输出中板块领涨情况不准确，未提及赛道股卷土重来的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_65
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the expected growth in fixed asset investment and does not mention other economic indicators mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_77
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含更多具体中标信息，但遗漏了总额6.7亿元的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_68
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the specific amount of 68 billion and the implication of the IPO price being too high, which are important details from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_67
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了重要的信息，但比预期输出多了具体工厂名称，且未提及从1到10000辆的跨越时间，遗漏了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_78
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但缺少了'达成'二字，略显简洁。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_72
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了提出法案的具体参议员名称，例如沃伦，以及法案的两党性质。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_83
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the duration of the environmental emergency and the impact on biodiversity and public health.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_82
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='包含额外的新增病例和累计病例信息，但未完全遵循预期输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_70
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by attributing statement to中国汽车工业协会 instead of付炳锋 and omits details about market regulation and continuous relief of chip shortage.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_71
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了更多的信息，但与预期输出的主要信息一致，未出现矛盾。主要差异在于实际输出中包含了发布机构的完整名称，而预期输出则简化了发布机构的表述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_74
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output regarding the net buy/sell amount by institutions and omits details about the net buying by some institutions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_75
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes details not present in expected output, such as the context of the price drop and the reasons behind it, which makes it less aligned with the concise summary expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_87
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有引入额外的信息，符合评估标准。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_85
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the phrase '迈入智能建造世界强国行列', which is an important detail from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_80
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了交易规模，但没有提到交易量翻番或大幅提升的预期目标，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_86
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the word '产能' (capacity), which is present in the expected output, making it less accurate.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_79
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="Actual output contradicts expected output by providing different information and omitting key details such as '防御属性高' and '外资机构频频扫货保险股'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_76
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含了关键信息，但添加了'3月开始'的具体时间，这在预期输出中并未提及，导致输出略显冗长。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_81
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing solely on GDP growth and omitting the optimism about the overall macroeconomic situation and the specific mention of consumer spending回升.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_93
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于债券停牌和交易方式调整的重要信息，且未反映预期输出的完整内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_91
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了一些额外信息，但遗漏了地点细节，如大同市云冈区，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_84
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the name of the investment firm and the specific event involving the futures industry leader, and it does not mention the fund touching the stop-loss line.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_97
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有引入额外不必要内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_88
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中包含了海底火山喷发导致汤加断网的信息，但忽略了电缆被切断这一关键事实，且标题长度略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_90
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出质疑特定数据的真实性，而预期输出要求挖掘数据背后的原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_99
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未提到疫情未终结的关键信息，且省略了政府行动成效及未来警告，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_89
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了有关BA.2亚型毒株传染性是BA.1的1.5倍的重要信息，且未提及BA.2被称为奥密克戎的“姐妹株”。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_92
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少重要的细节，例如电煤库存超过1.62亿吨和同比去年高4000万吨的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_105
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_101
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the type of fund and the total contribution amount, reducing accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_100
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中没有包含具体的13个地区名称，缺少了重要细节；但是没有引入事实错误，长度上也没有冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_107
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出省略了'不守规矩的旅客'这一重要细节，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_103
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the process of recording eye features and the option to include glasses for more accurate recognition.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_95
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits the name of the prime minister and the context of the current quasi-emergency status in 34 prefectures, while it correctly mentions the prime minister's stance on not considering a state of emergency.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_96
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出没有包含预期输出中的关键信息，如'券商首席栽跟头'和'野路子走不得'，并且长度远短于预期输出，未能传达完整信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_98
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the UK 10-year bond yield rising more than 7 basis points and the focus on central bank interest rate policies, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_111
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，也没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_114
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出忽略了通胀担忧和地缘政治风险的具体细节，且未提及关键市场数据和专家意见。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_110
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits important details such as '科学制定并实施入境旅游疫情防控技术指南', which is mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_121
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出提供了净利润同比增长的范围，但未完全匹配预期输出中的具体百分比。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_94
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中中信证券被列为被调查的中介机构，但输入和预期输出中提到的是金杜律师事务所，存在事实性错误；实际输出遗漏了IPO项目被暂停及需要提交复核报告的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_112
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于投资人重新押注和融资政策纠偏的关键信息，且没有提及部分公司有望改善财务状况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_108
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了预期输出中的'2021年净利为2.8亿元-2.9亿元'这一具体数值信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_113
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及《芯片法案》的公布，且具体数额和提升产能的内容虽有体现，但缺乏重要背景信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_106
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the expected price acceleration of lithium compounds exported to Japan and South Korea, and includes additional information not aligned with the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_117
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了具体的两个影响因素，且未提及王萍萍的名字，与预期输出相比信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_102
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出和预期输出的净利润同比增长范围略有差异，但没有引入事实错误。实际输出省略了净利润的具体金额和各板块业务的增长情况，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_109
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '数字新赛道、智能新终端、流量新入口' and '加大前瞻布局' from expected output, significantly reducing the informativeness.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_104
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出存在事实性矛盾，实际输出强调了加密货币价格与宏观资产的正相关性，而预期输出则指出加密货币被普遍接受不一定推高价格。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_119
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中缺少了'史上最强春节档'的描述以及对其他影片的提及，降低了信息的完整性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_118
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的投资金额与预期输出不符，实际输出提到100亿雷亚尔，而预期输出是18.6亿美元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_120
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as 5G key核心技术攻关 and supporting international standards, and introduces more specific information not aligned with expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_122
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits crucial information about the current status of the project and its market phase, focusing only on the number of product categories.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_123
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中省略了净利润的具体范围（2.00亿元-2.20亿元），且表达方式略有差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_129
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了定制细节和顺利交付的信息，且没有体现新闻中的具体数字和背景信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_133
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未包含预期输出中的关键细节，如框架协议的签订和金额上限。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_125
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output omits mentioning the restriction on public activities and the specific date mentioned in the input, focusing only on the closure of certain venues.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_124
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出仅在词语顺序上略有不同，未发现事实性矛盾，也未遗漏重要细节，但预期输出的措辞更符合语境习惯。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_135
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_131
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks key details such as the date, specific agencies involved, and the nature of the meeting, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_116
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出包含了GDP突破110万亿元的信息，但缺少了'总量突破110万亿元'和'开局之年'等关键信息，且表述不够简洁，没有完全按照预期输出的内容进行总结。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_115
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes specific details not present in expected output, leading to an omission of key information such as the location (宁明县) and the status of the核酸检测 results. Additionally, it introduces more information than necessary, making it less concise.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_126
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the negative test results and does not mention the start and end time of the second round of testing.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_127
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了部分预期输出中的细节，如预期输出中的'要加快推动'被简写为'加快推动'，导致信息不完全一致。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_140
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes additional facts not aligned with expected output, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_137
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了预期输出中的项目完成日期和建设单位的信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_130
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了对预期下调的描述，仅陈述了销售净额，并未反映低于预估的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_132
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the stock price change and the comparison to the five-month low mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_138
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中未包含'超21亿元'这一细节，导致准确性略有降低。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_128
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on a different aspect of the news content, missing the key detail about the status of the pandemic peak in many countries.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_139
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了发现53例感染病例的重要信息，且没有提及调查的具体时间和发现的病例数。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_134
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details such as the ongoing effort to promote intellectual property pledge financing and the specific context of the '入园惠企' initiative, which are present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_143
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到已完成自购，且未列出具体的基金名称，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_142
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，忽略了预期输出中关于为所有可能情况做准备的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_136
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits details about the specific model G9 and the official备案 information reference, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_146
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了券商对两融风险整体可控的重要信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_141
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比，仅在措辞上略有不同，但没有遗漏重要信息，也没有引入新的事实或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_145
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了新增确诊病例数和累计确诊超939万例的关键信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_147
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the specific requirement to explain future business development and audit work factors, and does not mention the issuance of a concern letter.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_148
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'浙江'和'富阳区'的具体位置描述，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_144
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contains incorrect information about Apple's stock performance, which is not mentioned in the input, and it also does not match the expected output format or content.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_149
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes additional information not aligned with expected output, omitting key details like '签署谅解备忘录'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_152
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了制定行动计划的重要细节，仅提到了支持浦东无安全员驾驶立法，缺少了制定智能网联汽车终端产业发展行动计划的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_158
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了试剂盒产品的具体名称，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_150
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了Apache Doris 1.0版本发布在即的重要信息，且未提及Apache孵化器的相关内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_154
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific time frame '2021年至今' and model type 'SDA1型' mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_151
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the impact of China's interest rate cut and the expectation of Fed rate hikes, and does not accurately reflect the overall market sentiment and activities described in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_156
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了换电站未营业，这与预期输出中的内容不完全一致，导致信息有遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_166
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes additional details not aligned with expected output, making it less concise and accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_165
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了具体地区的细节，仅提到国家层面，而预期输出包含了具体地区的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_162
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出省略了市场需求供不应求的情况以及募投项目的具体细节，但并未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_164
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了英国BAE公司制造设备的重要信息，且未提及美国国务院批准这一关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_168
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了电池容量和工厂建设等重要细节，且未明确提及电池用途为电动车。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_167
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于比特币价值的重要细节，且未提及被捕原因涉及的比特币金额和价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_153
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了AI能分析乳房X光扫描数据，但缺少了预期输出中关于首个能解释结果的AI乳腺癌诊断系统这一关键信息，且没有反映AI系统的创新性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_159
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the source (生态环境部新闻发言人刘友宾介绍) and specific event details (新冠病毒影响)，leading to less accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_173
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含新闻中关于缓和紧张局势的具体呼吁，缺少了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_157
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like '开年大派“红包”' and '最“大方”', which emphasizes the timing and generous nature of the dividends.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_171
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='忽略了广东和天津的具体本土确诊病例信息，且未提及无症状感染者转为确诊病例的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_155
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中GDP的数值以万亿元为单位进行了四舍五入，这导致与预期输出中的精确数值58887.41亿元有所偏差，但未引入新的错误事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_174
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='缺少了关于连续3年高速增长和行业马太效应加剧的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_179
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the specific cause and affected areas mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_176
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了银行审批放款进度加快这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_172
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少预期输出中的净利增长范围和收入结构调整等重要信息，且增长范围有所偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_161
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含预期输出中提到的'提交宫颈癌适应症上市申请'这一重要细节，但提供了额外的信息，如主要研究终点已达到和公司关联信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_177
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了注册资本金额等细节，但比预期输出更长，且没有显著增加价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_181
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了二期项目总投资62亿元的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_169
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了重要细节，如活动总数69场，仅提到了省级活动数量，没有反映预期输出中的总体活动数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_170
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '稳增长政策的发力见效' and '经济平稳健康发展可期', leading to less accurate representation compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_178
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对油价预测范围的描述，且没有提到瑞银上调油价预测的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_163
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在时间描述上存在差异，实际输出为收盘后评论，而预期输出为午盘评论。此外，实际输出未提及创业板指的表现和大蓝筹的表现，缺少了关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_183
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提到的构建准入标准与预期输出中提到的应用平台有所不同，且缺少了预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_186
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关于德国企业在华信心的重要细节和报告内容，仅提到了外交部的回应。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_160
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的信息不符，实际输出仅强调了2021年表现最差的国家在今年1月表现最好，而预期输出则要求强调全球股市走势逆转，最大赢家和最大输家对调。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_175
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了荷兰发现新型艾滋病病毒毒株这一关键信息，但未提及该毒株的具体名称HIV-1亚型病毒（VB），且未提及与原始病毒相比的发展速度差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_185
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific PMI value and the duration of continuous expansion, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_180
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出准确地包含了新增确诊病例和累计确诊病例数，但用词稍显具体，未使用预期输出中的超1176万例的表述方式。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_187
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details such as the number of remaining封控区和管控区, and is less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_190
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output focuses on consumer接待量 but misses the key information about the growth in火锅套餐销量, which is central to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_184
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output lacks key information like the company name '联创超导' and does not specify the milestone of being the first in the world, as seen in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_192
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含的事实与预期输出中的事实不符，遗漏了累计报告病例数的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_191
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少多人受伤的信息，且未提及警方正在进行的相关行动和建议民众避免前往事发地段的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_182
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by not mentioning the Fed's announcement of tightening policy, instead only referring to investors' expectations of加息. Omitting key details like the explicit Fed announcement reduces accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_189
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the specific claim about Ukraine's president认为美方夸大俄罗斯入侵威胁, focusing only on泽连斯基的不满和疑虑, missing key details from expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_188
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific denial regarding the testing of the air defense system and incorrectly generalizes the statement about military activities.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_204
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了数字货币概念股表现活跃的重要细节，并且对于市场的整体趋势描述不如预期输出准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_196
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks important details such as the initiative to accelerate data element market construction mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_202
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'集团'二字，导致标题不够完整；但是没有引入事实错误，且长度适当。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_199
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了重要细节，如两市超过3600股上涨，整体而言个股呈普涨态势。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_193
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the drug being an oral antiviral and自主研发的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_203
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于交易协议尚未签署的重要信息，且未明确停牌的具体天数和复牌日期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_200
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出提供了更多具体信息，如发车时间、货物详情等，但比预期输出长，略显冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_194
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的新机制与新动能与预期输出中的跨境资本流动助力有所偏差，且缺少了预期输出中关于跨境资本流动的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_206
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了确诊病例的信息，而预期输出只是提到阳性检测结果，实际输出提供了额外未预期的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_195
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the information about the price change of pork compared to the previous day and the price change of eggs, which are important details in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_198
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了赤金香港持有金星资源62%股权以及公司黄金资源量和产量将显著增加的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_208
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the growth of the three major indicators and the specific percentages provided in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_215
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了具体的发电量数字，但忽略了增长率的具体描述及电量的同比增长细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_201
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the specific percentage of doctors affected and the source of the data, but maintains the key information about the number of doctors and the reason for suspension.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_197
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含期望输出中的完整回应内容，如'外交部回应此前华为员工在波兰被捕'，且略显冗长，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_207
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了价格变化的具体数字和原因分析，仅提到价格飙升和最低值，而预期输出中包含了价格具体翻了三倍和‘平民美食’不再平民化的描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_209
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出提到了2021年全国财政收入的具体数额，但与预期输出中关于国新办将举行新闻发布会的预告内容不符，且缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_210
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了与宁德时代董事长曾毓群举行座谈的重要细节，且未提及双方的深入交流内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_217
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits the crucial detail that the loan is specifically for producing electric vehicles.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_205
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the number of stocks that doubled (305) and the specific涨幅 of the top performer (918%). It also lacks the information about the most bearish stock (中公教育跌逾83%).', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_213
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了新闻的关键信息，但详细描述了产品的具体用途和材料，而预期输出则较为简洁。实际输出与预期输出在重要信息上没有冲突，但实际输出略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_220
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了预期输出中关于目标价147美元和市场吸引力的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_218
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出主要描述了玉米期货的上涨，而预期输出则强调了硬红冬小麦期货连续三周下跌。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_230
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了增强欧洲自身实力和捍卫欧洲安全稳定的细节，仅提到了北约的重要性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_214
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the China Tourism Group and contains only partial information regarding the China Shipping Group, leading to a less accurate representation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_212
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the location '广州南沙', the specific number '17条', and the document name '试点措施'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_224
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了促进家政服务业提质扩容的重要信息，且与预期输出在内容上不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_235
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含净利润具体增加的金额范围，仅提到了增长比例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_211
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the specific location '东欧' (Eastern Europe) mentioned in the expected output, and lacks the detail that the price increase is conditional on a conflict in that region.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_226
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了具体的价格调整信息和特定的月份及地区，仅提到了上调MDI价格。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_232
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了净利润的具体范围和煤炭市场需求旺盛的信息，且增长百分比与预期输出略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_234
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_216
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits mention of the '地方两会回应养老关切' and the specific increases in养老金, instead focusing only on the national统筹工作, which does not cover all the important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_223
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了集合竞价一字跌停和年报预损的具体描述，且措辞上与预期输出有所偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_227
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于14天内出现症状时应进行核酸检测的重要信息，且未提及指引的具体措施。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_219
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on '小巨人' enterprises rather than '创新型中小企业', and omits the mention of emerging fields like '元宇宙'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_231
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但添加了不必要的细节，如合作公司和项目地址，这使得输出略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_221
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about Wi-Fi 7 features and the source of the information, and adds an unnecessary prediction of market entry year without corresponding context from the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_237
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中关于鼓励分布式光伏等主体与周边用户直接交易的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_225
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the approval by the Spanish interterritorial health council and the suggestion for maintaining masks in large outdoor events where 1.5 meters distance cannot be guaranteed.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_233
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出省略了净利润的具体增加范围，仅提供了同比增长的百分比。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_239
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了有关未来探索代币化资产结算的重要信息，且未提及测试成功的具体意义。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_238
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, with no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_229
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the name of the WHO official and the high number of new cases recorded, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_236
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出缺少了机构分析的观点，且没有体现预期输出中的'连续三个交易日走低'这一表述，因此在准确性上有所欠缺。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_222
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了净利润同比增加的范围，但缺少了具体的净利润金额（18.5亿元-20.5亿元）和增长的原因（HPV疫苗和新冠业务的增长），因此略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_228
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the detail about the unchanged interest rate and the specific bank names, while the expected output includes more context about the investigation and the consistency of bank loan quotas in Beijing and Shanghai.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_242
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about ongoing cooperation with oil producing and consuming countries, as stated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_240
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='Actual output omits the specific detail of the share quantity and price mentioned in the expected output, but does not contradict any facts.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_241
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了新闻中关于人工智能和区块链的具体应用场景的描述，仅提到了区块链技术在权益链应用中的部分内容，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_244
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了病例为本地个案和连续两天新增病例超300的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_251
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, with no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_245
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output omits critical information regarding the impact of underground pipe network construction on the company's municipal engineering business, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_250
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing the number of new cases instead of the cumulative total cases.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_252
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于疫情防控有序不过度的重要建议，且长度显著短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_243
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了净利润的具体金额范围以及公司在市场地位和营业收入方面的表现，仅保留了净利同比增长的预测，因此略显不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_255
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于马斯克请求的具体内容和特斯拉在印度面临的挑战，且没有提及当前印度的电动汽车进口税率。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_247
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在标题结构和关键信息传递上有较大差异，且实际输出未准确反映预期输出的核心内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_253
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键人物郭树清的信息，且未提及会议的主要目的是研究金融资产管理公司如何聚焦主业。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_259
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及葛兰规模的具体增长情况及成为第三位千亿基金经理的事实，且忽略了赵蓓的相关信息，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_264
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits key details about the fund's focus on digital twin and intelligent simulation sectors, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_265
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits important details and contradicts expected output by not mentioning the official document name and key overall goals.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_254
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about disposing of risks associated with delayed delivery of projects by some top real estate firms, and focuses only on the housing positioning policy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_249
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的收购比例为80%，与预期输出中的100%不符；同时，实际输出中未提及交易对价为9.56亿元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_260
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the precise percentage 767.04% mentioned in expected output, but does not introduce any factual errors or contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_256
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output contradicts the expected output by focusing on a broader commentary rather than providing specific details about the strong RMB exchange rate and its relation to the year-end strong foreign exchange demand.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_267
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对公司利润端受影响的具体原因的描述，且未完全涵盖预期输出的所有要点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_262
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the significant decline in the创业板指and the performance of other key sectors like机场航运and旅游板块, which are mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_261
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the amount of the B round financing and does not mention the 50 billion yuan raised, despite these details being present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_257
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出相比，缺少了对累计确诊病例的简化表达，即'累计确诊超188万例'这一表述，但没有引入其他错误或冗余信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_269
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='忽略了员工会议和扎克伯格鼓励员工的信息，以及股价下跌的具体原因，且描述过于简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_268
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits '联合' which is present in the expected output, leading to a slight loss in accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_263
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output discusses blockchain and Netflix, which are unrelated to the expected output about major indices. There is a clear contradiction between the content of both outputs.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_248
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中目标价被四舍五入为86.3港元，与预期输出中的精确值86.33港元不符，且忽略了评级上调的具体百分比和非利息收入增长的预期上调等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_266
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出提供了准确的感染病例和累计感染病例数字，但将累计感染病例表述为具体数字而非概数，略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_270
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但添加了具体车企名称，这超出了预期输出的简洁要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_271
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了推动中原银行、郑州银行设立银行理财子公司的重要信息，且未提及中原农险等内容，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_274
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了关于布伦特原油价格的信息和美国政府的应对措施，但遗漏了关于拜登面对汽油价格问题的核心主题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_276
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了具体年份2021，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_278
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the purpose of the agreement and the commitment to reduce fiscal deficit, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_258
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出在关键信息上一致，但实际输出添加了'加强在4/8K超高清技术、三维声技术、虚拟技术等相关高新视频业务领域的布局'等信息，这些在预期输出中未提及，导致输出略显冗长。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_246
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了北约向东欧增派军舰和战机的信息，但用词稍显不同。俄方的反应也被提及，但表述为'俄方称'而非'俄指责'，导致用词略显差异。整体上，实际输出未引入明显错误，但语言表达略有出入。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_275
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到王兴将辅助陈亮，与预期输出中的信息相反；且实际输出中缺少陈亮将重心放在组织建设和战略研究的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_282
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含春节后重要时点进行调仓、加仓的具体动作，且缺少光大永明资产负责人的直接引语。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_283
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by focusing on general economic conditions rather than specific measures like commodity supply and price stabilization.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_285
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the details about selling some goods and the importance of team strength, but does not contradict any facts from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_287
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='忽略了布伦特原油和天然气的具体数据，且未提及WTI原油连续第六周上涨的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_272
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了欧洲央行将加息且幅度低于市场预期的关键信息，但与预期输出相比，信息不完全一致，且略显简化，缺少了新闻中提到的加息周期预计不及市场预期的具体幅度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_284
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by not mentioning the use of natural precipitation for artificial snowmaking and does not cover the key concept of 'green Olympics'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_279
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as mentioning the '奔富计划' achievement and the specific target of 3200 billion yuan, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_291
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason="实际输出中缺少关键信息，例如'党委书记'的职位描述和'监察调查'的具体内容。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_292
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中未提及'物流'这一关键细节，导致准确性降低。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_277
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出提到了QDLP试点项目评审会的召开，但省略了会议的详细内容和政策推介活动，与预期输出相比信息不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_290
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出在百分比范围上略有不同，但没有明显的事实性错误或重要细节的遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_280
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key details such as the increase in revenue and net profit, and does not mention the fourth-quarter gain from property compensation. It is also less accurate as it does not reflect the uncertainty mentioned in the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_288
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及未成年人具体的限玩时段和禁玩日期，且没有说明未成年人最多可玩游戏的时间，导致重要信息缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_293
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits key phrases such as '坚决查 彻底改', leading to less accurate representation of the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_289
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the detail that the company is a参股公司 (participating company), which is mentioned in the expected output. No contradictions are found.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_294
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了国务院副总理胡春华的督导信息，但缺少了督导的具体地点山东寿光。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_286
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as further guidance for local development alignment with RCEP and enhancing the China Free Trade Zone service website, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_295
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及商户数量，未反映数字人民币生态体系初步建立的重要信息，且与预期输出的描述有偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_301
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by not mentioning the significant growth in smart home appliance consumption and instead only restating the report title.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_273
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on Bitcoin's response to the Fed's interest rate expectations, rather than the overall market risk preference boost mentioned in the expected output. It also omits the detail that Bitcoin surpassed $40,000 as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_299
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了孙天琦的具体职位以及对问题银行的描述，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_297
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了华为分红总额350亿元的重要信息，且未提及超过12万员工受益的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_303
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中关于2026年全球市场占有率目标的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_296
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the start date (2月7日起) and does not match the exact wording of expected output, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_281
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出中的增长率范围略有简化，从117.79%-182.54%简化为118%-183%，这导致了一些细节上的缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_304
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on market vitality rather than the specific improvement in funds utilization efficiency.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_302
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the meeting's purpose and the companies involved, focusing only on the potential outcome of the meeting.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_308
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅在用词上略有不同，未引入事实错误或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_305
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少'房地产'一词，导致调控政策的来源不够明确，但未引入新的矛盾或冗余信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_298
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about the specific impact on the California hospital system and the mention of the Omicron variant's spread across the US, as seen in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_300
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了对疫苗加强免疫接种和疫苗研发攻关的强调，且与预期输出相比，缺少了对闭环管理措施的明确表述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_307
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the official verification and lacks the '官方：消息不实' part from expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_309
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于乌克兰准备发动袭击的重要信息，仅提到了乌克兰在顿巴斯地区的部队集结。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_313
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='The actual output matches the expected output exactly, with no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_315
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了同比增长8%的重要信息，且没有完全遵循预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_318
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了预期输出的所有关键信息，但增加了'积极的'一词，略显冗长。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_306
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="Actual output omits specific details like the company name '北京朝酿暮饮商贸有限公司' and the法定代表人 '杨伟峰',注册资本 '100万人民币'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_311
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提到调整前置仓，但未提及预期输出中的“暂缓”和“关停”，且信息不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_312
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含的信息与预期输出不符，且遗漏了预期输出中关于部分国家刺激政策退出可能引发需求萎缩的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_314
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes more details than expected output, but does not contradict any facts. However, it is slightly longer without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_310
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出存在事实性矛盾，实际输出强调了液化石油气的价格上涨，而预期输出关注的是生猪价格的下降。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_320
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits future plans mentioned in the input, such as the company's intention to adjust prices based on various factors in the future.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_317
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific information about William's statement and does not mention his exact words, leading to less accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_322
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits details about strictly controlling secondary market investment scale as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_325
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output includes Marko Kolanovic's title, while expected output does not. However, actual output is slightly more detailed than required.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_316
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了密接和次密接人员的具体数字，而这些信息在预期输出中是关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_327
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了劳斯莱斯销量创新高的事实，但遗漏了具体销售数字和分析疫情下奢侈品热销的原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_333
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出在内容上基本一致，仅词语顺序有所不同，没有引入新的事实或细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_338
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了有关七层复合加热膜的重要信息，且未提到这是新一代产品。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_330
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的主题不符，实际输出侧重于业内人士的观点，而预期输出侧重于资金的流入情况和公募REITs的表现活跃。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_324
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in terms of the trend of dollar movement and lacks the phrase indicating the end of a decline, introducing factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_336
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了返程航线直飞机票涨价的重要信息，且未提及热门景区和航线折扣的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_331
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details from expected output and introduces specific information not aligned with the expected summary style.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_332
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the key point about the loss of 20 million dollars and does not mention the reasons provided by IMF, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_321
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及马斯克的抱怨，遗漏了重要细节；并且没有具体说明这是在马斯克抱怨后拜登首次的认可，不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_323
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键信息，但与预期输出在表述上有所偏差。实际输出强调了三孩政策的实施时间短，而预期输出强调了生育配套支持政策的效果显现困难。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_335
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了金刚线产品价格还未企稳这一重要细节，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_329
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键事实，但省略了资金来源的详细信息和"宣布"一词，略显简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_319
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了净利润下降的具体百分比29.09%-37.33%，仅描述为29%-37%，减少了细节准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_334
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing solely on the European Central Bank's potential rate hike, while the expected output requires a broader perspective including the Federal Reserve and a trend of central banks tightening policies.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_340
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the average discount and the involvement of institutional investors as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_337
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits mentioning that it is '一机构' that buys 2.38 billion yuan, aligning less with expected output details.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_326
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output in mentioning '道明证券' and specific percentage increases, and omits key details such as the specific warning from '道明证券' about low effective spare capacity of OPEC and the impact of Russia-Ukraine and Middle East tensions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_328
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits specific examples of '硬科技' companies and their activities, focusing only on the number of companies issuing financial forecasts, while expected output highlights the overall positive performance and busy start of科创板 companies.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_339
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键信息，但是略去了具体的药品名称和来源网站的时间细节，且比预期输出略长但未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_348
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有引入任何矛盾或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_344
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了董事局主席许家印的名字和公司根据实际情况精简机构的具体意图，略去了部分重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_345
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the fact that 6 people were injured and does not mention the organization's willingness to aid in the peaceful resolution of the conflict.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_341
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing on a different aspect of the speech rather than the specified key points about energy production and coal supply.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_353
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output as it focuses on future growth instead of reporting past sales figures.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_351
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少重要细节，如新增确诊病例数和新措施对抗奥密克戎的具体内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_349
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by stating that stocks will digest rising bond yields, while expected output highlights the higher risk of growth being pressured.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_342
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了预期输出中未提及的额外信息，但忽略了预期输出中强调的中西部和东北地区承接产业转移能力提升的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_361
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the cumulative confirmed cases detail mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_359
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了导致评级下调的具体原因，即比特币带来的风险。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_343
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extra information about different transportation modes and national highway traffic flow, which are not present in the expected output. It also lacks the date mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_355
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有包含深成指跌逾2%的信息，且与预期输出相比缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_352
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output contradicts expected output regarding the number of stocks that opened higher, and omits details about the specific涨幅of major indices.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_358
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了提醒的措辞，而且没有使用今日一词，导致信息不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_354
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the purpose of the plan to narrow the wealth gap and focuses only on improvements in services, contradicting the expected output's emphasis.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_350
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提到了接收船只的具体日期和船只名称，但并未提及这是新造船只的交付，且比预期输出详细了许多不必要的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_362
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有提供关于尽快恢复审查的信息，且语言较为简略，缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_360
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有引入额外无价值的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_356
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中的关键信息，如‘网红’景区和发展的概念，且重点在于服务提升。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_363
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键能量输出数值59兆焦，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_346
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like the term '实地探访', '已开始供货', and the strategic context between battery and vehicle companies. The output is also shorter but lacks important information from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_371
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, no contradictions or omitted important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_366
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output omits key details like the source '外媒' and the meeting with泽连斯基, reducing its accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_347
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出中增长百分比为644.28%至778.39%，而预期输出为644%至778%，具体数值存在差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_374
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key sales figures and growth percentage from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_369
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the financial measures and negotiations mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_365
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the predicted capital market size and contradicts the expected output by not providing the specific financial forecast.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_368
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了探索中小银行设立理财公司的模式路径这一重要信息，且未能提及曹宇的具体言论。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_367
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，只是将'应'字省略，导致语气略有不同，但未引入事实错误或重要细节遗漏。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_357
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="Actual output contains factual errors as it includes '恒生科技指数涨0.8%' which is not mentioned in expected output and omits '港股恒指' part.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_372
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output lacks the context that this is a recurring event, as mentioned in '再次' in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_373
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及元宇宙写入政府工作报告这一核心事实，且内容与预期输出不符，缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_375
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="Actual output omits '国务院国资委' and the year '2021', which are important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_379
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits details about the volcano eruption impacts and expert confirmation in expected output, but does not introduce factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_364
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output regarding the stock price increase; actual output states a peak of 24%, while expected output mentions an increase of 14%. Actual output also omits the final stock price increase information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_377
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by not mentioning the total confirmed cases or the type of virus, and omits critical details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_383
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了恒生科技指数和汽车股涨幅的信息，且未提及恒生科技指数涨幅超过3%这一关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_382
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key financial details about net profit increase and includes unrelated information about兴业矿业, which is less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_385
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the political stance and primary goal of investor protection mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_381
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了缔结协议的事实，但增加了投资金额的细节，而预期输出中没有提及这些细节。实际输出比预期输出更长，但没有显著增加价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_388
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the crucial detail of the 25.71% increase in注册资本, which was included in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_380
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by mentioning incorrect company (安徽安科生物) and missing key details about子公司生长激素产品纳入广东集采文件.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_391
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少持有期不少于1年的细节，且没有明确表示这是公司的宣布，略显不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_376
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出在内容上一致，只是使用了不同的词汇（运输 vs. 运送），没有引入事实错误或遗漏重要细节，仅扣1分是因为语言上的细微差别。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_387
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中的具体报价522.1元/吨，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_395
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about expected net profit range and the reasons for growth mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_384
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键信息，但比预期输出多了“河北”二字和具体数值及增长情况，虽然信息量稍大，但没有引入错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_370
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on the wrong aspect (yield curve steepening) instead of the overall decline in US Treasury prices, and omits critical details about the extent of the decline and the specific impact of European and British treasury movements.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_389
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了净利润的增长率，但缺少了具体的净利润范围。预期输出更简洁，直接表达了净利润同比增长的幅度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_393
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by providing details not aligned with the expected summary, which focuses on support for traditional Chinese medicine and brand building.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_394
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key information such as the dynamic adjustment mechanism and the principle of tilting towards western regions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_392
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及液化石油气和不锈钢的具体跌幅，而预期输出中有明确提及这两者的跌幅超过4%，缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_396
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output includes unnecessary details from the input beyond the expected output, which introduces extraneous facts not aligned with the expected concise summary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_400
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了地点哥德堡和工厂规模50GWh的重要信息，且未提及投产时间。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_406
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits important details about the areas of exploration for cooperation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_386
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的主要事实，但是将累计确诊数具体为2361702例，而预期输出则为更简洁的236万例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_403
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但加入了国家属性的描述，稍微冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_390
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on the phase achievements instead of emphasizing the need to promptly extinguish cluster outbreaks. Additionally, it omits key details about deepening implementation of control measures.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_397
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出缺少预期输出中的关键细节，例如'不足一个月'和'公募开年迎清盘小高峰'。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_405
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了预期输出的所有关键信息，但多了一个字'到'，没有引入事实错误，也没有显著增加长度。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_399
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了有关收购保尔利德股权作为《酿酒大师》海外发行主体支撑的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_398
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits crucial details about the ranking of the top three apps and does not mention TikTok, Instagram, or Facebook, which are important details from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_402
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the formation of a dedicated institution led by the president mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_378
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中提到的关键词包括'消费'、'新能源'、'地产'等，而预期输出主要关注'消费'和'新能源'，实际输出包含了一些预期输出中未提及的内容，导致信息不完全一致且冗余。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_401
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了关键信息，但未使用'今日起'这个时间表述，略显不准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_410
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提到降幅超出预期，且时间范围不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_407
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'天津市'这一地点信息，导致与预期输出不完全一致。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_404
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output includes more specific details than expected output but does not contradict any facts. It specifies the location of the subsidiary, the planned capacity, and the total investment, which are not present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_415
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details about emergency state and immediate response to incidents as outlined in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_413
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预增公司数量的具体数字，且未完全反映预期输出中的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_412
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了抢占虎年主题和基金发行市场的热闹景象等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_409
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the impact of the autumn flood and the specific measures planned to ensure a successful harvest as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_414
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了利润总额的增速，忽略了收入增速和整体增速企稳的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_417
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the IPO plan and the timeframe mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_408
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了QDII基金规模增长的具体数值和原油类QDII表现突出的信息，但忽略了预期输出中提到的多方位捕捉海外投资机遇的内容，且信息相对简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_416
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了关于2022年快递市场平稳开局的重要信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_422
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="缺少'上海市'导致信息不完整，但未引入其他错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_419
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了具体地点名称，但缺少了省份和城市名称，且没有提到时间等重要信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_421
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了回购总金额超过1200亿元的重要信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_411
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the mention of '债务重组' and '违规保壳' from the expected output, and does not highlight the expert's viewpoint.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_425
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the amount of the acquisition (3 billion yuan) and the fact that it is a planned acquisition.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_424
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了日里诺夫斯基入院的信息，而预期输出中提到了这一点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_418
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含了关键信息，但使用了'东京电力公司'而非'福岛第一核电站'，且略去了发现沉积物的具体时间等细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_432
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key points about market sentiments towards low valuation and high growth sectors, and does not mention market professionals' views.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_429
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了贵州电网有限责任公司的具体信息，且未明确指出唐斯庆的职位为原党组书记、董事长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_433
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'传票'这一关键信息，但没有引入事实错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_426
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了比特币价格腰斩的重要信息，且没有明确指出3万美元作为下一个支撑位。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_439
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, with no contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_423
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by omitting critical details such as overall energy supply stability and the emphasis on ensuring the baseline of civil energy usage.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_430
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中的关键细节，如最高日检测量和检测时间，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_428
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output does not match the expected output, as it focuses on data management and consumer protection instead of platform enterprise mergers and preventing '掐尖式并购'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_427
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出未包含预期输出中的'绩优股也遭减持'这一重要信息，且表达不如预期输出详细。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_435
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出基本一致，仅在表述上略有不同，没有矛盾或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_431
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details like the ranking of top three companies in terms of new value and the context of the top 100 real estate companies, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_437
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了印尼限制棕榈油出口和国内库存创5年低点的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_436
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the Fed officials' stance on interest rates and their specific plans, focusing only on a part of the expected output which discusses the officials' desire for stability.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_449
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as specific product names and overseas plans mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_442
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="Actual output omits the '中国（三亚）' part which is present in the expected output, making it less accurate.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_420
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了天能股份提供新能源电池的信息，但包含了更多细节，如电池的具体型号和材料体系，而预期输出只强调了天能股份电池助力冬奥会。实际输出的信息更具体，但超出了预期输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_440
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the specific acquisition percentage, the continued independent operation of 艾瑞咨询, and the support provided by 亚信科技.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_448
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the source '中上协' and the specific year mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_443
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes additional details about the performance of specific stocks, but omits the performance of the technology and coal sectors mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_434
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by stating '业务和运营一切正常' which does not address the key point about not being on the UVL list and the expectation of not being added in the future.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_460
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_441
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了会谈的部分内容，但忽略了预期输出中的关键细节，如支持彼此维护主权、安全和发展利益以及有效应对威胁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_444
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the specific name of the subsidiary '海顺印业' and the service details, making it less accurate than expected.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_450
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提及转向其他更盈利的疫苗，且未明确指出是美媒报道，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_438
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by omitting key details about the '令人震骇' approach and the context of high inflation, focusing solely on the shift in opinion by Nomura.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_453
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中省略了合同的具体内容和项目名称，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_447
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the vote count and the specific mention of the bill's final passage in the French parliament.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_446
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits details about creating a software and hardware 'ecological chain' and the timing of the development, reducing accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_445
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about low-risk area返乡人员的规定，并且主要描述了中高风险地区返乡人员的管理措施，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_457
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific year 2025 mentioned in the expected output, leading to less accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_454
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by providing unnecessary details and omitting key phrases like '依法查处'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_455
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='Actual output omits the completion date and the status of the acquisition condition being either fulfilled or waived, making it less accurate than expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_452
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了更多的细节，但这些细节并未在预期输出中提及，且实际输出比预期输出更长，不符合预期的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_466
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了进入亚洲杯决赛的具体信息，且没有提到时隔14年的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_459
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出内容基本一致，但顺序略有不同，实际输出没有包含预期输出中的'与智度股份拟'这一细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_456
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少重要细节，如具体整合的产品列表，且表述上不够全面，仅提及整合小微相关产品而非全面整合。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_463
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，未发现任何事实上的矛盾，也未遗漏重要细节，长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_458
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了本土病例的具体数量和12例源头不明的信息，同时实际输出中的数据与预期输出不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_467
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了新增装机规模的具体数字，但缺少了风电和光伏发电的具体增量数据以及其他关键发展情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_462
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出虽然提到了确诊病例的总数和本土病例数，但缺少了‘国家卫健委’的来源信息，且与预期输出中的表达方式不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_465
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中省略了'促消费扩投资'和'加固经济基本盘'等重要信息，导致内容不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_468
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了收入降至最低水平的关键信息，且没有完全反映预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_475
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了日期信息，导致与预期输出相比不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_472
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了具体的放松措施开始日期，但未引入事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_476
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing specific GDP growth data instead of a press conference announcement preview.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_474
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'投资'一词，但未引入事实错误或明显遗漏重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_479
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关于疫情扩散风险的关键信息，且未提及国家卫健委的来源。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_470
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未能突出意大利和西班牙国债收益率的显著上涨，且忽略了本周具体涨跌情况的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_461
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about specific index levels and fails to mention the need to value the market at 2800 points for the Growth Enterprise Market and 3400 points for the Shanghai Composite Index.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_481
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the new cases and deaths information provided in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_464
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts the expected output by stating a 'decline' instead of a 'slight decline', and omits key details like the percentage change and the comparison to the previous year.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_469
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual Output contradicts Expected Output by focusing on different aspects of the news, omitting key details such as the wind power capacity and its global ranking.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_487
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual Output matches Expected Output exactly, without any contradictions or omitted important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_471
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了对中国上市公司协会倡议具体内容的描述，也未提及倡议的目的和对资本市场的积极影响，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_473
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出遗漏了'四个首次'的关键信息，仅提到了卫星投入使用，而未提及卫星实现的技术突破和创新。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_486
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, with no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_480
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，实际输出强调了产业链合作共建回收渠道，而预期输出强调废旧动力电池在特定领域的安全梯次应用。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_484
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于中融信托多个到期项目的具体信息，且未明确提及是针对多个到期项目进行的债务重组谈判。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_482
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出提供了净利润和同比增长的数据，但缺少新闻的具体类型（如业绩快报），并且没有提及业务增长的细节，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_478
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关键内容，如国家发展改革委的具体表述和对经济前景的信心表达，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_490
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the crucial date and timing information from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_498
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了具体年份，但没有引入事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_477
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific number of companies and the fact that it is a main channel for risk clearance, leading to less accurate representation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_497
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于拜登执政一年的重要信息，且未提及封面的隐含意义。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_485
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by changing the source and tone, omitting the mention of 'MNI' and overgeneralizing the content.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_451
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific type of clinical trial (I期临床试验STAMINA), the significance of ATG-037 being the first oral CD73 inhibitor in China and Asia-Pacific, and the context of it being the first workday of the Year of the Tiger. Additionally, the output is too vague and lacks essential information from the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_492
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出中提到的员工离职信息与预期输出内容不符，且未提及任正非对未来的乐观展望。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_493
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中缺少与去年同比增长16%的重要细节，但没有出现事实矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_488
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及预期输出中的关键信息，如第二次申请公积金贷款的首付比例降至40%，且实际输出过于简略，缺乏具体细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_483
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到股市波动和买入机会，但未提及标准普尔500指数不会带来巨大回报的重要信息，且缺少来源和专家意见，与预期输出有较大出入。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_491
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the market being in a 'cooling-off period' and the expected回暖after the Spring Festival, while also introducing vague language without substantial value.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_503
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了新增死亡病例和累计死亡病例的信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_489
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了波罗的海干散货指数的具体涨幅，但预期输出仅指出了一年内单日最大涨幅，因此实际输出包含了额外的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_495
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the analysts' name and specific actions related to inflation concerns and market reactions in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_501
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by adding unnecessary details about Apple's performance, which were not present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_494
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及被点名的保险公司数量，且未明确指出存在的具体问题类型，如产品设计和费率厘定问题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_508
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少了关于市政路网及配套工程的重要细节，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_502
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及中签率等关键信息，且未完全涵盖预期输出内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_505
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中缺少了'再接新订单'这一重要信息，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_507
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical financial details such as the revenue range and the exact net profit range provided in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_500
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要信息，也没有引入事实错误或冗长无价值的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_499
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出不符，实际输出提到的是我国成为全球第二大商品消费市场，而预期输出要求强调的是货物贸易总额连续5年全球第一。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_496
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含关键信息，如疫情可能由接触污染入境物品导致，且未提及进一步的流调溯源工作正在进行中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_504
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了出资金额和基金类型，但缺少了具体的操作时间框架，略去了'自公告之日起15个交易日内'这一重要信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_516
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='遗漏了工信部来源和连续三年增速超过20%的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_506
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as 'in mutual respect' and 'finding common ground while reserving differences', which are present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_511
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the mention of '十大重点工程' and '时间表、路线图', which are important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_515
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，也没有遗漏重要细节，且长度相当。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_509
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the 5-year period and the total amount of 11.9 trillion yuan, which are critical facts from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_518
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了四季度销售规模环比增长的关键信息，且仅包含预期输出的部分内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_521
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于首相强调去碳化投资翻番的重要信息，且没有提及任何具体领域的讨论。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_512
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about supporting and cooperating with the Sci-Tech innovation board and promoting more 'hard tech' companies, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_514
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容不符，实际输出简述了地方政府债券的发行情况，而预期输出则提到了地方政府债务余额及其限额情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_526
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了珠海和中山多家公司回应疫情的部分，仅提到了格力电器放假两天。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_522
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出省略了热销商品的具体类别，如盲盒、徽章、贵金属等，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_529
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了提高中央企业清洁能源装机占比这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_510
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on the overall goal of building a modern railway network instead of emphasizing the specific task of积极推进重点城市群城际铁路规划建设 as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_520
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about '悟空搜索', '游戏社区'灵选'和机器人', which are mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_523
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output discusses small-cap Chinese stocks and their performance, contrary to the expected output which focuses on the opening performance of major US stock indices.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_531
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了出售股权和交易所得款项用途的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_513
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中包含了预期输出的所有关键信息，但省略了'净'字，导致略显不准确；实际输出比预期输出略长，但没有增加实质性的内容。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_525
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有包含预期输出中的重要细节，如经营范围，且提供的信息与预期不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_527
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了德国总理会见挪威首相这一重要信息，且没有提到建立更深入的能源伙伴关系的期望。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_517
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出包含了原石材产业研究院主任工程师的身份，但省略了审查和调查的具体细节，且提到罗宏文为'原'主任工程师的信息在输入中并未明确提及。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_534
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual Output omits important details from Expected Output, such as the date and the specific new cases reported.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_530
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含预期输出的所有关键信息，但添加了注册资本的具体数额，这使得实际输出比预期输出更详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_539
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了小行星飞掠地球的具体日期，与预期输出相比信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_524
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the focus on stability in macroeconomic control and the specific measures mentioned in expected output. The summary is also significantly shorter, potentially lacking in important information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_535
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了深股通资金净流入的具体金额和减仓股票的信息，且招商银行加仓的具体金额也没有提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_536
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the number of units and area for residential and business apartments, focusing only on the total number of projects.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_541
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了从日本进口这一关键信息，且未明确美国的宣布行为。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_528
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the name of the supercomputer and the claim of becoming the world's fastest AI supercomputer, which are present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_543
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了预期输出中提及的钢厂利润有望逐步恢复的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_538
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了关于首次加息后实施量化紧缩的重要信息，且没有明确提到预期的时间点，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_550
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出缺少'展开正式访问'这一重要细节，导致内容不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_545
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的内容不一致，缺少对实体经济、科技创新和绿色发展的支持这一重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_533
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出正确反映了市场对欧洲央行和英国央行加息的预期，但缺少了具体的债券类型和收益率差的具体数据，且表述不如预期输出简洁明了。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_542
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by mentioning Shanghai Rongtuo exiting instead of Nan tong project, and incorrectly stating Jianfa International as the new shareholder without specific project details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_548
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含中标金额但遗漏了具体的地区信息，这减少了摘要的准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_540
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了严防禁燃区燃煤经销死灰复燃，但未提及加强散煤市场监管和减少污染，忽略了预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_555
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical financial details and range of expected profit, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_519
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="The actual output omits the specific number of确诊病例 and无症状感染者, only stating '新增5例无症状感染者'. The expected output specifies 1确诊病例 and 2无症状感染者 on the first day, and 1确诊病例 and 1无症状感染者 on the second day, totaling 5 cases with a breakdown of their types.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_557
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中省略了密切接触者均已落实隔离管控的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_537
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提及了新增至MSCI新兴市场指数的三家公司，而忽略了预期输出中提到的新增至MSCI中国A股在岸指数的中国移动等股票，且未提及全部新增内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_532
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contains more specific information about the companies involved compared to expected output, but it omits the fact that it is a donation and the capacity of the冷库. The length is slightly more than necessary without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_544
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details such as the specific responsibilities of celebrities in commercial endorsement and the definition of brand experience officers as advertisers, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_549
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the specific requirements and emails sent by Citibank and the names of executives mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_552
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_546
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了总投资额，但遗漏了年度计划投资额这一重要细节，且内容比预期输出更长，但未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_553
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the detail of '同比' (year-over-year) from the expected output, making it less accurate but not contradictory.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_556
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了芯片短缺的信息，但未提及特斯拉减配的具体内容，且没有提到USB-C模块取消多媒体功能的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_559
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了新闻的部分事实，但遗漏了总统关于骚乱事件调查无须外界介入的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_562
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the inclusion of预制菜相关品类的业务 from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_560
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the percentage of equity and the expected end date for the stock suspension, reducing its accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_551
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了捷成股份承担央视春晚部分节目及高清/4K重播版制作的任务，但略去了世优科技的相关信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_561
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了德国子公司将运营项目的具体信息，且未提及正式注册成立运营公司的细节，导致信息不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_554
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了关键信息，但增加了'以回应立陶宛此前拒绝白运载钾肥火车入境'，这使得输出比预期输出略长，但没有实质性错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_558
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有包含预期输出中的关键信息，如放宽住房套数认定政策和只认贷不认房的标准，导致信息不全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_565
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by focusing on the wrong content and omitting key details about economic growth compared to major developed economies.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_566
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了新闻秘书的警告这一重要细节，但没有引入事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_547
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出包含了具体机构名称和官员职位，但与预期输出相比，提供了更多的细节，而这些额外的细节在预期输出中并未提及，导致冗余。同时也未完全遵循'Expected Output'中的简化表达方式。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_563
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提到将加息预期时间提前到7月这一关键信息，且长度比预期输出短，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_564
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了孙力军的原职务公安部副部长，且没有明确指出被提起公诉的主体，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_569
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on order demand instead of production recovery and omits key recovery detail.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_568
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，且缺少关键细节，如CPI数据的具体评估和市场押注增加的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_571
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中缺少了'210高效组件'和'成功下线'的关键信息，导致内容不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_574
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中遗漏了被制裁官员的具体身份（现任或前任政府官员），导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_578
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='包含票房破亿的信息与原文不符，且忽略了排片上涨的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_567
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="Actual output omits crucial information such as the release of the White Paper and focuses only on the scale of the industry, contradicting the expected output which highlights the White Paper's release.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_577
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits details such as the date and the internal nature of the document, but does not contradict the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_576
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the full name '海洋工程有限公司' of the company, which is present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_579
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有出现事实上的矛盾，也没有遗漏重要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_580
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少劫持者死亡和拜登发表声明的重要信息，且未提及人质被释放的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_581
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like the number of companies with positive performance and the expansion of production in the downstream sector.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_583
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未明确指出子公司出资6000万元，缺少重要细节；但没有出现矛盾的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_572
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了美联储决策的具体影响和对美国加息预期的增加，且未提及新闻中鲍威尔的言论以及收益率在未来几天可能走高的预测。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_570
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出未提及严查电子烟线上交易和针对青少年的营销推荐问题，而预期输出强调了这些关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_588
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中没有包含预期输出中的净利润具体金额范围，略去了具体增长金额信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_589
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="实际输出中缺少了关键的地理位置信息'广东惠州市仲恺区'，导致信息不够准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_587
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了新闻的核心内容和银保监会的具体提示，包括诈骗风险的警告。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_591
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出没有包含'世界最高最大'的重要细节，但没有出现事实矛盾，长度适中。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_573
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，且遗漏了重要细节。实际输出仅提及北京市交通委执行冬奥会防疫要求，而预期输出则涉及交通运输部发布的春运疫情防控和运输服务保障工作的通知。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_575
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中引用了特定分析师的观点，而预期输出更侧重于机构分析。实际输出没有直接反映市场情绪恶化和美联储政策反应不足的核心信息，且缺少预期输出中提及的'周末之前'的时间限制。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_586
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了所有重要细节，但添加了‘明斯克国际机场’和‘出席疫苗交接仪式’等未在预期输出中提及的内容，导致略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_590
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于瑞科生物专注于HPV候选疫苗研发的重要信息，且未提及公司提交上市申请的具体日期和疫苗研发进展等关键内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_582
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the key fact about the annual growth rate of 34% and does not mention the period of time as '2018至2021年', which are important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_594
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the mention of price pressure increase and the possibility of上调通胀预测, leading to less accurate information compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_596
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出遗漏了燃油短缺导致的具体影响区域，即贝鲁特的西部地区，且未明确指出是首都部分地区互联网中断。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_605
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing a different company name and financial details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_593
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了台积电为英特尔设立3纳米生产线的内容，但缺少了预期输出中关于合作超预期和长期关系的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_584
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提到了新主播入驻、留存和MCN机构的激励，但未明确提及现金激励和扶持中腰部及新达人的内容，且未提及具体的年份2022。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_604
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits critical details from the expected output, such as the content and findings of the investigation report.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_597
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output on the impact of oil prices and misses key details about the impact of the central bank's hawkish stance on yields and currencies.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_602
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了净利润的具体范围和产品价格上涨的信息，且增长百分比的范围与预期输出有偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_592
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='Actual output does not contradict expected output but omits details about the timeline and the mention of 30 officers from earlier in the month. The output is concise but lacks some key information from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_601
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中的机构分析和供应紧张的关键信息，且缺少对原油供应趋紧的直接描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_603
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但缺少了'无症状感染者'的表述，影响准确性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_610
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但缺少了对上海一芯智能的具体描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_595
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出提到了同比下降87.3%，而预期输出要求的是环比下降11.9%。实际输出包含了额外的信息，但缺少预期输出中的关键环比数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_585
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含的细节与预期输出不一致，实际输出强调了通胀率高于7%，而预期输出的重点是CPI数据对市场的考验。实际输出忽略了预期输出中关于市场动荡风险的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_598
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on a specific part of Macklem's statement about interest rate adjustments rather than the broader point that policy rates have multiple possible paths.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_613
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了维持买入评级的重要信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_606
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了净利润的具体数额，以及LNG和CNG的相关信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_599
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了对2022年消费领域的乐观态度和回归正常经营状态的预期，同时未提及均衡配置的概念，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_607
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='缺少关键的推迟至2027年的具体日期，且未明确表示为官方公告。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_611
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the phrase '机构分析' which is present in the expected output, indicating a less accurate representation.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_616
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中省略了'蓝皮书'这一重要细节，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_609
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in authorship and content summary, omits key details such as acknowledging achievements and maintaining sobriety from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_600
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了古特雷斯的具体名字，而预期输出中没有。虽然实际输出提供了更多的细节，但并未引入新的信息或事实，且比预期输出略长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_618
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及是否为临时取消，且措辞较为模糊。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_617
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning key details such as asset management scale and ranking, focusing solely on a snippet of the interview.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_615
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output contradicts expected output by not mentioning the volcanic eruption in Tonga, focusing only on the tsunami warning issued by Japan.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_619
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了地点信息'海南'，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_624
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='The actual output matches the expected output exactly and does not omit any details or introduce contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_612
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits crucial details about the inclusion of information technology outsourcing in the daily risk monitoring and on-site inspections of banking and insurance institutions as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_614
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details from expected output, such as '要践行真正的多边主义' and '共同建设和谐合作的国际大家庭'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_629
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks specific date for the second round of testing mentioned in expected output and includes unnecessary information about the first round.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_620
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了AMD不愿意对客户价格评论以及浪潮已证实并接受价格调升等重要细节，但并未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_627
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含预计输出中的关键时间信息'下周'，导致准确性降低。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_628
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as龚正's name and the current stage of the科创中心's development, resulting in less accurate information.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_634
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但存在细微差异，如百分比范围略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_623
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出的关键信息不一致，缺少了对工程建设、电力、互联网和汽车等行业投资机会的建议。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_625
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning the involvement of three departments and focusing on a narrower aspect of the news.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_621
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的是子公司签订合同，而预期输出中明确指出是孙公司签订合同，且合同内容为供货，实际输出中未明确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_640
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了等值外币的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_630
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the specific locations of the cases and the method of discovery, but does not introduce any factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_622
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes information not present in expected output, introducing vagueness but omitting key expected details about the absence of spread inside the closed loop.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_639
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key information about the performance and reliability improvement of automotive products, focusing only on product application and sales.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_633
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了关于2025年建立健全预警监测体系的重要细节，且措辞较为模糊。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_638
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出提供了正确的累计确诊病例数，但未采用预期输出中的亿为单位表示方法，略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_636
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason="Actual output omits key details about the specific changes made to vehicles and the regions affected, as well as the official response from Tesla's customer service.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_632
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了新闻中关于经济增长前景和通胀前景的细节，且语言较为模糊，未能全面反映预期输出中的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_635
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='Actual output includes all key details from expected output but has a slight variation in the percentage (36.3% vs 36%).', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_608
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output mentions the resignation of four senior aides and deepening crisis, but the order of information and framing differ from expected output. Actual output starts with the resignation causing crisis, while expected output starts with the crisis and then mentions the resignation. Additionally, important details such as the names of the aides and the context of the 'partygate' scandal are omitted.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_637
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了确诊新冠肺炎病例和宵禁措施，但遗漏了宵禁的具体时长和详细措施，且比预期输出详细，但未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_626
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the impact of Meta Platforms' earnings, the performance of other tech stocks, and the market reaction to Peloton's potential acquisition. It also lacks the context of other major indices and their performance.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_649
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'浑水报告中的'这一重要细节，但这并未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_645
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key details such as the analysis from Dongwu Futures and the forecast for short-term price movements, focusing only on price movements without substantial value addition.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_642
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中包含了额外的信息，如'承购人取得共有产权住房个人份额'，虽然这提供了更多信息，但与预期输出相比略显冗长。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_643
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output does not match the expected output; it summarizes the analyst's view on the market impact of Microsoft's earnings report rather than providing a stock rating and target price.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_650
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中缺少了境外输入确诊病例的相关信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_651
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了感染不可避免的重要信息，且没有准确反映多数美国人的感受。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_647
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="Actual output omits '海西州州长乔亚群表示...' and other context details, but does not contradict expected output facts.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_648
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了更多细节，但偏离了预期输出的主题重点，且未明确官方的澄清意见。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_641
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了油价上涨和创七年新高，但缺少了土耳其输油管道中断的关键信息，且未提及机构分析和地缘政治问题，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_644
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output includes additional details about the police finding a body, which were not part of the expected output, leading to a less accurate summary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_664
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, no contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_660
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少了总投资额的具体信息，而这是预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_652
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了去年年底账面现金的具体数额和足以应对短期债务的关键信息，导致输出内容不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_646
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes specific location information (首都基多) not present in expected output, but omits the number of injured and missing people and damage details, leading to less accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_659
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及北向资金这一关键信息，且未突出中国人保与新华保险最受青睐这一点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_656
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits the full company name '中国万向控股有限公司', leading to less accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_655
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the denial of developing a $25,000 car model and is less detailed compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_658
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但略显冗长，引入了预期输出中未提及的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_662
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits '公司' before VR.AR.MR business, but does not introduce any factual errors or contradictions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_631
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output contradicts the expected output by specifying '温和的正回报', which is more detailed than '正回报' in the expected output but adds an unnecessary detail. Additionally, it omits key information such as the time frame '2022年' and the mention of '策略师们'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_657
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='Actual output includes extra information about the speaker and specific advice, which is not in the expected output. However, it does not contradict the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_653
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific percentage of decline for the Hang Seng Index and the significant decline of Wuxi Biologics, which are present in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_666
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_663
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中忽略了成立调查组进行全面调查这一重要细节，仅提到了将依法严肃处理。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_670
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits important details such as the specific distribution of cases among buildings and the government's further measures.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_667
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了票房预测信息，但缺少了关于影片开启预售的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_654
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了具体的月份信息，即2021年12月份全国销售彩票322.57亿元，同比下降11.7%的数据，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_672
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了对大盘形成支撑这一重要信息，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_665
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的信息与预期输出不符，实际输出强调了游客在本地逛景区的比例，而预期输出则关注本地酒店订单占比。实际输出未涵盖预期输出中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_674
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details about the project's purpose and scale, such as '规划建设年产10万吨高性能电解铜箔项目'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_680
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_675
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了具体年份，但没有其他重要的事实性错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_671
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key information about the iPhone's热销情况 and 苹果重夺全球智能手机市场桂冠, which are important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_669
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了油价连续第六周上涨的重要信息，并且没有明确提到东欧与中东的地缘政治紧张局势，仅提到了地缘政治风险和油价上涨。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_681
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output provides specific details about the project name, whereas expected output is more generic. No contradictions found but actual output includes extra information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_668
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the specific percentage increase and price change of必和必拓集团, and does not reflect the significant rise over seven weeks as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_694
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output includes extra details not present in expected output, introducing unnecessary information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_682
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the impact of the suspension and the reiteration of the 2022 production guidance.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_661
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在矛盾，实际输出提到沪指上涨0.14%，而预期输出强调创指的表现和新能源板块的拉升。同时，实际输出缺乏预期输出中的关键细节，如创指盘中的表现和新能源板块的表现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_676
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the expected runtime for 4号机组 and incorrect expected runtime for 3号机组, which is not specified as 2022全年 in the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_684
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了预期输出中的警告内容，且没有体现对民进党当局的直接警告。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_678
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details from expected output, such as the context of 'pigeon' central banks becoming endangered species and the question about how long the European Central Bank can persist.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_673
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output uses '同比减少50.99%' instead of '环比减少42%', contradicting the expected output's requirement for a month-over-month comparison.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_686
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了项目总投资额和预期年销售额的重要信息，且未提及项目落户南昌的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_687
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about maintaining high pressure against film piracy and does not fully capture the expected output's intent.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_685
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了关于货船故障导致堵塞的重要信息，且没有提到堵塞的情况，只提到了通行恢复。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_677
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出包含了净利润的具体数额和同比增长范围，但是缺少了'预增'这一预期增长的明确表述，同时实际输出的信息量比预期输出多，但并未显著增加实质价值。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_689
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了预期输出中的重要细节，如指导意见的发布以及市场交易和价格机制的形成等内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_688
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='The actual output matches the expected output exactly, with no contradictions, omitted details, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_691
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了新增确诊病例的具体数量，仅提到了累计确诊病例数。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_693
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及美国收紧货币政策将提高美元债务偿付压力这一关键信息，且与预期输出的主要信息有所偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_683
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在事实不一致，贵州茅台和浪潮信息的净买入情况以及中国中免的净卖出情况被遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_696
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output omits important details such as the uses of the raised funds and the financial performance forecast, contradicting the expected output's completeness.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_697
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了会议的时间和内容，但比预期输出多了会议的具体日期和工作内容，虽然信息量稍多但并未影响准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_692
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及许昌市，且未提及第10轮核酸检测计划，缺少关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_690
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits details about the condition for approval and the nature of Kustomer as a customer relationship management company, but does not contradict any facts from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_679
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未直接引用预期输出中的关键短语'美联储利率决议'，并且包含了更多细节，如CFTC数据和掉期交易员的情绪变化，这使得实际输出比预期输出更详细，但没有引入矛盾信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_706
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提及大宗商品强势开局的关键信息，且缺少新闻的时间背景和来源信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_704
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含医院名称，缺少关键信息；但未出现事实矛盾，且长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_695
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by not providing the required information on the overall and regional operation status of futures companies.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_702
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的信息与预期输出不符，缺少美伊谈判和油价从7年高点回落的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_703
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于发射频率的具体描述，且没有提及一周一次的平均发射频率。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_700
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出相比，缺少了'建设成功'这一细节，但没有引入事实错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_707
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的重要信息，如总投资额超过2万亿元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_699
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了额外的信息，如优化外债利率和期限结构的内容，超出了预期输出的范围，并且没有完全反映预期输出中关于个别房企违约不影响市场整体功能的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_698
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含错误信息，提到机上两具发动机被拆下，这与预期输出和输入内容不符；并且遗漏了航班挂出紧急代码和目击者看到消防车进入机坪的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_718
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important financial details and range provided in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_701
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the detail that it is a '合作协议书', but does not contradict any facts in the expected output. The length is appropriate without unnecessary elaboration.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_711
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on confidence rather than the long-term positive fundamentals of China's foreign trade industry.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_715
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key facts about the number of projects and amount of社会资本 introduced, focusing only on the perspective of国企改革的组成部分.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_712
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits key information such as '深交所' and does not explicitly state '调入', leading to less accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_714
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the detail of 'price war' and 'grassroots survey', which are important points mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_709
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了能源成本飙升对金属产能的影响这一重要信息，且与预期输出中呼吁欧盟采取行动的具体内容不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_713
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了部分信息，但遗漏了关于国际邮件从业人员的具体核酸检测频次，且未完全反映原文的详细内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_720
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes additional information not aligned with expected output, and omits key details about FDA EUA authorization and sensitivity issues.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_723
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少医药股集体下跌的重要信息，且与预期输出相比，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_724
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了净利润的具体范围和成本上升的影响，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_722
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了核酸检测结果均为阴性的关键信息，且未提及重点人群和环境样本的检测情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_719
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了民俗消费成为热门的信息，并且未提及消费增长的具体品类，与预期输出相比，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_717
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出缺少'近期'这一重要时间描述，且没有完全复现'派遣少量美军'的具体表述，导致信息不完全准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_721
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含关于美国向台湾出售武器项目的具体信息，且比预期输出详细得多，重点偏离。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_705
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '首次亏损' (first-ever loss) and does not match the exact phrasing of '2021年度预亏' (expected loss in 2021).", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_725
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits the important detail of the completed power generation, which is a key fact in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_716
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了科技股的跌幅和具体个股的表现，如恒生科技指数的4.51%跌幅和B站、美团的具体跌幅，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_710
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到宁德时代成立新公司，但期望输出指出该公司是由宁德时代投资成立，且实际输出中没有提及四川时代新能源科技有限公司和宁德时代的全资子公司关系。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_708
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的内容不符，实际输出仅提到跨国公司本外币一体化资金池业务试点，而预期输出要求涵盖资本项目高水平开放的内容，且实际输出遗漏了预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_726
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by stating that a slower immigration flow may help alleviate job vacancies, whereas expected output suggests higher immigration levels could help address labor shortages.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_727
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中缺少了项目包含多地核心资产和地标的信息，且未提及最多可回款236亿元的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_728
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the yield differential between Italian and German bonds and does not mention the new high since September 2020.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_738
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键事实，但省略了阿联酋国防部的声明来源和确认无人伤亡的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_736
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中没有提到2021年的销量数据和市场份额，缺少重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_735
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了预期输出中待复核87人的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_734
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes revenue and growth details not present in expected output, and omits '业绩快报' which is an important detail from expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_737
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits crucial details about the COO's request for a 20 billion dollar compensation and his past contributions to WeWork.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_743
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少承诺至少持有1年的信息，且未提及20个交易日内申购的具体时间安排。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_731
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少重要细节，如设备名称“共工号”和成功下线信息，且未提及设备的用途和影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_732
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出相比，省略了部分细节，如'网传'和'传闻'等词汇，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_747
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了'有关地区税务部门'，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_729
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output misses crucial details from expected output, such as the specific number of items removed from online platforms and the identification of the entity issuing the directive (国家无线电办公室).', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_733
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及长城汽车业绩低于预期，且未包括瑞信报告中的关键细节，如季度利润增长、毛利率上升的原因以及一次性项目的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_751
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了预期输出的部分信息，但忽略了市场增长空间的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_730
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到恒大完全退出股权，但预期输出中只说明转让了股权，并未提及完全退出，且未提及退出的具体百分比，导致信息不准确且有部分细节遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_749
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了回应市场疑问的重要细节，且长度远短于预期输出，未能全面概括财政部的解释。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_742
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及病例的具体日期和病毒类型，且与期望输出相比过于简略，缺乏关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_739
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含具体自购基金公司的数量和自购金额的细节，且比预期输出更简洁，但未引入新的事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_741
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits important details from the expected output and introduces a different focus without addressing the main concern highlighted in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_750
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details such as '依法从严' and the full entity names, reducing its accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_745
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了'两连板金陵饭店'这一重要信息，且未提及子公司预制菜业务处于起步阶段，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_753
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了消费者信心指数处于乐观区域的重要信息，且没有提及指数下降的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_748
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific details about the violation of防疫政策and the company's advice to not focus on八卦新闻, leading to less accurate representation.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_754
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含预期输出中的'菜价会逐步回落'这一重要细节，因此在准确性上有所欠缺。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_740
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出的表述与预期输出略有不同，将'预亏'表述为'净利预亏'，虽然没有改变核心意思，但稍微偏离了预期的简洁性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_744
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output mentions the correct bid amount and the nature of the project but omits the specific role of the subsidiary as a joint lead and the use of EPC terminology in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_757
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits details about the expected 1-2 additional future interest rate cuts, making it less accurate than the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_759
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes additional details not aligned with expected output, leading to less accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_755
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中省略了项目具体位置'安徽省芜湖市车管服务中心和驾驶人考试中心'，导致重要信息缺失。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_760
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes extra details not aligned with expected output and omits key phrases like '兼容性认证'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_763
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及预期输出中的重点项目数量，且标题未能反映规划的具体内容和目标。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_771
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少来源信息和具体的新闻细节，仅保留了核心事件。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_746
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出主要提及了抗疫概念股和大型科技股的表现，而预期输出则关注道指、标普500和纳指的开盘跌幅。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_756
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但实际输出略长且使用了'左右'一词，使得表述稍显冗余。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_766
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了经济总量和同比增长率，但遗漏了经济增长的良好开局和新闻标题的情感表达。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_758
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the demand from锂电池厂商 and their order status, focusing only on the stability of PCB铜箔 supply.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_752
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contains additional information not aligned with expected output, including details about the New Zealand government's response and the current state of the disaster, which are not present in the expected output and introduce a broader context that was not required.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_761
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了中证报和上证报关于A股长期向好的重要信息，且未提及具体回购和增持计划。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_773
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='缺少关键细节，如具体股票的表现和板块涨幅超过2%。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_765
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the 65% booking rate and does not mention the average stay duration or the increase in亲子消费力环比增长超30%.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_774
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without omitting any details or introducing contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_767
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少具体时间、轮次等重要信息，且未提及26日未完成检测的居民需参加检测。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_762
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了布朗顾问公司的具体声明，仅强调了投资者无需担心股市波动，但忽略了股票市场表现出剧烈波动的背景信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_768
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中包含汽车零部件制造的信息，但未提及汽车零配件批发的具体范围，且与预期输出相比信息不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_769
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了房源稀少推高房价的重要信息，且没有提及房价上涨15%和中值为382900美元的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_781
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了新增死亡病例的信息，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_770
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了市长龚正的名字和加装电梯后的长效管理信息，这些是预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_772
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到美元指数突破去年高点的具体数值和未来的反弹目标，缺少预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_764
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了古贤镇20例和育才学校15例的具体病例数，且未提及文峰区2例感染来源的调查情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_775
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有直接引用输入中的具体内容，而是提炼了其中的主要观点，但忽略了输入中有关裁员和间接投资的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_779
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于监管加力查处中介违规的重要信息，且未完全准确反映预期输出中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_778
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了低于预期的营收信息，但缺少了美股的具体信息，且比预期输出多了不必要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_780
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中未提及商汤成为前十大股东的可能性，且缺少了AI公司的具体描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_777
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出仅提到了货币政策将继续偏松操作，但忽略了预期输出中关于货币调控大幅宽松空间有限和小幅降准的具体细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_784
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了净利润的具体增长金额范围，但没有出现事实上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_782
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了营收和同比增长的细节，但遗漏了主营业务调整和电动车销售收入的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_783
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了佩洛西的年龄和她可能不再担任民主党领导职务的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_785
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the predicted CAGR and 2026 industry size from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_786
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了具体的政府职位信息，未提及警告的具体内容，且措辞略显简化。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_790
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific positions of the officials involved and the comprehensive discussion topics mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_787
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output provides key facts but omits important details like the establishment date and the company's business scope as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_791
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the specific drop in points and the fact that it reached a one-year low.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_776
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的关键信息不一致，实际输出主要强调了收入低于预期，而预期输出更侧重于PC组件业务对业绩的拖累以及对2022年展望的关注。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_794
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits important details from expected output, such as the lack of contact with比亚迪公司and no cooperation意向with刀片电池供应商.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_788
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output is concise but omits the specific method (协议转让) and the price (5153.35万元) mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_796
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key information such as the expected approval and the drug's role in passive immunity, reducing its accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_789
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未提及经济增长减速导致金融股挑战这一关键信息，且标题内容与预期输出相比过于简略，未能反映预期中的核心因素。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_802
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要信息，也没有增加冗余的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_795
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了主要信息但略显直接，缺少'预期输出'中的双方均不回应的明确表述，导致信息不够全面。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_792
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了'市场分析'这一重要细节，且未提及具体加息行动及其影响，这使得信息不够全面。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_804
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了大部分关键信息，但投资金额和项目细节略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_801
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the expert's confirmation and the potential for three generations of cases, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_800
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了监管机构的具体要求和对违规行为的处理措施，且未强调有人已触发预警。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_806
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少营业收入和同比变化的信息，对比预期输出有所遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_803
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了'港交所'，导致句子缺少明确主体，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_798
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比，省略了鲍威尔讲话、收益率差的具体数值和市场情况等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_799
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the key phrase '反映了“异常时期”', which is crucial to convey the full meaning of the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_807
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少重要细节，如万事利的IPO信息和两度参与奥运会绶带生产的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_817
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出包含了联合体中标的信息，但缺少了中标金额的具体数值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_810
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about battery suppliers and price issues with宁德时代, focusing only on the delivery plan.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_814
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by listing different board members instead of mentioning Hu Shaofeng as the board secretary as expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_793
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出的主要差异在于净利润增长百分比的精度不同，但并未引入新的事实或错误。实际输出提供了比预期输出更多的细节，如净利润的具体范围，但这也未导致明显的不准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_819
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output mentions only Russian forces, omitting details about other member countries' forces as specified in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_812
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the acquisition of the办学许可证and the specific name of the new school, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_805
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="The actual output accurately captures the key details about the AR headset development and the projected launch year from the expected output, but it omits additional context such as the project's codename and team size.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_809
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits specific details about the criteria for declaring the emergency, such as the percentage of ICU beds and oxygen-dependent patients, as well as the number of daily new infections.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_797
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的旅行服务逆差大幅下降是导致服务贸易逆差减少的原因之一，但遗漏了其他重要原因，如服务业快速增长、知识密集型服务出口竞争力提升和运输服务出口快速增长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_822
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific percentages for the indices and the cause of the decline, which are important details from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_815
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了氧化铝和铝的产量信息，且标题格式略有不同，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_823
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了将持续招聘人才这一重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_816
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少对评级和目标价的重要信息，仅提到了下调EPS预测，而期望输出强调了维持跑赢行业评级和具体目标价。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_811
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like overall strong demand and key drivers such as stable economy and low gold prices, focusing only on the growth of gold jewelry demand.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_818
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了SOFI获得批准成为银行控股公司的重要信息，且未提及这对SOFI的积极影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_820
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output contains factual errors by omitting key details such as the specific date for implementation and the options for transferring the property.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_827
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contains extra information not aligned with expected output, introducing unnecessary details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_813
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含的部分事实与预期输出一致，但实际输出中的表述更为具体，包含了发言人的职位和对监管的详细描述，而预期输出较为简略，未包含关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_830
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='遗漏了许昆林当选江苏省省长的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_824
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the current price of 58.50元/吨, only mentioning the price increase compared to the previous day.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_821
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output contains all key facts but omits '英国' before '政府', slightly less accurate than expected.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_808
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出虽然提到了支持“专精特新”中小企业高质量发展的措施，但忽略了开发“专精特新”贷和建立上市绿色通道这两个具体措施，且信息量远超预期输出，因此扣分。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_833
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the date, the meeting, and the comprehensive reform plans mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_829
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及供应液化天然气的具体类型和分析的象征意义，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_831
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了专项治理工作的具体信息和电子商务平台的相关要求，且未提及多部门联合行动的具体名称和目标。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_837
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks details about the similarity with North American and Singapore strains, omitting key information present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_834
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未提及本土病例的具体数量，与预期输出有重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_843
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by introducing additional information not aligned with the expected concise statement.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_825
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出缺少了预期输出中的关键细节，如'机构分析'和'六年来最差的1月份表现'，且未能全面概括新闻内容。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_832
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output omits key details such as the date and the four characteristics of the projects mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_835
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits mentioning the production of '冰墩墩' pattern towels for the Olympics and does not highlight the significance of producing Beijing-themed products as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_828
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes the disease names but omits the specific drug name '泽布替尼胶囊' and the '突破性治疗品种认定' detail, while staying close in length to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_836
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了南方五省区的具体年份和全社会用电量的具体数值，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_826
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的是防范火山喷发次生风险，而预期输出中强调的是防范海啸灾害，两者内容不一致，且实际输出中没有提及海啸预警和避难指令，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_838
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但省略了新增阳性人员和疫情防控严峻的背景信息，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_850
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出没有包含预期输出中的'动态价格指导'这一重要细节，导致信息不够全面。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_848
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及年内到期债券总额接近万亿元和并购贷登场缓解偿债压力的重要信息，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_842
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了扩大有效投资这一关键点，并且未提及新老基建的概念，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_845
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键事实，但描述略显冗长，包含了额外的股权转让信息，这在预期输出中并未提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_855
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含净利润的具体数值和范围，略去了关键的业务背景信息，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_853
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含病例活动轨迹信息，且比预期输出更简略，缺乏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_840
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on packaging design instead of consumer reduction measures, and omits crucial details about reducing plastic use through incentives.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_852
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含提高网络安全这一重要细节，且比预期输出略显冗长，但未出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_841
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits crucial details about the negative response from the US regarding the indivisible security agreement, focusing instead on the completion of internal coordination within Russia.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_839
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在内容上存在较大差异，实际输出未提及1月信贷投放的情况，且未提到房地产融资的积极信号。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_849
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="The actual output contradicts the expected output by focusing on Tesla's decline while omitting the general decline of large tech stocks as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_846
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the name of the project '丰e足食' and the names of the investors, making it less accurate compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_844
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在内容上有所偏离，实际输出包含了专家分析，而预期输出更简洁，直接指出LPR下调和更多宽松举措。实际输出并未完全符合预期输出的内容要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_847
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提到了欧洲央行的平衡策略，而未包含预期输出中拉加德关于2022年不太可能加息的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_854
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出基本一致，仅在金额表述上略有不同，且未包含预期输出中的所有细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_867
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了预期输出中关于总统因密切接触而自我隔离的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_851
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了额外的细节，如12万吨/年碳酸乙烯酯装置产出电池级产品，但未超出预期输出的核心信息，只是稍微详细了一点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_856
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提及了境外输入性病例，但忽略了无新增本土病例这一重要信息，且与期望输出的主要事实不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_858
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了关于建立健全合法捐卵、储卵途径的重要细节，且没有明确提及答复委员提案的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_861
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the progress status of the acquisition and the $400 billion valuation, leading to less accurate representation of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_869
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了额外信息，但遗漏了新春特别版冰墩墩即将上线的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_859
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及英镑与欧元的预期走势，且未完全反映预期输出中的英国劳动力市场向好的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_857
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含控制体育场馆规模和构建全国公共体育设施电子地图的重要信息，且表述略有不同，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_862
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含具体来源和通知要求，略去了部分重要信息，但并未出现事实矛盾，长度适当。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_860
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中的关键细节，如欧佩克+的会议安排和分析师对油价的预测，导致信息不完全。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_863
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by emphasizing '本公司绝对没有威胁要离开欧洲' instead of the more subtle '不希望离开欧洲', and omits the key point about continuing progress in dialogue with European regulators.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_866
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出与预期输出相比，缺少了'助力有效投资'这一重要信息，虽然没有事实上的矛盾，但信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_878
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了净利润的具体范围，但并未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_864
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了子公司获宝马12V辅助锂电系统项目定点的信息，但比预期输出多了项目周期和量产时间等细节，这些额外信息虽然不完全错误，但超出了预期输出的简洁要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_870
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到电商物流指数的具体数值108.6点，且缺少了部分重要细节，如哪些分项指数上升。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_886
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical information about the unresolved key issues depending on the US political decision.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_874
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了新闻标题的信息，但与期望输出中业内人士的观点不符，且包含了过多无关细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_875
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了新闻的一部分关键信息，但遗漏了病例初步判断处于感染早期阶段的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_883
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了预期输出的主要信息，但多了个'的'字，导致略有不同。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_873
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含预期输出中提到的元宇宙潜力巨大的信息，且缺乏具体的投资描述，导致信息不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_881
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了对营业收入的提及和净利润的具体范围，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_872
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了新闻标题中的'热点行情回顾'部分，且未明确指出拉加德言论转趋鹰派的具体原因。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_868
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含关键信息但略显简略，缺少'引江补汉工程新进展'这一开头表述，且未明确提及该工程的位置和作用。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_888
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='包含额外的累计确诊病例信息，但遗漏了新增病例的具体描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_865
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the specific date of establishment, the name of the company, the法定代表人,注册资本, and经营范围. It also does not mention the注册资本1.2亿 as specified in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_871
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与期望输出不符，实际输出包含更多无关信息，而期望输出仅提及新冠治疗药物相关产品收入占公司营收比重较小。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_882
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中的关键信息，即出货量同比提升34%。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_891
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, without any contradictions or omitted important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_880
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少珠海华润材料10万吨/年PETG特种聚酯工程的具体名称，且未明确提及项目总规模。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_892
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='包含额外的累计确诊数据，但遗漏了新增死亡病例和正在治疗的患者数量等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_876
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出在数值上略有不同，但未引入事实错误。实际输出省略了重组和双主业布局的信息，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_877
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出仅在符号使用上有所不同，实际输出使用了'到'，而预期输出使用了'-'。除此之外，两者在传达的信息上没有差异。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_897
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in content focus, providing an incomplete summary of the input without mentioning attracting more multinational companies.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_879
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含了所有关键信息，但增加了'依法防疫人人有责'这一部分，这使得输出相对于预期输出略长，且没有增加实质性的新信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_889
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details like the date and the changes to the specific areas from封控区 to管控区, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_899
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出一致，未出现矛盾且未遗漏重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_887
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output includes extra information about vaccine接种工作 which was not present in the expected output, leading to a deduction. However, it correctly captures the main point of the fourth wave of the pandemic easing in Africa.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_898
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits specific profit range details and slight variation in wording compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_895
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the official statement that the test station is different from the officially released version. Additionally, the actual output is significantly shorter, lacking important details from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_885
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含了预期输出的主要信息，但使用了更具体的表达方式，如'紧锣密鼓地推进'，这虽增添了细节，但并未显著提高信息量。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_890
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the launch of the EVOGO brand, the comprehensive solution including fast swap stations and APP, and specific information about the pilot cities and compatible models.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_902
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了新闻内容的主要信息，但略去了预期输出中的某些细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_896
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及了乌克兰军队未从边境撤离，但忽略了泽连斯基关于外交官撤离和局势升级可能性的重要观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_893
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中将李红军的职位从'江西省虚拟现实产业链链长'错误地表述为'江西省委书记、省虚拟现实产业链链长'，引入了身份的错误描述。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_908
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对FCC决定的具体回应，仅提到了中国联通将密切关注。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_903
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits critical details regarding the specific actions to stabilize monetary policy and maintain total stability as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_907
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未区分确诊病例和无症状感染者，导致信息不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_894
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the key detail of the project cost (6.76亿元) and the partner company (河南豫资朴和实业发展有限公司), making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_884
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output includes a factual detail about the profit range but omits the specific mention of the profit range being 8亿至9亿元 and the company's business expansion into the Belt and Road Initiative markets, which are important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_904
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了具体缩减比例47%，且未提及疫情前的对比时间点，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_913
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了业内分析人士的观点，但缺少了关于上海工厂零部件短缺情况有望缓解的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_901
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出机构不同，且缺少预期输出中关于不确定性凸显和政策方向的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_912
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含净利润的具体范围，且缺少业绩回暖和新增控股子公司的详细信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_900
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出基本一致，但缺少了'原油'和'止损价'的信息，导致信息不完全。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_915
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少解散政府和国民议会的关键信息，且未提及关闭边界的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_918
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及派对门丑闻和警察调查，缺少关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_909
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含预期输出中提到的今年将推行单独签订民生用气合同的信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_906
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits details about the top stocks in net buying and selling, and does not specify the exact threshold of 910 billion yuan as in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_905
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits key details about the profit range and the significant contribution from the non-recurring profit, while the language is concise but less descriptive than expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_922
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output includes extra detail about rocket intercepts but omits information about aircraft damage, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_916
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了贵州茅台的具体持仓基金数量和持股市值等重要信息，且未突出贵州茅台作为头号重仓股的地位。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_919
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="Actual output contradicts the expected output by not mentioning Wang Wentao's video address to the WTO event as stated in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_917
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了厦门是否将纳入房地产税试点的问题和税务局的回复，但遗漏了税务局强调的具体政策以正式文件为准的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_921
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中只包含了交通管制的信息，忽略了人员聚集场所关停等重要信息，且与预期输出的内容不匹配。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_924
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含预期输出中的具体注册资本数值35.58亿，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_920
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了时间信息和首次勘探的具体年份，而预期输出中提到了这是30年来首次以及具体时间。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_928
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了具体的地点浙江，时间信息也不够准确，因此扣分。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_911
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the location (朝阳区), the specific variant (德尔塔变异株特异性突变位点阳性), and the situation where the individual was controlled on the high-speed train.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_933
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='缺少部分重要细节，如珠海中山多家公司的回应。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_925
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含具体地点分宜，且未明确死亡人数为2人，缺少一些细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_914
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了预期输出中关于第四季度GDP的预测和奥密克戎变异株对经济影响的评估，且没有提及经济增速放缓和随后的复苏情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_910
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出包含了额外的信息，如药明生物的回应和采取的措施，而预期输出仅要求声明'未经核实的名单'不是'实体名单'或'黑名单'。实际输出偏离了预期的简洁表述。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_935
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contains contradictory information and omits important details compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_923
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the scope of basic medical insurance and the specific request for infertility treatment inclusion, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_927
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the 2024 election and misses the direct quotes from Biden, making it less accurate than expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_929
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在标题上存在较大差异，且缺少预期输出中关于加快解决问题速度的具体表述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_926
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少一级火箭曾作为猎鹰重型火箭助推器的信息，且未明确指出发射的是意大利CSG-2雷达星。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_930
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the important detail of '加快推广绿色低碳技术' from the expected output, reducing its accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_936
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing the growth percentage instead of the total sales amount in dollars.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_931
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出中提到的所有期货价格创新高，与预期输出中的具体玉米期货七个月新高不符，且引入了额外的不准确信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_944
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少'超'字，这使得金额的具体描述不如预期准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_941
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了网友的评论和基金经理的完整回应，未涵盖预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_950
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有包含注册资本的重要信息，且描述过于简略，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_943
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未提及佳能珠海成立32年的事实，且未明确指出目前正与员工协商方案。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_942
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中遗漏了市场监管总局要求交易双方和集中后实体履行的具体义务，如不得强制搭售、阻碍购买等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_932
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出虽然提及了继续深入推进'双减'，但未包含将'双减'工作摆在突出位置的细节，且未提及预期输出中的其他关键信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_938
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits crucial details such as the meeting between the city secretary and the company chairman, and introduces a new point not aligned with the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_940
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了所有关键信息，但比预期输出多了'新增病例均在伊犁州霍尔果斯市'，虽然准确但增加了不必要的长度。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_939
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，实际输出只提到了钯金缺口的预测，而预期输出强调了半导体和汽车产量对铂金和钯金前景的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_945
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含预期输出中的具体净利润金额范围，且增长百分比略有不同，但未出现矛盾之处。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_951
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少索赔1000万元的信息，且没有提及具体的赔偿要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_934
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了全球出货量的具体数字和3.41亿台的全年总出货量，仅提及了连续两年超9000万台，未能完整传达预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_937
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output includes additional information about韩国军方有能力探测和拦截朝鲜导弹, which is not in the expected output, resulting in a less accurate summary. However, it correctly captures the main issue of朝鲜导弹威胁直接、严重.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_952
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有矛盾，没有遗漏重要细节，且长度相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_953
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在信息细节上存在差异，实际输出未能准确反映伦敦证券交易所的具体提议，即为私人公司特别上市的计划。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_960
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，但缺少‘全国’这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_949
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少有关支持重点企业围绕新领域布局的重要细节，且未提及行动计划的具体领域和方向。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_958
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的净利润同比增长范围与预期输出不符，且缺少有关营业收入增长和业务发展机遇的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_946
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing on a different aspect of the speech instead of the key message about not lightly criticizing the U.S. monetary authorities and their policies.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_954
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少冷俊峰接替廖鲁江职位的重要信息，且未提及冷俊峰接手营销管理工作的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_956
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output contradicts expected output by not mentioning the importance of researching the necessity and feasibility of mixed-ownership reform, omitting a key detail.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_948
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details such as Microsoft's overall revenue growth and the specific revenue figures, while also being vague about the impact on the overall quarter's performance.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_957
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出与预期输出相比，缺少了'中药板块回调'中的时间描述，并且没有明确指出回调的具体情况，导致信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_967
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了国家航天局的信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_955
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on different metrics and omitting the key detail about the technology coverage rate of central reserves, which is over 98%.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_963
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有提到个股大幅高开的重要信息，且比预期输出更详细，但未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_962
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the extent of the sale and the drastic price drop, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_964
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中提到的对实体经济的支持这一重要信息，且内容过于简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_947
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中忽略了事故原因和建议问责的内容，只提到了将10人移送司法机关处理，而未提及完整的事故调查和处理建议，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_961
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about encouraging financial institutions to provide supply chain financing and exploring the use of digital currency, focusing only on asset securitization.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_965
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提及房地产并购贷款不再计入‘三道红线’这一重要事实，且未包含国资正在接触优质项目的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_959
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的内容与预期输出有出入，将俄联邦对外情报总局的声明错误地归于俄外长，且省略了盗采石油的具体数量等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_980
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes all key points from expected output but is slightly longer without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_979
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about data classification and responsibility, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_976
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出基本一致，但缺少了基金经理对消费股加仓的信息，且表述略显简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_966
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了发改委推进基础设施REITs试点的相关信息，且措辞略显简略，未完全体现预期输出中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_968
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks critical details such as the specific measures to be lifted and the confirmation by the prime minister, omitting important information from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_985
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by incorrectly stating 5 new local cases instead of 1.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_978
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了中标金额和招标项目，但省略了物资品类的具体信息，略长于预期输出但未显著增加价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_969
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了净利润的具体范围但忽略了净利润下降的具体原因和额外的财务细节，如坏账计提和投资收益影响，与预期输出相比信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_977
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific amount of the认购额 and does not mention the record-breaking number of participants.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_972
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about domestic interest rates and their expected behavior, focusing only on the impact on the US market.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_971
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容不符，仅提及了油价上涨的风险，而未提及预期中的2022年油气市场的强劲表现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_974
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits mentioning the intention to acquire and the phrase '改变行业格局的交易', making it less accurate compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_973
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出不符，实际输出侧重于发行公司信用类债券，而预期输出强调引导早期投资支持医药产业科技创新。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_989
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了具体时间，而预期输出包含了具体的时间段。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_990
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes factual details missing from expected output, but omits key information like signing the agreement.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_983
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，仅在措辞上略有不同，但并未遗漏重要细节或引入错误事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_981
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='存在事实性错误，实际输出中提到的是恢复大额申购，而预期输出中并未提及恢复大额申购，且日期信息有误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_987
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于RRP和IORB利率之间差距的具体细节，并且没有明确提及德意志银行的完整名称。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_982
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了发布《指南》和春运期间疫情防控工作的具体内容，仅提到了加强从业人员培训的部分细节，未能全面反映预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_991
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了新闻的主要时间点和对春节消费升级的助力，且没有提到具体的活动内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_970
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出包含了预期输出的主要信息，但增加了部分细节描述。主要差异在于实际输出中包含了商务部发言人的具体言论和背景信息，虽然这增加了文本长度，但并未显著降低准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_992
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了服务贸易仍低于疫情前水平这一重要信息，且未提及服务贸易增长的具体驱动因素。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_988
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出严重不符，实际输出强调新西兰火山喷发规模，而预期输出强调汤加火山喷发的持续时间和活跃期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_986
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提及了新冠疫情影响，忽略了人口下降的其他重要因素，如生育旺盛期妇女规模下降和生育意愿持续走低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_975
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出存在事实上的矛盾，实际输出只提到了欧元/美元跌破21日移动均线，而预期输出指出欧元整体跌破重要支撑位，并强调了油价上涨和美债收益率上升的影响，实际输出遗漏了这些关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_994
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，遗漏了关于一线城市、二线城市和三线城市的具体涨幅信息，且未提及同比上涨情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_993
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific price increase of over 50000元/吨 and the list of affected products.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_997
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于另派生成立房地产公司的关键信息，且长度明显短于预期输出，准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_984
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了关于智利锂矿国有化提案在议会全体成员投票和全民公投中的进一步步骤，以及市场对全球锂资源释放不确定性的讨论。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_995
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出的信息基本一致，但实际输出略显简洁，可能遗漏了'拟'这一表示计划或意图的词汇。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_996
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中包含的信息与预期输出不完全匹配，缺少了关键信息如'坚决阻断病毒隐匿传播'。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1002
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details such as '广东' (Guangdong) and '紧急' (emergency), which are present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1001
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on potential Fed actions and market expectations, instead of highlighting the impact of Omicron on employment numbers.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_998
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了8K直播对观众视觉震撼的具体描述，且未强调这是奥运史上首次8K超高清直播，重要信息缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_999
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出没有提到具体的日期（14日），并且没有提到新冠病毒，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1004
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了上海证监局发布2021年年报审计监管提示的关键信息，且未涵盖所有提到的风险，仅提到了部分内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1000
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了对利润增长原因和第四季度利润回落的具体描述，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1010
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了额外信息，但缺少了关于“固收+”基金规模激增9500亿元的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1009
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提到蔚来投资的具体金额和直面中介的意图，且未明确指出新能源车企与保险业合作的具体好处。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1006
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes all key facts but uses a different company name '中国保利' instead of '保利集团', and '中国建设银行' instead of '建行'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1003
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有包含预期输出中的净利润范围和公司净利润稳步增长的信息，且语言较为简略，未能全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1005
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the performance of other stocks and ETFs, and does not mention the comparison with美股三大股指 as stated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1011
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the details about the new equity structure and the involvement of other companies, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1024
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='The actual output matches the expected output exactly, without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1013
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中遗漏了'领跑芯片类股'的重要信息，且与预期输出相比过于简略。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1008
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中省略了具体产品类型和基地信息，同时并未明确指出交付的是车规级产品，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1012
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes extra details about transportation modes and highway flow which are not in expected output, and omits the date '2月6日'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1018
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the new product launch and the overall impact on company operations, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1020
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中的年度计划完成比例95%，略去了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1023
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分重要信息，但遗漏了春运启动日期的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1015
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details such as cumulative deaths and does not match the expected output's completeness.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1021
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly with no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1016
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于返乡人员不能确认无风险的重要细节，且省略了对家人错时就餐和不参加聚集性活动的要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1025
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了具体的日期信息，但未引入事实错误或明显矛盾，且长度适当。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1007
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了资产管理规模升至创纪录的10万亿美元以上，但与预期输出中的“首度突破10万亿美元”相比，缺少了首次突破这一关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1022
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了债券市场的开放，但未提及股票市场主要股指上涨及两市成交金额增长明显的重要信息，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1028
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了GDP同比增长的具体百分比和多项指标的表现，这与预期输出中的关键信息不一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1026
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了时间范围'1-12月'，导致信息不完全，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1031
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits specific locations mentioned in expected output and lacks the time indicator '今日'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1014
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中使用了'住建部、发改委'而非'两部门'，缺少了对两个部门的概括性描述，但未引入新的事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1027
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了2022年春节楼市成交同比下降51%的信息，但未提及深圳楼市几乎“零成交”的关键事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1033
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了新闻来源和日期的具体信息，这些信息在预期输出中是存在的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1035
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出遗漏了深交所采取自律监管措施和核查上市公司重大事项的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1019
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '中国资产优势尽显' and '全球资金坚定增配', which are crucial for conveying the expected message about the attractiveness and steady allocation of global funds towards Chinese assets.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1017
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the risk of the Fed tightening policy at every meeting starting in March as mentioned in the expected output, focusing only on specific months of加息. It lacks the critical information about the increased risk of more frequent tightening due to inflation pressures.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1030
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在重要细节的遗漏，且夸大了原文信息，引入了未提及的风险程度描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1029
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含累计确诊数量的概数表达，与预期输出中'累计确诊超981万例'的表述方式不同，导致信息表达不完全一致。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1037
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分关键信息，但遗漏了春节临近的时间背景和防止政策执行简单化的具体内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1039
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output states a contradictory fact to the expected output, with a growth in passenger turnover instead of a decline.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1034
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="实际输出包含了更多的详细信息，但与预期输出的标题不符，而且预期输出强调了'深V'反转，而实际输出没有提及。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1032
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output omits important details from the expected output and introduces a factual error by highlighting '焦炭跌超3%' instead of '红枣主力合约涨超5%'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1046
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出缺少'首次举行'这一重要信息，同时没有明确提到是在线上举行的会谈。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1047
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by omitting key details about the leading sectors and other significant stocks mentioned.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1036
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts the expected output by using 2.8 billion yuan instead of 14.8 billion baht and omits the implementation detail of the price stabilization plan.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1045
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了预期输出的部分信息，但遗漏了许多重要细节，如文件起草的具体内容和下一步行动计划。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1044
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了额外的细节，但并未与预期输出中的信息产生矛盾，仅在描述上更详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1057
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the number of regions affected and the duration of the measures, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1043
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键信息，但缺少股票代码(01209.HK)，且目标价上调的具体百分比有所不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1042
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提到了人参的一体化发展，但缺少了将人参产业打造成重要支柱产业的关键信息，且比预期输出多了不必要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1052
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含赛迪报告的信息，且未具体指出展锐在多个垂直领域市占率的具体数据，重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1040
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by indicating a potential increase rather than a significant and steady rise. Important details about the extent of the increase and the impact on consumers are omitted.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1038
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes more details than expected output, such as the involvement of the CEO and the timing of the decision, which are not present in the expected output. However, it does not contradict any facts in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1055
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the majority of the券商seeing increased profits and specific growth rates, and introduces a vague title that does not capture the essence of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1066
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, with no contradictions, omitted details, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1053
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含警告这一重要信息，且表述稍微偏离了预期输出的语义，但是没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1058
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details such as '85后' and '理工博士' from expected output, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1051
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了净利润的具体范围和营业收入提升等重要信息，且表述略显简略，但未出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1041
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output does not contradict expected output but omits details about euro weakening and the specific mention of the ECB falling behind other major banks. The length is appropriate but lacks some key points from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1048
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出中的亏损范围描述为6.5亿元至4.5亿元，与预期输出的4.5亿元到6.5亿元相反，存在事实上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1050
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，实际输出概括了工信部对2021年工业经济的评论，而预期输出是关于新闻发布会的预告。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1060
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于猪粮比价进入过度下跌三级预警区间的具体信息，而这是预期输出的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1056
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the specific name of the subsidiary and the license validity period, but does not introduce factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1054
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了伊曼纽尔·克利弗的全名，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1067
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅在开头部分略有不同，但未改变核心信息和重要细节，且长度适宜。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1049
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了高盛上调美债收益率预测的原因，但遗漏了具体的预测目标，即2022年末的10年期收益率目标从2％上调至2.25％。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1064
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了中国平安的信息，但遗漏了宁德时代和药明康德的净卖出信息，且金额细节不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1062
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及缩短后的具体时长，且未包含预期输出中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1070
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="实际输出中缺少了'美国国家航空航天局'的关键信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1068
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于全链条排查和追溯到末端的重要信息，仅提到了从业人员排查，与预期输出相比，信息不全。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1071
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的关键信息不符，包括公司名称、新势力的具体表现和估值方法的介绍。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1075
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预计输出中关于多地新年庆祝活动被取消的信息，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1076
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少了关于未来适当时候介入该产业的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1069
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了经济损失的估计信息，且未提及停产检修的具体生产线类型。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1061
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出的主要区别在于表达方式，实际输出添加了更多背景信息如罚单原因，但并未包含所有预期输出中的细节。长度稍长，但未添加实质性的价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1063
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about '中欧班列与跨境电商实现融合' and focuses only on the B2B export regulation pilot, which is an important aspect but not the full scope of the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1065
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了对半导体行业的具体聚焦，且未提及投资的主要方向，这与预期输出中的关键信息不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1073
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by mentioning wrong founding company and omitting key details like注册资本7.7亿 and precise company name.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1078
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少成交量呈V型走势的信息，导致内容不完整；但没有引入新的矛盾事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1077
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific support measures from the市委市政府 and the overall tone of encouragement from韩立明.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1072
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details about the seizure of assets and does not fully capture the extent of the arrest as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1083
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有矛盾，没有遗漏重要细节，且长度相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1059
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the discussion of launching a market for NFT transactions and the involvement of Meta Platforms. The expected output incorrectly mentions Facebook and Instagram as the entities making the plans instead of Meta Platforms.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1074
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅包含了观看人次的信息，忽略了销售情况和地方特色商品等重要细节，且与预期输出的主题不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1088
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，缺少了关键的细节，如掉期价格显示加息可能性上升的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1086
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'最高人民法院'，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1092
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output includes deaths and injuries but omits the specific location and depth of the earthquake mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1084
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出基本一致，但缺少了净利润的具体范围和业绩预减的原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1079
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output does not contradict expected output but uses '将持有' instead of '受让', which is slightly less accurate.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1082
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了刘璐辞去董事会下属专门委员会职务的信息，以及公司副董事长陈明先生代为履行职责的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1089
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes all key details from expected output but adds more specific information about the timing of the event which was not in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1095
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits '有限公司' from the company name but does not introduce factual errors.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1080
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了火箭残骸的具体来源SpaceX和碰撞的具体时间，且来源信息由俄媒变成了美媒。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1085
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出漏掉了CEO辟谣的关键信息，且标题对消费者需求减少的原因描述不够准确，偏离了预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1096
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现事实上的矛盾，也没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1081
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason="Actual output omits key details such as the specific date of the release, the involvement of both Chinese and American factories, and the partnership with a '美国科创公司Nuro'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1087
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了一些事实信息，但并未完全符合预期输出的关键点，如未提及一季度或迎来蓝筹股配置良机等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1100
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the significant increase in case filings and the specific percentage growth mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1090
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details such as the company's internal control and risk management, and focuses only on a minor aspect of the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1111
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1106
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='缺少关于AI赋能新药研发的重要信息，且未提及具体合作内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1093
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中包含了加息次数的信息，但缺少了对2023年经济增长压力的提及，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1104
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出提供了确切的确诊病例总数，而预期输出则使用了约数，略显概括。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1098
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及评级下调的原因以及Meta广告收入增长放缓的信息，且未指出这是摩根大通分析师对于Meta评级下调的历史首次，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1097
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了一些未在预期输出中出现的具体信息，如加息幅度的讨论和美元指数的具体表现，导致输出信息冗余且偏离主题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1094
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在事实上的差异，实际输出提到外资私募规模不及50亿，而预期输出强调多数外资私募存续规模不足5亿元。实际输出忽略了外资私募管理规模的详细分布情况，且表述较为模糊。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1102
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出中未提及连续两年跌破1%这一关键信息，且未提及2021年净增人口创60年新低的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1103
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by stating that 3 companies will operate normally instead of the expected companies that will cease operations until 2022年3月15日.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1117
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='The actual output matches the expected output exactly, without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1116
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了预计输出中的关键细节，例如经济学家的具体观点和薪资数据的重要性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1107
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about Amazon's entry into physical retail and the specific nature of the store as a 'fashion store', reducing its accuracy compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1099
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts the expected output in terms of timing and details. It does not mention that the event is on the next day, and it omits the key information about the organizer being the State Council Information Office.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1101
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出中的事实与预期输出中的事实相矛盾，实际输出称北向资金净流出超140亿元，而预期输出称北向资金净流入近300亿元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1114
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现事实上的矛盾，也没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1115
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes specific figures but omits details about the contract sales area. The length is slightly longer without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1119
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了总投资金额20亿元的重要信息，但没有引入事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1091
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了软银不会出售阿里巴巴股份的信息，但与预期输出相比，信息出现了偏差，实际输出中提及了美国上市的存托股计划，而预期输出中仅提到软银未参与阿里巴巴注册ADS的事项，且实际输出信息比预期输出更详细但并不完全匹配。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1105
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出缺少了欧洲议会希望航司从2026年起为碳排放付费这一关键信息，且没有明确提到比欧盟最初计划提前一年的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1112
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the context of Nationalist Party's consecutive failures and the impact on supporters' morale, making it less accurate compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1109
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by mentioning '证券日报头版评论' instead of '经济日报' and does not reflect the expected focus on the size of the monetary policy tool box.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1113
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，遗漏了财报公布日期、预期每股收益、营收预测等关键信息，仅提及摩根大通的报告内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1108
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了缩表计划的回应这一重要细节，但与预期输出相比，提到了更多具体信息，包括分析师的引用和奥密克戎变异株的影响，这超出了预期输出的范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1122
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中省略了净利润的具体数值和增长百分比，但是没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1110
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了董承非下一站可能去私募机构的重要信息，且没有完全反映新闻中的不确定性（用词如“或”、“下一站‘奔私’？”表示不确定性）。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1120
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出存在事实上的矛盾，实际输出提到的是收益率普遍上涨，而预期输出则表明市场对美联储加息预期导致美债价格下跌，收益率曲线趋陡。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1124
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了东证指数的具体数值和市场中股票及板块的涨跌情况，且增加了MedPeer公司跌幅的信息，这与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1123
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出忽略了西方国家单边主义和中俄关系作为国际关系典范的重要细节，只提到了中俄关系超越传统同盟的部分。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1118
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the exact range of net profit (12.04亿元至12.99亿元) and the increase amount (4.83亿元至5.78亿元), leading to less accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1121
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出提供了额外的地点信息，即新增病例均在伊犁州霍尔果斯市，但并未减少准确性。不过，实际输出比预期输出多了一些细节，略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1130
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omitted the key detail that启源芯动力is a '绿电交通'领域综合智慧能源服务商, reducing its accuracy compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1126
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the lowest涨幅省份云南 and the total number of省份, leading to less accurate information compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1129
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '看望慰问受灾群众', missing important context from expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1133
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于去年全球钻石首饰需求量达到创纪录水平的重要信息，且未提及需求超过供应的具体背景和数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1131
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了过多细节，如人员受伤情况，而预期输出更简洁，侧重事故和系统暂停。实际输出偏离了预期的简洁性和重点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1137
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含的内容与预期输出不符，且省略了预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1132
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的具体薪资数额和调整详情，仅概括了薪资上调的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1134
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于虎年新能源行业基本面全面爆发以及避免短期频繁交易的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1127
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出准确地反映了累计确诊病例的数字，但未采用预期输出中的数字表示方法（亿为单位），略显不够简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1136
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the specific net profit range (5亿元-6亿元) mentioned in the expected output and input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1125
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by stating the ECB will raise interest rates in 2023, rather than indicating it still needs more than a year and a half before doing so.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1128
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了合资金额6000万元的重要信息，并且未提及公司股权比例，与预期输出相比信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1143
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contains additional details not aligned with expected output, making it less concise.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1144
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了预期输出中关于2022年下半年运价同比可能回落的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1135
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中提到的12月份的数据与预期输出中提到的2021年全年数据不符，且实际输出缺少了预期输出的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1148
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by providing only flight information and omitting passenger throughput details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1139
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了投资者的亏损金额和投资总额，但缺少了基金名称ARKK和基金运作时间等关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1146
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于外贸企业受益的具体信息，且未提及关税削减细节，与预期输出相比信息量不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1147
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the purpose of the mid-term notes, which is intended for commodity housing projects as stated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1142
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like '提高宏观政策前瞻性、针对性和有效性' and '形成稳增长合力', making it less accurate compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1145
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于打造世界级旅游景区的目标和具体创建活动等重要细节，仅提及了部分城市的支持措施。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1149
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比略显冗长，但未遗漏关键信息且无事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1150
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the contradiction of 'no new projects' and fails to clarify it as a false message, as expected.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1138
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键信息，但未完全匹配预期输出的表述方式，且缺少了对造谣者责任追究和呼吁公众不造谣、不信谣、不传谣的部分。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1157
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未提及股东名称，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1152
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于经济复苏面临的问题和国际货币基金组织的声明，且与预期输出的主题不完全吻合。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1151
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了日期信息和境外输入病例的信息，且比预期输出多了无症状感染者的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1141
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含天齐锂业回应网传的信息来源，略去了投资者交流会的内容，导致信息不完全；但总体上没有引入新的矛盾，且保持了简洁性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1140
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by stating luxury sales are above pre-pandemic levels, while expected output indicates a decline in luxury sales. Additionally, actual output lacks specific growth figures for affordable housing as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1153
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the number of cases by province and the number of deaths, deviating from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1158
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了营业收入和归母扣非净利润等重要细节，且表述方式与预期输出不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1169
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键人物吴清和提升全球资产管理中心建设能级的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1155
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the closing price of 58.00元/吨 and the consistency of the highest, lowest, and opening price throughout the day.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1162
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中净利润的具体数值范围，仅提到了同比增长的范围，缺少了关键的财务数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1156
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits specific actions mentioned in expected output, such as '严防病例回流社会', '严防疫情反弹', and '严防疫情输入'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1164
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output includes additional details about specific companies, which were not in the expected output, leading to a slight deviation from the concise summary expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1159
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了新闻的背景和官方态度，如'秀肌肉'的评论和美国海军拒绝评论飞机是否坠入南海，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1161
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅包含了WTI原油的信息，忽略了布伦特原油的相关数据，且并未提到7年新高的表述，因此遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1160
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了批发销售数据，但缺少终端交付信息；实际输出与预期输出在表述上略有不同，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1170
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出和预期输出在关键事实方面一致，但实际输出省略了‘比上年增长’这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1163
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关于大年初四预计发送76万人次和提前迎来返程客流的重要信息，且没有提及发送191.1万人次的具体日期范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1168
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific position of the incoming executive and the approval status, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1166
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了恒指上涨的信息，但遗漏了国企指数和红筹指数的涨幅，以及科技、餐饮和汽车股走高的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1154
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含停产的具体时间点和原因等重要细节，略显简略；但未发现与预期输出的事实性矛盾，且未引入新的模糊或矛盾观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1165
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output includes additional details about the patients being from a concentrated isolation medical observation point and their current status, which were not required in the expected output, leading to a slight deviation from the concise requirement.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1182
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少重要细节，如全面停止的表述和公司价值等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1175
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits crucial details like the cancellation of purchase restrictions on new energy vehicles and promoting support policies, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1167
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits information about the total number of new院士和外籍院士的数量、通用电气智能电网业务负责人McDonald John以及中国科学院院士方岱宁的入选。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1177
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及希腊国债收益率显著上涨和市场对欧洲央行加息前景的担忧，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1173
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了有关非法集资的具体描述，且未提及误导或怂恿非正常退保等其他违法违规行为，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1180
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含欧洲渡轮运营商的具体名称，且措辞略有不同，但未发现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1176
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output regarding screen size, stating 5.7 inches instead of the correct 4.7 inches.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1181
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Omits the key detail of profit growth and includes the month range in the title, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1171
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了议案的具体内容和联邦在半导体产业方面的支出增加，且未提及关键零部件短缺导致的供应链瓶颈问题，与预期输出相比，信息量不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1172
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the meeting between Russian and French presidents and Macron's belief in finding time for peace. It is also significantly shorter, lacking essential context from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1174
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the involvement of specific investors like Tencent and the amount they invested, and the interaction with蔚来资本、美团。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1183
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但用词略有不同。实际输出中没有提到'部分税收优惠政策'，略显笼统。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1186
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出省略了关于2022年订单已安排至年底的重要信息，仅保留了部分自行车行业的生产方式描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1179
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出和预期输出在关键细节上有所偏差，如指数涨跌幅和强势板块的具体描述不同。实际输出比预期输出略短，未能涵盖数字货币板块全天领涨的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1187
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了具体数字，但未提及超出预算预期的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1184
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于发达国家货币政策转向和国际金融市场脆弱性上升的重要信息，虽然没有出现与预期输出相矛盾的事实，但遗漏了关键细节导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1178
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的内容与中国央行副行长刘桂平在全球财富管理论坛上的讲话内容不符，忽略了大部分讲话要点，特别是关于展示开放姿态和深度参与世界经济合作的具体细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1194
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing unrelated stock market information instead of the expected index performance data.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1188
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by omitting key phrases like '减排不是减生产力' and '不搞齐步走、“一刀切”', which are important details.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1198
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on investment value rather than the trend of market segmentation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1200
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键细节，如总裁的职位和推进扩产的具体计划。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1192
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了拜登宣布防疫新规和呼吁民众积极配合的重要信息，仅提到了疫情对美国的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1197
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了预期输出中的具体价格变动信息，特别是碳酸锂的价格涨幅，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1201
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific amount of新增地方债发行和基建投资的相关信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1191
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the current capacity of 7 million head and focuses only on future plans, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1211
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning the company name and持股比例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1195
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键信息，但缺少了更名的具体表述，且比预期输出多了“重塑为”一词。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1199
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中缺少了具体的地点信息'广西百色市'，并且没有提及新增疑似病例的情况。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1196
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output contradicts expected output by focusing more on Alibaba's performance and omitting details about internet technology stocks and sectors that strengthened.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1190
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到取消部分关税，而预期输出更倾向于美国或放弃加征关税的表述，实际输出未完全传达预期输出的意图，且缺少对铝关税的提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1185
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了预期输出中的关键信息，但增加了'公司生产的KN95口罩有出口至欧洲市场'这部分，虽然这部分信息在预期输出中没有提及，但并没有直接影响主要认证信息的准确性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1204
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少发改委和商务部的支持，同时仅提及深圳方面的支持，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1207
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含预期输出中的净利润增长范围，但未引入新的矛盾信息，且增加了对公司产品市场需求旺盛的具体解释。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1210
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现任何矛盾或遗漏重要细节的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1202
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到2022年的计划和元宇宙探索，而这些是预期输出中的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1189
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于美国代表团抵达首都机场的具体谣言内容以及该谣言的具体日期，且未提及警方对造谣者的具体刑事措施，导致重要信息缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1203
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，忽略了关键的市场分析观点和分析师的评论，仅提到了鲍威尔的讲话对美元的影响，缺乏全面性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1193
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on a specific analyst's prediction rather than summarizing the news content about the potential impact of the Japanese central bank's actions on the yen.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1213
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出未提及公积金贷款调整的关键信息，与预期输出内容不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1208
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits critical details about the total income and growth rate of tourism revenue, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1212
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及减持比例的具体数值，且未明确说明是被动减持，与预期输出相比缺少重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1205
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了古巴和日本被列为最高风险区，但遗漏了135个国家和地区这一重要信息，并且没有提及风险区总数的增加。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1215
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了启动定增发行和报价日期的信息，但缺少询价发行方式这一关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1225
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'基本'一词，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1217
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出遗漏了预期输出中的关键信息，即疫情尚未终结，这降低了输出的准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1206
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了净利润同比增长的准确数据，但省略了净利润的具体范围（21.5亿-24.5亿元）和产品价格保持高位运行的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1214
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出准确地反映了累计确诊病例数，但未采用预期输出中的亿为单位的表达方式，略显不一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1209
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output introduces '开年以来' at the beginning, which adds unnecessary information compared to the expected output. The omission of this prefix does not alter the core meaning but adheres more closely to the expected output format.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1220
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the mention of a partnership with private equity firms and the initial report of a media source.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1218
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output in content and does not match the financial projections and company analysis provided in the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1216
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关键细节，如参与集采的具体品种和文件发布等信息，且没有明确指出是上海、浙江、安徽三地达成一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1219
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中提到的融资总额与预期输出的内容不符，且未提及销量暴涨的具体数字，忽略了'预期输出'中的关键信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1222
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the cumulative number of infected children and does not mention the total of over 10 million children infected since the pandemic began.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1232
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the specific cause of the price increase and the term '扩大涨幅' which highlights the extent of the price rise.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1221
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing only on parking facilities instead of城际充电网络和高速公路服务区快充站配套设施.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1230
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the amount of asset impairment provision and investment loss, and does not explicitly state that the asset impairment provision is reasonable.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1224
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks specific details about the leading role of贵州茅台and the market outlook, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1231
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了产品获批上市的关键信息，且表述方式与预期输出存在差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1239
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the critical detail that the 2000 vehicles cannot be sold temporarily.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1229
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits '核酸' before '检测机构', leading to a less accurate representation compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1227
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键事实，但是将莫斯科具体化为俄罗斯首都，而预期输出中仅提到俄罗斯，这与预期输出略有不同，但没有重大遗漏或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1234
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the specific mention of '加大纾困帮扶力度' and the name '徐晓兰', reducing its accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1236
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了基金的具体名称、募集规模和基金经理的信息，这些信息在预期输出中都有提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1228
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在事实上的偏差，未体现宽货币信号的强烈性，且未提及稳增长主线。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1223
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出中包含了净利润的具体增长范围，而预期输出较为简洁，未提及具体增长范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1244
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了挂牌转让的具体信息，且未提及转让价格和最终交易价格的确认方式。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1242
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details such as specific time and expected output's phrasing.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1237
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键信息，如1月15日起社会面没有新增病例以及社区传播风险逐步降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1235
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了收益率曲线趋平和支撑市场的具体因素，如大宗买盘、空头回补及美股下跌等细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1233
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出概括了春节期间消费市场的多个方面，而预期输出仅强调了冰雪消费迅速升温。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1243
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual Output matches Expected Output exactly, with no contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1241
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出提供了大部分预期输出的信息，但略显冗长且未提及生活水平冲击和避免第二轮通胀效应的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1248
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了投资的时间框架和扩充空调业务的具体细节，如研发和生产。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1250
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'公司'一词，但未引入事实错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1238
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出虽然提到了物价保持平稳运行，但没有具体提到CPI延续温和上涨和PPI涨幅回落的预期，缺少了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1246
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关键细节，如网络的具体长度5600公里，未能完全反映预期输出中的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1247
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits detail about the project location and land acquisition but does not introduce any contradictions or factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1240
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by providing detailed information about VR/AR devices instead of addressing the non-contrived '元宇宙' concept as required.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1245
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有包含预期输出中关键的3000美元价格上限信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1226
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的三花智控加仓市值超4亿元与预期输出中的阳光电源和北方稀土等10股获增持额超亿元不符，且实际输出遗漏了阳光电源和增持市值最多的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1254
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但缺少了非经常性损益对净利润影响的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1249
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了项目涉及的新老基建和智能制造等具体领域，且与预期输出相比信息量较少。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1252
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了预期输出的所有关键信息，但比预期输出多了具体指标的内容，导致略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1255
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要信息，也没有增加不必要的长度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1256
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了再次尝试打破僵局的重要信息，且没有提及未来投票的计划。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1259
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="缺少了'昨日'这个词，且缺少了具体的区域信息和感染者详情。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1251
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="Actual output omits the specific context of '硅片市场环境非常良好' and the time frame '预测首季' mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1264
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the continuous three-year growth mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1267
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了预期输出中关于4人为同一单位冷库装卸工的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1266
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中没有提及道路交通出行的平稳有序，遗漏了重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1261
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the specific subsidiary and the fact that it is an independent game developer, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1258
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在重要细节差异，实际输出未提及上调预测次数和具体数值，且信息量较少。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1257
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by mentioning 102 abnormal trading behaviors instead of 9 major matters of listed companies.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1263
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the original target price of 1800美元 and the stock rating information, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1262
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出增加了发布人的信息，这虽然是额外信息，但并未影响主要事实的准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1272
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the context of strict regulation becoming a norm and the specific details of the types of abnormal trading behaviors addressed.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1260
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出缺少了对生产经营环境变化和证券投资亏损原因的要求说明，以及股价下跌的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1265
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the specific context of financial transactions and does not mention the companies involved, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1269
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the expected title and the future position as the fifth largest airline in the US.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1271
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少知情人士的回应，且未明确指出被调查的是前总经理。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1274
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的是印度政府，而预期输出中没有提到具体的来源，且实际输出缺少了手机出口金额的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1280
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中省略了'部分经济强省'这一细节，导致信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1268
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了更多具体信息如会晤的具体日期和地点，虽然比预期输出详细，但未引入错误或遗漏关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1278
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了病例聚集发病的具体原因，如婚宴和母婴馆洗澡，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1276
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少了市场需要做好准备的重要信息，并且没有完全捕捉到预期输出中提到的多国央行可能表现活跃的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1270
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '货币政策靠前发力呵护市场资金面' and introduces a less accurate focus on '开门红', which does not align closely with the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1275
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了华尔街人士的观点，但遗漏了预期输出中的市场分析角度和美联储不会立即干预的具体描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1279
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少预期输出中的重要细节，即离岸人民币较周二纽约尾盘下跌44个基点的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1277
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output in tone and does not convey the importance of the event as a 'bottom signal', omitting key details about the significance and intention behind the self-purchase.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1273
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the responsibility of COO柯南 and the vision statement of 小红书, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1285
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了净利润增长的预期范围，但缺少了净利润的具体数值范围和毛利率提升的原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1284
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出提供了交易金额的具体值，但没有包括增长率和其他重要消费增长的信息，这导致了信息的不完全。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1283
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on local and nearby travel instead of the significant increase in winter tourism bookings.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1288
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about green transformation and clean production, focusing only on carbon trading market development.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1286
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于组合换电整体解决方案的具体信息，且未提及标准化换电的破局作用。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1289
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于加强网络巨头监管的重要信息，未能反映预期输出中的核心要点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1253
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了与期望输出相同的关键事实，但增加了北京科兴中维生物技术有限公司的合作信息，这一细节在期望输出中未提及。然而，由于实际输出比期望输出详细，尽管增加了信息量，但并未明确指出期望输出中缺失的合作方具体名称，导致准确度略受影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1281
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含基金浮亏信息但未明确指出涉及659只基金，且未提及股票重挫的具体细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1287
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了中小企业的裁员情况，只提到了上市公司的裁员，与预期输出相比信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1291
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了与阿联酋阿布扎比王储会谈的重要信息，且未提及双方将探讨的领域。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1282
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the detail about daily income of 10.07 billion yuan and does not mention the income slowdown compared to 2020.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1298
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了新增死亡病例的信息，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1295
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出提供了更详细的背景信息和解释，但比预期输出长且包含了冗余细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1292
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about expanding the company's explosives business scale and improving overall competitiveness, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1290
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details such as the major research and testing platform for quantum computing and the establishment of the provincial quantum information technology innovation center.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1297
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅包含外交部的部分回应，忽略了美日印澳四边机制外长会的具体讨论议题和完整的外交部回应。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1308
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了子公司名称和采用预制菜生产模式的具体细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1294
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了额外的信息，如合作推进延缓、累计盈利150万元等，而预期输出仅要求提及签署合同终止协议书，因此包含了不必要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1303
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及开发基于区块链的跨境证券交易系统原型这一重要细节，且与预期输出内容不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1293
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了会议效果的重要细节，如债券市场发行情况和融资成本降低的信息，且未能体现会议已见成效的关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1310
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关于回购股份的重要信息，仅提及了高管减持股份的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1305
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及具体的稳产保供稳价工作部署，仅提到了保障供应，缺少了预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1299
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未明确指出新公司为酿造食品公司，且公司名称为海天酿造食品有限公司而非直接说是海天味业成立的新公司。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1304
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出提供了具体的项目细节，但遗漏了项目资金来源和地理位置等重要信息，且比预期输出详细，但未显著增加价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1300
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了关键的投资金额和目的，但用词略有不同，强调了基础设施现代化而非改造升级。未包含预期输出中提到的数字化重点及其他细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1313
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少上汽集团投资的关键信息，且表述不够详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1307
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about total passenger numbers and fails to mention the specific days of the春运. It only covers the overall stability of passenger flow.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1296
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了美军抵达波兰的信息，但未具体指出人数为几百人，且未提及后续部队将在几天内到达，以及与罗马尼亚和波兰的合作演习计划。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1301
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了对未来运价走势的预测，未提及2022年运价高位震荡的可能性，且标题长度较预期输出更短，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1309
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了主要信息，但遗漏了宣布此决定的具体组织，导致准确性略有下降。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1319
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了北京市委宣传部的信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1312
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中没有明确提到葛兰旗下的相关基金，且表述较为模糊，遗漏了预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1318
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the number of recently投产屠宰场 and the total屠宰产能, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1317
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了重要细节，没有提到减税降费政策和财政超收的具体关系。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1321
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the threat to other political figures and the source of the threat, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1302
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="The actual output omits important details such as Lishuguang's previous position as the chairman of Wuliangye Group and his new role as vice chairman of the Economic Commission, which were specified in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1316
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出缺少了预期输出中的关键信息，如美联储加息预期和中国货币政策'以我为主、稳字当头'的基调。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1315
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出没有包含期望输出中的关键细节，如10名以上保守党议员提交不信任函，且未明确提及面临下台危机。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1314
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'业绩快报'和'同比增长4.26%'中的'同比增'，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1320
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes multiple product price changes but omits specific details about the decline in生猪（外三元）, as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1326
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the number of cumulative deaths and the precise wording for the cumulative confirmed cases as in '近1775万例'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1325
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及沪锡早盘涨超5%的关键信息，且未完全反映预期输出中的核心要点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1327
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'图像传感器（CIS）'的完整表述，但没有出现事实性错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1322
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只提到了对A股行情的看好，但没有包含预期输出中关于信贷开门红和市场反弹的关键信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1332
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the source of the news and the specific response from the White House statement.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1306
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the detail that the bonds are to be issued in both domestic and foreign markets, instead stating only '不超过1000亿元非资本补充性质的金融债券'. Expected output specifies '境外发行', but actual output does not mention the market location.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1323
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的是澳大利亚首席经济学家的观点，而预期输出是高盛的观点，两者来源不同且存在事实上的矛盾；实际输出保留了加息时间的信息，但来源信息有误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1333
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了欧元疲软作为推动因素这一重要细节，且内容概括不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1337
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了股东信息和注册资本等重要细节，未能完全符合预期输出的内容要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1340
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the '处于失联状态' part which is present in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1324
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了周江勇的具体职务信息，仅提到了他被开除党籍和公职，而预期输出中明确指出了他的职务以及违纪违法的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1328
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on a long-term price trend instead of the specific 2022 price trend as outlined in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1336
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未包含关于未设置房价红线的重要信息，且对预期输出中的动态价格指导细节有所忽略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1331
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了案件被立案的事实，但省略了案件归类为简单程序案件以及开庭日期等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1342
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于激发市场活力和支撑市场主体发展的信息，且未提及发布会的具体内容和目的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1339
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了会议部署的内容，但忽略了关键的打击行动细节，且比预期输出多出的信息并未提升准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1350
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without any contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1338
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出仅提及了部分信息，忽略了预期输出中的关键细节，如划分最小风险区的前提和疫情闭环管理的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1344
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及点火仪式开始，且未准确描述为冬奥会火炬传递，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1346
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the reason for potential emergency declaration and the timeline of events, leading to less accurate summary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1334
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中提到至少4人被困，但预期输出中提到已致4人被困，实际输出中没有明确指出人员伤亡情况，这可能导致信息不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1347
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了重要事实，但缺少了引用来源和具体的日期信息，且略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1311
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出在增长率上略有差异，实际输出为25.80%-67.74%，而预期输出为26%-68%，但两者实质上是一致的。实际输出省略了净利润的具体金额范围以及控股子公司业绩上升等细节，导致准确性略低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1330
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the winter peak demand, the specific date and time of the expected peak, and the historical context of the 200 deaths last year. It also introduces vague language without substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1349
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output captures the key message but omits some details from expected output and is slightly longer without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1353
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出一致，没有事实矛盾，也没有遗漏重要细节，长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1335
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details like the ranking among G7 countries and the comparison with the US. It only mentions the growth rate without providing the context of its placement among G7 nations as stated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1348
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及汇钧科技退出，仅提到厘铂信息科技有限公司成为新股东，缺少转让股权的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1345
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on 5G network construction instead of 6G technology research support and the development of the ultra-high definition video industry cluster.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1341
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中缺少了船舶类型'半潜式'和建造的具体公司名称'荷兰西特福船运公司'，这些信息在预期输出中有提及，但被省略。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1329
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了预期输出未提及的具体投资金额和项目名称，但引入了具体数字，这可能被视为冗余信息。此外，实际输出包含了预期输出中没有的重要细节，如总投资金额，但预期输出要求简洁，因此存在冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1352
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the mention of financing pressure and the expectation of accelerated capital supplementation, which are key details in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1357
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the total contract amount and the positive impact on future business performance.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1356
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by not mentioning the impact of the volcanic eruption on the future harvest.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1360
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中忽略了净利润同比下降16%的重要信息，导致输出不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1351
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了重要细节，例如市场震荡导致资金涌入低风险产品的原因，收益率高于货币基金的对比情况，以及具体的基金数量等，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1343
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了预期输出的内容，并添加了更多细节，但与预期输出相比，实际输出更长，且包含了一些预期输出中没有的重要细节，虽然这些细节有助于理解情况，但根据步骤3，应避免冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1368
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关于阳性检出的重要细节，且未提及国际邮件的相关信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1362
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中关于抛售将继续的重要信息，且没有体现交易员的预期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1354
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了子公司的中标信息，但省略了具体的子公司名称仪电鑫森，且将装饰提升工程一并提及，与预期输出略有差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1365
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts the expected output regarding the date of implementation and omits specific details about the type of services affected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1355
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the release of production capacity and the predicted decline in silicon material prices, focusing instead on the current price and growth rate of the photovoltaic industry.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1364
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中遗漏了投放点的数量和设立的具体企业信息，且未提及统一投放时间，导致信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1358
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了'部分车辆被曝减配'这一重要细节，且特斯拉中国客服的具体回应措辞与预期不符。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1363
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中的关键细节，如会议的具体内容和日期，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1376
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the growth rate of 20.4% mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1359
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了股份数量的具体数字，而预期输出中明确指出了240万股，这使得实际输出在准确性上有所欠缺。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1361
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on year-over-year growth instead of month-over-month growth, and omits the specific details of the sales volume and price changes.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1366
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中未提及冬奥会外汇账户开立和资金汇兑的重要信息，且与预期输出相比略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1370
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了连续10天无新增病例的信息，但遗漏了中风险区降为低风险区的重要信息，且与预期输出内容不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1373
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出没有包含轻微症状和自我隔离的信息，且使用了'新冠病毒检测'而非'核酸检测'，略显信息不足和不精准。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1372
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于欣旺达电池缓解电池产能紧缺的重要信息，且未完全概述新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1377
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了封闭管理和村屯的具体措施，且未提及网格化管理等内容，仅包含了居住人口和禁止行为，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1382
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了增加的人口数量和流动人口的具体数字，且没有体现人口超过5亿的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1371
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出与预期输出存在细节差异，实际输出中的降幅数据为27.4%，而预期输出中的降幅数据为31.1%，且实际输出未提及具体车辆类型产量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1378
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含现总统马塔雷拉获得最高票的事实，且未提到选举无果的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1390
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1380
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了大商所和郑商所的具体名称，且包含的信息远少于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1367
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中仅提到了疫苗接种要求，忽略了输入中关于本周末有12个航班、200多名涉奥人员进入北京的重要信息，且与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1375
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，虽然包含了主要信息，但具体数字和时间表述不够准确，且忽略了引述专家的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1379
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了俞建华强调的加强双边务实合作和推进协定全面实施的重要细节，仅提及了高品质地理标志产品，未能全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1374
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits specific details about the market performance and the suggestion for improvement, focusing only on the '一头热一头凉' phenomenon and the need to remove obstacles.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1383
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key information about multiple Canadian investment banks and their expectations for the Bank of Canada's policy, focusing only on the general direction without specific details.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1392
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1381
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出内容基本一致，但缺少了具体地区（大阪府和东京都）的确诊病例数细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1389
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the climate financing target and timeframe, focusing only on the private sector investment goal.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1384
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes the growth percentage but omits specific net profit ranges and the detail about the increase in non-operating profits. The length is slightly longer without substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1391
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key information about the risks of climate transformation and the potential impact on inflation mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1393
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without omitting any important details or introducing contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1387
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于1.3610水平的重要支撑细节，且未提及看跌旗形的形成条件。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1388
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出不符，忽略了全资子公司签署协议的关键信息，且未提及具体的终止契约协议书。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1396
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未能完全反映预期输出中的关键信息，如白宫发言人的身份和对乌克兰美公民的具体措施。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1397
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键信息，即美国的目标是通过乌克兰遏制俄罗斯，这与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1369
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出内容基本一致，但用词略有差异，实际输出中使用了“净利同比预增”而预期输出使用了“预计净利同比增长”，虽未完全符合预期输出但未引入事实错误或重要信息遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1400
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了配股的具体原因和1月26日继续停牌的信息，且表述不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1385
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by mentioning an institutional analysis instead of a specific prediction by the strategy analyst. Additionally, it omits the specific detail about the economic change mentioned in the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1399
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific percentages and the leading positions of both provinces, less accurate than expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1395
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含办公厅字样，而预期输出中没有，但未发现其他重要细节遗漏或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1386
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出的主要区别在于数字的格式，实际输出使用了完整的数字形式，而预期输出使用了简化形式。虽然实际输出没有遗漏重要细节，但数字格式的不一致可能影响理解。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1398
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，但实际输出提供了更多的背景信息，虽然这些信息对于摘要来说略显冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1412
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了关于开发炼钢脱碳解决方案的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1402
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容完全不同，实际输出提到了美国农业部的报告，而预期输出则是关于芝加哥小麦的价格上涨。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1394
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中包含了中国船舶集团超越韩国现代重工的信息，而预期输出没有这一细节，导致信息量超出预期；同时，预期输出中的'十四五'开门红这一关键信息在实际输出中被遗漏。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1405
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details about the context of the Fed's expected tightening and the expectation of China's monetary policy independence.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1411
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与期望输出相比略长，但没有引入事实性错误或遗漏关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1406
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了打造特斯拉软硬件生态链的重要信息，并且没有提到业内专家的观点，内容较为简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1407
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中未包含预期输出中对净利润的具体范围（3.3亿元-3.5亿元），且增长率的范围略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1409
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了子公司名称和采购量的具体信息，但与预期输出相比，提供了更多细节，导致信息冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1404
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes additional details about El-Erian's full title and the reason for the need, which were omitted in the expected output, making it less concise.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1403
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了中标京东方重庆第六代AMOLED（柔性）生产线项目的具体信息，但预期输出中并未提及重庆的具体位置，导致信息量略多。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1415
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含财信证券IPO进入辅导期这一重要信息，且表述过于简略，缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1408
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出在数字上略有不同，但并未出现事实性矛盾。实际输出略去了同比增长的具体数字范围，略显不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1420
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了全球经济复苏动能持续减弱的重要信息，且未完全匹配预期输出的语义。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1418
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the year and specific details about the original plan of public ticket sales, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1417
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="Actual output omits key details about the water dam's alert level changes and the number of displaced people, focusing solely on the death toll.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1410
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了部分预期输出的内容，但遗漏了关于促进技术规范健康发展的核心信息，并且标题采用的是人民日报而非人民时评，与输入内容不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1401
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing a market size of 7.6 billion dollars, while the expected output specifies a size of 3.2 billion dollars for the first half of 2021.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1419
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出缺少了罚款金额的重要细节，且没有完全传达出向未满12周岁儿童提供服务的具体处罚措施。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1428
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by providing an incomplete financial summary and introducing a stock price change not mentioned in the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1422
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含北外滩核心区地块股权的具体售价信息，也未提及已经抵押的项目，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1421
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output includes more details than expected output, such as the date and additional context about the visit, which were not present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1424
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中未提及乌克兰紧张局势和MSCI全球股指下跌等重要信息，且比预期输出更加模糊，缺少具体细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1423
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有提到俄外交部发言人扎哈罗娃，且缺少了新闻中关于普京不参加的明确声明，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1416
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出的差异在于免费核酸检测的描述顺序和是否包含时间安排。实际输出没有包含具体时间，但没有引入事实错误，只是略去了细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1425
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出内容基本一致，但顺序略有不同，未提及连续三天刷新最高纪录，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1436
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了LPG的跌幅信息，且没有提供其他具体品种的下跌情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1426
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by focusing on a specific action item ('坚决杜绝重复资助等') instead of the main objective ('加强专利申请行为精准管理').", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1413
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output contradicts expected output by not mentioning the OKR for personnel optimization and the departure of the vice president. Additionally, it omits important details such as the order of product and technology layoffs and the confirmation from multiple insiders.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1427
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提及了玉米期货的下跌和投资者的担忧，忽略了其他谷物期货的价格变动，且用词不完全准确，未明确指出芝加哥期货市场。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1432
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the reason provided by the company about the market entering a relatively reasonable valuation range, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1429
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关键细节，如11月可能正式采用比特币的时间点和法案提交时间范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1438
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未提及总投资额6亿元，缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1430
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含了新闻的核心事实，但使用了更详细的描述，如'中国首条跨海高铁'及'新建福厦铁路'，而预期输出较为简洁。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1435
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容不符，来源和评论内容不同，存在重要细节的缺失和偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1433
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到调整封控区、管控区及防范区范围，但未提及解封信息，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1431
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by providing additional details not aligned with the expected concise summary. Expected output was shorter and did not require details about transaction functionalities.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1437
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未能包含预期输出中的关键细节，如北向资金累计净流入的具体金额，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1414
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on '加快上市步伐' (accelerating the pace of listing) instead of '销量攀升' (sales climbing) and '忙扩产' (busy expanding production), omitting key details about the increase in sales and the urgency of expansion.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1445
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出省略了关于公共预算收入和城乡居民收入增长的重要细节，且与预期输出相比略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1453
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了重要细节，如同比增长的时间点和占全国的三分之一，降低了准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1441
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the specific area and road boundaries mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1448
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了投资金额和开发计划的重要细节，且未提及未来五年的投资计划和目标。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1455
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='缺少预计投资额60亿元的具体信息，但未发现实际输出与预期输出之间存在矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1456
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未提及收购的7个印尼地热项目，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1457
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了广西凭祥的具体地理位置信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1440
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含预期输出中的关键信息，即实现社会面和隔离点双清零的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1434
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about the Chinese embassy's response and the relationship between China and Tonga, and does not mention the发言人's name or the context of answering a journalist's question.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1439
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有与预期输出中的事实相矛盾，但省略了关于奥密克戎毒株可能降低未来疫情严重程度的具体细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1449
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了环比增加的信息，而预期输出没有提到这一点，导致实际输出比预期输出多出一些细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1443
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，引入了关于机构分析的额外信息，且忽略了预期输出中的关键事实，如油价持平和关于增产的传闻。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1464
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出缺少关键细节，如具体金额和对华出口增长率。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1451
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中包含的信息与预期输出不符，忽略了对业务没有影响这一关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1460
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits details about the uncertainty of impact and the company's response to the situation.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1454
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by stating an increase in net profit when the expected output indicates a decrease.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1446
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by mentioning Guangzhou Nansha instead of Zhuhai, and it omits the upgrade of the entire Nanshan Town to a controlled area.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1458
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the trial activity ending and only partially reflects the optimization efforts mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1447
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含预期输出中的关键信息，如钢铁领域重组整合和适时组建新的中央企业集团，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1452
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific inflation rate of 48.69% mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1459
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，无任何矛盾或重要细节遗漏，且长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1450
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the ticker BYND.O and details about the price target and developments in food service, resulting in less accurate information compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1465
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到新增7例境外输入性病例，但未提及无新增本土病例这一重要信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1461
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了托卡耶夫的名字以及对中国经济成就和合作领域的具体描述，这些是预期输出中提到的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1442
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，但预期输出中净利同比增长范围为65%-84%，而实际输出为65.42%至83.80%，略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1467
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the year and the comprehensive economic growth goals mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1468
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了完善管理服务的重要细节，且未提及健康监测期间的相关要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1484
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output precisely without any contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1463
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预中标的信息，但缺少了中标金额的具体数值，而预期输出明确提到了1.73亿元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1474
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少签署合同的关键信息，且未提及交易对方，与预期输出相比不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1477
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits important details like '中国银行战略合作方' from expected output, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1462
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="The actual output omits the key phrase '助力有效投资' and does not fully capture the expected output's message about PPP market development and its contribution to effective investment.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1470
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的是2019年的数据，而预期输出是2021年的数据，时间线不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1471
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes specific details about the fund name and the exact amount, but omits the date range. The length is slightly longer without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1444
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on Liang's attendance at a hearing about stable coins and crypto intermediaries, while expected output emphasizes the need for more regulation of crypto intermediaries. Actual output also omits key details such as Liang's full title and the specific points of discussion.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1481
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了访问有研集团和强调自主创新的内容，且没有提到稀土产业链的全面可持续发展。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1476
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了项目一期竣工的具体描述，且用词与预期输出存在差异，未能准确反映项目内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1472
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不一致，实际输出仅提及新增病例数，而预期输出需包含累计确诊病例数。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1478
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中的关键信息，如所有船型运价下跌和指数终结4连涨的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1480
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了发射次数等重要细节，且未明确指出这是今年朝鲜的第四次发射。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1485
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了黄河区域的内容和整体高质量发展的目标，仅聚焦于长江经济带的部分目标，不符合预期输出要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1466
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output contradicts expected output by focusing more on expert opinions rather than the factual market expectations and the specific action of monetary policy adjustment. Additionally, it omits key details like the specific rates and the scale of operations mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1488
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了新闻的关键信息，但比预期输出多了一些描述，略微偏离简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1483
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的细节不符，忽略了预期输出中提到的国库券供应前景不明的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1487
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，未提及具体标准名称，且包含额外信息，导致偏离主题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1494
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output and expected output match closely, with no contradictions or omitted important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1482
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅有细微差别，未引入事实错误，但实际输出比预期输出多了一个空格，稍显冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1490
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含新能源汽车市场发展及产品盈利水平提高等重要信息，且表述略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1489
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the specific amount of 1800万美元 and does not mention the cooperation with other institutions as detailed in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1479
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的原因是教职人员短缺，而预期输出中提到的原因是新冠病例激增，两者原因不一致。实际输出未包含预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1473
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the implementation of positive fertility support policies and the improvement of birth and education costs, focusing only on the number of childcare positions. Expected output includes details about improving fertility levels and maintaining a balanced gender ratio.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1469
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出内容基本一致，但实际输出中的'将2022年人道主义援助预算增至15亿欧元'略微改变了语序。此外，实际输出没有包含导致援助预算增加的具体原因，如疫情、气候变化等，这使得信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1475
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提到德银的政策路径分化导致美股回调和中国市场提振，但预期输出中强调的是德银加入唱多中国股市行列，料美国股市将进一步下跌。实际输出缺少了预期输出中关于德银唱多中国股市的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1486
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the decline of the hot tracks and the cooling of profitability. The expected output also highlights the awkward moment in the market, which is not reflected in the actual output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1491
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出遗漏了前五大贸易伙伴的具体信息，只提到了对'一带一路'沿线国家的贸易增长情况，与预期输出不符。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1497
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the total investment amount of 5 billion yuan but does not contradict any facts from the expected output. The length is appropriate without unnecessary details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1499
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output includes the sales figure but omits the market forecast and the adjusted EBITDA details mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1492
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中提到的诉讼和指控与预期输出一致，但使用了不同的措辞。实际输出中未提到'不当获取'这一关键细节，导致信息不完全一致。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1502
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits specific details such as the names of the clinics and the type of penalty, while maintaining the core information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1509
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了持有期不少于一年的重要信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1504
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键信息，但包含了超出预期输出的地点细节，导致略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1503
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中的“多国新增确诊病例数破纪录”这一关键信息，导致重要细节的遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1493
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the price per share and total number of shares, and introduces a contradiction by stating a total amount without specifying per share details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1496
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="The actual output omits important details such as Sumco's specific booking of future production and the timeframe mentioned in the expected output. The actual output is also vague and does not capture the core message of the news accurately.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1506
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出缺少了具体的地点信息'安徽'，但未发现事实上的矛盾或冗长无价值的内容。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1498
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到春节假期缩短至三天，但未提及具体公司名称兰花科创，且将地点误认为陕西，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1501
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了敦促美国国会的内容，但忽略了声明的具体批评和不满的原因，且缺少对法案涉华内容的描述，因此遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1508
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及不良贷款率和拨备覆盖率的重要信息，且净利润增长比例与预期输出略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1507
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits key phrases like '情绪底'和'市场底'共振, which are present in expected output and crucial for conveying the full context.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1500
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于北上深上车价超过300万元的重要信息，且未提及新一线和二线城市的房价变化情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1516
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少重要细节，如停航的具体日期和涉及的中山航线，且长度较短未提供完整信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1512
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about the vaccine's efficacy and the specific antibody level it achieves, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1513
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output omits important details from the expected output and does not align closely with the input content.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1495
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes specific financial range and additional details about growth rate, but omits key details such as ad and operator revenue增速均超过30%，年末芒果TV有效会员数达5040万，同比增长40% from expected output, leading to less accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1515
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="实际输出中只提到了部分信息，遗漏了深交所要求说明是否存在蹭'元宇宙'热点概念的情形，且与预期输出不符。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1510
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未包含本财年的销量预期低于预期的具体数字330万台，且未提及索尼的原销量预期，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1514
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes slightly different wording and additional details compared to expected output, but does not introduce contradictions or omit key information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1521
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1505
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及了下载量超过2000万次，但未包含冬奥会期间消费者选择软硬钱包的细节，且比预期输出更简略，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1511
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes unnecessary details about '长津湖之水门桥' being the box office champion, while the expected output only mentions the total box office revenue exceeding 45 billion.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1518
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出没有包含扩招1000名审核人员这一重要信息，且提供的信息比预期输出更详尽，但缺乏关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1524
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about planned large-scale joint projects mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1533
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1519
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output misses the distribution map of the 118 cases and only partially matches the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1517
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及利用区块链等现代信息技术推进银行函证数字化转型工作，遗漏了预期输出中的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1520
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容不符，实际输出仅提到了分析师对奈飞市盈率的怀疑，而预期输出则是分析师将奈飞的评级下调，两者信息不一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1525
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含关于疫苗生产商辉瑞和临床试验首席研究员的具体信息，略显细节不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1534
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中未包含预期输出中的'进一步优化市场竞争环境'这一重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1526
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output lacks specific source attribution and details about the location of cases, contradicting the expected output's mention of the National Health Commission.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1539
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了多数ETF上涨的重要信息，且没有提到具体的涨幅。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1540
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1523
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比，包含了公司名称的细节，但省略了这些具体的公司名称。长度上，实际输出更简洁，但略失细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1531
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但增加了不必要的细节，如具体的日期和描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1537
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='遗漏了试剂盒在德国和奥地利等欧洲国家销售的信息，仅提及未出口到美国和印度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1528
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes the key points but omits mention of the French nationality of CMA CGM and the specific agreement details. The length is appropriately concise.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1535
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中提及了美联储将在3月开始加息，但未提及加息次数高达7次的重要信息，且来源信息不一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1530
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但使用了'暴露于新冠中'而非'怀疑感染新冠'，导致表达稍有不同。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1527
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by including information about医药外包概念股跌势 which is not mentioned in expected output, and omits关键信息如地产股和有色金属股的普涨。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1536
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了2019年的恢复比例，但遗漏了与2021年相比略有下降的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1529
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output does not match the expected output content. It summarizes the leading industries in terms of growth rate, while the expected output seeks to list the top inflow stocks in the building decoration sector.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1552
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，遗漏了光伏订单增加的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1522
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出包含了具体的日期2023年1月，而预期输出中并未提及具体日期，反而使用了更模糊的表达'尽快'。实际输出并未遗漏重要细节，但包含了预期输出未提供的信息，导致与预期不符。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1547
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了预期输出的内容，但添加了更多细节，导致信息量超出预期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1542
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键信息，如专家预测和基建投资同比增速达到6.0%的具体数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1545
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits critical details about market risks and the expected conflict between future developments and current expectations, as indicated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1549
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing the growth rate for December 2021 instead of the annual growth rate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1544
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少比亚迪和招商银行的净买入信息以及赣锋锂业的净卖出信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1541
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未能包含预期输出中的关键信息，如已签约数字人的流量较小以及商业价值和变现能力的不确定性，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1556
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少关于双面太阳能电池板和恢复进口关税的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1543
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="Actual output omits key details about the expected inflation rate dropping below the ECB's 2% target in 2023 and focuses on a different aspect of the speech.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1538
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含的部分事实与预期输出不一致，如未提及验证购买打折产品的信息。同时，实际输出中包含了一些预期输出中没有的信息，如reddit上的讨论。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1551
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含新增确诊病例数，但遗漏了累计确诊病例数和新增死亡病例的相关信息，且比预期输出多了不必要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1558
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出不符，缺少关键细节，如有利条件增多的表述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1566
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits critical details about the ongoing engineering project and focuses on unrelated information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1532
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中提到世贸组织认定美国对韩产洗衣机措施违规，但没有明确指出是关于进口关税的问题，且使用了'保障措施'这一不明确的表述，与预期输出中明确的'进口关税违规'不符。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1546
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了比预期输出更多的细节，但没有提及这是俄法总统在7天内的第三次通话，且包含了一些预期输出中未提及的关于明斯克协议的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1555
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的内容不符，缺少了关于最小风险区的前提条件和奶茶店的具体信息，且没有提到精准防控的要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1550
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出存在事实上的分歧，实际输出强调了开门红回款快和库存低，而预期输出的重点在于估值消化后配置价值凸显及建议增持的三条主线。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1565
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分预期输出的信息，但遗漏了关于计提大额减值的原因和合理性的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1553
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by discussing corrective policies and the real estate industry instead of focusing on the growth pole of the rental housing market as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1559
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关键细节，如油价飙出7年新高的信息，且整体表述不如预期输出具体。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1568
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='标题与预期输出不符，缺少鼓励引导商业航天发展的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1548
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output contains relevant information but omits key details such as '第二波已开启', '一季度为黄金配置期', and '上半年比下半年好', which are present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1570
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'总经理'这一职位信息，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1561
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于正式注册和运营公司的关键信息，且未提及具体细节如管道段长度和终端位置。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1567
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes specific details about product income percentage and product names which were not mentioned in the expected output, making it less concise.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1554
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出与预期输出仅在用词上有细微差别，未引入事实错误，也未遗漏重要细节，但根据预期输出的表述，建议使用'可离开'来保持一致。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1557
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了额外的信息，即进一步购回债券的过程，而预期输出则较为简洁。尽管实际输出增加了信息量，但并未违反评估标准。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1560
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output contains the key information but omits details about the joint venture with Hainan Creation and the project timeline for construction access, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1562
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits details about '群雄逐鹿' and the involvement of '造车新势力', which are highlighted in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1564
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as total investment amount and project count, focusing only on the issuance of the list.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1569
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了涨价的具体金额和对公司业绩无影响的原因，且标题没有明确提到网传涨价的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1563
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含期权交易和Reddit平台的相关细节，略显简略；但未出现事实性错误，且长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1571
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出相比，省略了CPI的具体月份和科技股跌超反弹的具体表述，略微减少了信息的准确度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1577
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只提及了管理人员的晋升，忽略了组织结构调整和全民K歌的相关信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1574
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'厦门市统计局官网'中的'官网'一词，导致信息不够完整；但没有引入事实错误，且长度适当。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1572
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits '疾控中心' and uses '流感样病例' instead of '流感病例', but still conveys the key information of the percentage increase.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1573
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了关于对进返京风险人员进行落位管控的重要信息，仅提到了倡导跨省通勤人员居家办公，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1596
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了联合工作组有效磋商的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1581
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于美国出口管制的具体信息，且未提及高管的回应。虽然提到了供应商，但缺乏预期输出中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1576
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中没有提到新兴市场将面临的挑战，且未完全反映专家意见。但总体上，它传达了美联储加息预期及其对我国跨境资金流动的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1583
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出仅提到了部分内容，忽略了预期输出中关于'开门红'四个条件具备的事实，且未提及这些具体条件。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1592
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中遗漏了工人被解雇和转移的信息，且没有提到受影响的工人数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1585
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits key details such as Meta's name, Zuckerberg's potential imprisonment, and the specific law mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1587
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes all key points from expected output but adds unnecessary details. The length is slightly longer without substantial added value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1578
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与期望输出的内容不符，实际输出强调的是中央对地方转移支付的增加，而期望输出的重点在于合理安排地方政府专项债券和保障重点项目建设。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1582
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the number of countries that failed to meet the target and the specific mention of African countries, focusing only on the vaccine gap.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1584
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the precise percentage growth range (9.69%-16.47%) mentioned in expected output, instead providing a rounded figure.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1580
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了提高政治站位和落实调控政策的重要细节，仅提及了建议房企合理控制金融杠杆和积极销售回款，未全面反映预期输出中的关键建议。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1590
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了药物已经上市的重要信息，且比预期输出更为简略，未能完全反映预期中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1597
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks important details such as specific fund allocation and the names of the participating entities mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1603
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits information about considering stable stock price schemes, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1594
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出与预期输出相比，忽略了'控股子公司'和'十四五'规划重点项目的重要信息，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1595
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了疫情影响和服务贸易逆差的具体原因，且未提及留学等跨境支出下降的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1579
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出提供了具体的同比增长百分比5.5%，而预期输出只是描述了同比增长是稳定的，没有提供具体数值。虽然实际输出提供了更多信息，但与预期输出相比，它更具体，而非仅仅描述增长状态。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1591
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中缺少了关键细节，如投资的具体位置和涉及的工厂数量，但未出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1602
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了程磊的职务信息和减持股份的具体数量，降低了准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1575
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有直接回答新闻内容中的主要矛盾，即汽车制造商与芯片制造商对未来芯片短缺缓解时间的不同看法。实际输出只提到了缓解和持续紧张的情况，但没有体现出两种不同立场的对比，与预期输出对比明显缺少重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1589
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的关键信息，但添加了不必要的细节，如来源和统计机构名称，导致略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1598
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及了电网投资突破5000亿元，而未涵盖新型电力系统建设加速和电网投资快速增长的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1593
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出与预期输出相比，省略了具体的反倾销措施和相关企业的信息，且表述更为简略，缺乏详细内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1606
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing additional unrelated details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1586
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了阿里巴巴和杭州瀚云投资合伙，但遗漏了注册资本8亿元的重要信息，并且将杭州灏星企业管理合伙企业描述为合伙成立，与企查查提供的信息不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1599
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '硅谷风投大佬' and does not match the expected output's description of Peter Thiel.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1605
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits details about in hand orders and timeframe, reducing its accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1607
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Omits critical details such as the fund being the largest globally and the seven consecutive quarters of growth.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1588
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出与预期输出在细节上有所不同，例如实际输出提到的是所有类型的公募基金，而预期输出特别指出了权益类基金。实际输出中提到的均衡配置成为共识，而在预期输出中并未提及这一点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1600
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未详细列出地方债发行的具体计划量，且未明确指出发行量超过1700亿元，与预期输出相比，缺少重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1604
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实上的矛盾，没有省略重要细节，长度也一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1601
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key entities like '中国外运', '招商港口' and '中国重汽', and does not accurately reflect the partnership details as expected.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1611
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出包含了新闻的部分内容，但遗漏了保荐人和财务数据等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1609
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了券商发布的投资组合及策略观点，但缺少了行业‘茅’推荐次数较多这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1614
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分信息但未提及发放失业保险稳岗返还资金的具体数额，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1608
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the initial 2022 hydrogen demonstration project and the detailed timeline for the renewable energy installation, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1618
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中缺少恒生指数的具体收跌幅度和本周累计涨幅的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1610
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="Actual output omits details about the current grinding bottom phase of A股 and the support from the central bank's loose monetary policy and advanced infrastructure measures.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1625
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了更多细节，但与预期输出相比长度过长，且未精简关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1616
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'新房预售资金'的具体描述，但未引入事实性错误，整体简洁但略显模糊。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1615
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output contradicts expected output by omitting the term '新冠病毒核酸检测阳性感染者' which is more specific compared to '核酸检测阳性'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1622
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少预期输出的重要细节，例如积极研究和编制磁悬浮郊环线以连接五个新城的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1613
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '上海口岸汽车出口延续高增长态势' and '外高桥海通码头', leading to less accurate representation.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1638
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了净利润的具体范围和业务增长的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1629
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks details about the specific models and timeline mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1621
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但稍微冗长，包括了预期输出中没有提到的细节，如投资产品的类型。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1630
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了证监会核准股权转让的重要信息，且表述过于简略，未能准确反映新闻的核心内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1623
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在来源上不一致，实际输出标注为人民日报钟声，而预期输出标注为新华社。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1619
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason="实际输出没有包含预期输出中的'千亿件'时代来临这一重要信息，同时实际输出中的内容相对较短，但主题信息基本一致。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1636
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出省略了汤加遭受火山灾害以及出发时间的重要细节，降低了准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1624
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，未发现任何事实上的矛盾，也未遗漏重要细节，长度也完全匹配。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1626
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了实际控制人的姓名高晶和持股比例，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1612
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少预期输出中的关键投资方名称，如绝味食品、洽洽食品等，且未明确指出这些公司对书亦烧仙草的投资是间接的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1634
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提到了部分股票的表现，遗漏了山水比德大跌11%的重要信息，且整体信息量不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1620
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the date, time, and specific impact on local tide stations. It also lacks the expected conclusion about no impact on China's coastal areas.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1628
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出的内容与预期输出的内容不符，实际输出没有提到预期输出中提到的关键工程开工建设的信息，且实际输出的内容过于简略，没有涵盖预期输出的主要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1627
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the detail that SK创新和福特汽车是合建电池厂，但没有引入新的矛盾信息或增加冗余内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1639
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the total number of launches and success rate of the Long March rockets, as specified in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1631
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key financial details such as the total amount insured and growth percentage, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1617
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on the overall performance of the banking index and the increase in institutional research, while expected output emphasizes the persistence of the investment logic in bank stocks and the frequent research conducted by institutions at the beginning of the year.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1633
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现任何事实上的矛盾或重要细节的遗漏，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1646
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了净利润的具体数值，且增幅的表述略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1635
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅包含了中方的回应，忽略了新闻中的关键信息如乌克兰请求美国部署萨德反导系统及其背景，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1632
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中提到的是深圳发布金融高质量发展'十四五'规划，而预期输出则是《深圳市金融业高质量发展'十四五'规划》正式发布，实际输出缺少正式发布的具体表述，且未涵盖预期输出中的正式发布这一重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1644
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了预测票房和市场热度等重要信息，且表述不如预期简洁有力。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1643
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key information about the number of new banks and the total count of pilot banks in both regions, as required by the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1647
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="Actual output omits the location '广东珠海' and does not specify the region within珠海, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1642
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了幻方量化及其员工和股东总共筹集的3.5亿元自购资金的关键信息，且未提及反驳量化机构集体平仓导致市场下跌的谣言。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1655
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了沈阳铁路公安局的来源信息和具体的违法行为，但未出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1649
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但缺少了关于通胀数据具体细节的提及，如通胀数据的具体数值和影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1650
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少预期输出中的关键细节，如标普500指数可能再跌8%和抄底过早的建议。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1640
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关于动力煤保供稳价常态化的重要信息，并且用词与预期输出相比较为模糊，未能准确传达预期中的稳价目标。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1651
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on a different aspect of the news, omitting important details about reducing purchases of foreign goods during high pandemic periods.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1659
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the specific net profit range and the significant decrease in non-recurring profit, but does not introduce factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1658
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the specific date and the origin of the news, but does not contradict any facts in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1653
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，缺少了理性看待财政超收现象的关键信息，且增加了不必要的细节，导致输出不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1664
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='省名称被前置且未提及关键详情如生产任务和项目进展，输出信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1660
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含辽宁和新疆新增本土确诊病例的具体数字，遗漏了关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1645
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了江苏省取消地方金融资产交易中心的信息，但遗漏了具体叫停业务的三家公司的名称，并且实际输出中的数字4与预期输出中的数字3不符，导致信息不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1667
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少韩国KOSPI指数的具体跌幅信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1641
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了8000万人收到警报和近5700个航班延误的信息，但遗漏了航班取消的具体数目，且表述与预期输出相比信息量较大，未精简。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1666
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了注册资本增幅的具体百分比，即25.71%，这导致信息不完全。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1656
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like '一墩难求', online sales being sold out instantly, and long queues at offline stores. It only captures a minor aspect of the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1654
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details from expected output, including '谈第四针疫苗' which contextualizes the statement. The actual output is also shorter but misses the essential context provided in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1648
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出内容基本一致，但实际输出中的表达稍显冗长，未使用连词连接两个信息，而预期输出使用了“和”将两个信息连接，更加简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1669
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于经济下行压力和跨周期调节力度的关键信息，仅提及了部分政策细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1665
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the number of companies involved and the specific salary range mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1663
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the detail that the company was 'invested' by China Telecom, as stated in the expected output. Otherwise, it aligns well with the input.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1657
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了一些预期输出中未提及的重要信息，如严防“地条钢”死灰复燃，但遗漏了预期输出中强调的坚决遏制钢铁冶炼项目盲目建设的关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1637
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的事实与预期输出中的事实不一致，实际输出只提到了79%的人预计通胀会升至‘一定程度’，而没有提及大约一半的人预测通胀会‘大幅上升’。此外，实际输出中缺少了对美联储政策决议的提及，这是预期输出中的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1662
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了会议通过的细节及债券的原付息日和宽限期信息，且用词较为简略，未能全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1661
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出的主要内容一致，但对增长范围的描述略有不同。实际输出为50.68%到71.98%，而预期输出为51%-72%，两者在数值上略有差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1677
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但表述稍显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1652
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='The actual output omits the critical detail that晶澳科技从三季报的第九大重仓股跃升至第一大重仓股，and does not mention the specific action of刘格菘将晶澳科技提升至第一大重仓股。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1670
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，只是词语顺序稍有不同，没有遗漏重要细节，也没有引入事实错误或冗长描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1672
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the visit's purpose to counter global unilateralism and stabilize the region, as mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1671
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到奥飞娱乐退出以及B站关联公司持股100%的具体情况，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1679
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the future development plan of focusing on pork products and does not mention the current status.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1668
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output in terms of the price increase of battery-grade lithium carbonate, missing key details about the correct price increase and average price.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1673
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含了关键信息但略显冗长，缺少了子公司名称'联合利康'和'新冠病毒核酸检测'的具体描述。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1674
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中缺少了'满产满销'这一重要信息，且表述略显简略，未能完全符合预期输出的要求。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1681
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about budget deficit and special bond issuance scale, focusing only on the fiscal policy initiation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1682
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未提及全资子公司，缺少重要信息，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1684
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the key phrase '放宽市场准入特别措施发布', leading to less accurate information compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1686
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了新闻发布会和补偿计划的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1690
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了小米成为第三的重要细节，且未明确提到销量冠军的概念。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1675
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中关于制裁导致供应阻断的观点，且表述不如预期详细，遗漏了关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1687
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了HiHopeOS成为首个通过认证的重要细节，且未提及HiHopeOS的具体版本名称。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1676
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output omits the detail that the secondary listing in Singapore is considered to be as early as this year, which is an important fact from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1692
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1678
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了防止资本无序扩张和定期研判制度等重要细节，且比预期输出更为简略，未能涵盖所有关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1694
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by focusing on vaccine benefits instead of the reasons for prolonged hidden transmission.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1680
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the reason for the decline due to the Fed's hawkish stance and the time-specific rate of 1204.85, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1697
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了中药与体外检测板块净利润增幅较大的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1693
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分预期输出的内容，但遗漏了对确认依据的要求，且增加了不必要的细节，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1685
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及央行降息的具体信息，缺少关键事实；且标题与新闻内容关联度不高，未能准确反映预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1688
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了俄外交部发布公告和欧安组织探讨安全保障议题的具体提及，且未明确表达俄方的具体立场。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1695
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in content and does not mention the key points about the adjustment period and technological turnaround as specified.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1691
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the coal consumption days and contradicts the expected output by focusing solely on the current stockpile without mentioning the achievement in terms of days of supply.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1683
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing on a different aspect of the news and omitting the key detail about the number of people choosing not to use disposable cutlery when ordering takeout.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1698
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="缺少'杭州市'导致与预期输出略有不符，但未发现事实性错误或重要细节遗漏。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1700
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing outdated information and missing the key detail of new cases reported.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1696
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like注册资本2亿元 and does not accurately reflect the expected output's information.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1702
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少加息担忧和2016年以来最糟年度开局的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1701
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含返回的具体驻地信息，且未明确指出返回俄境内，导致信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1707
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了陈龙已离职的信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1699
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了生物医药B类股大跌的重要信息，且与期望输出相比，在细节上存在较大差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1712
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by not mentioning the signing of a strategic cooperation agreement.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1704
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出提供了比预期输出更多的具体信息，但没有包含宣布调整的日期和时间，略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1706
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了粗钢产量的具体数值和纳入统计的国家信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1705
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对北半球春播影响的关注，且未提及汤加火山喷发的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1689
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出相比，主要信息一致，但用词略有不同且略显简洁。实际输出未提及净利润的具体数值范围，但未明确指出该信息为关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1708
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了一些预期输出的信息，但遗漏了具体的募款金额和公司数量，且添加了不必要的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1709
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中的关键信息，如稳增长和不搞“大水漫灌”的重点内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1715
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like the historical data and probability of A股上涨, focusing only on the optimistic outlook for February.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1719
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the partnership with一汽-大众 and future support for 80多款车型.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1710
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了具体的企业数量，只提到了企业规模的扩大，而预期输出则提供了具体的4万多家企业数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1717
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中提到净利润同比增长，但未明确指出扭亏为盈的情况，且缺少了'同比扭亏'这一重要信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1714
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the detail of cumulative cases, but does not contradict expected output. The length is appropriate without unnecessary details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1713
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了病例总数但忽略了新增病例数，且病例总数与预期输出略有不同，导致信息不完全匹配。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1711
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了分析师的评级和目标价，但缺少了对2022年交付量的乐观预期，且目标价解释有误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1723
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，也没有遗漏重要细节，长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1721
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the specific detail about the three-month permit and does not mention the exact terms of the approval as in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1718
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未提及21Q4业绩增长承压，遗漏了重要信息；但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1722
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了重要细节，如贷款总额4000亿元，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1729
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出遗漏了总抗CE认证和自测版产品进入审批流程的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1703
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by mentioning '证监会核准批复' which is not aligned with the provided input, and it omits crucial details such as the stock issuance price, total fund raised, and specific amount and entity认购3亿元.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1720
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by omitting crucial details such as the reason and the names of the sanctioned Chinese entities, reducing its accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1728
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分重要信息但遗漏了社会物流总额的关键数据，且与预期输出内容不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1726
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了重要细节，如涉及犯罪并被移送公安机关处理的人数，这与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1716
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the specific location of PriceRunner (Sweden) and the amount claimed (24 billion USD), making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1724
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the cause of inflation and the economic minister's view, and does not mention the potential duration of inflation as in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1736
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有引入新的信息或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1730
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅在用词上略有不同，但未遗漏重要细节且未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1727
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output in terms of the focus and figures provided, omitting critical details such as 5G phone specifics and overall growth percentage.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1731
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含积极评价协定实施效果这一重要细节，仅提及会议召开，与预期输出相比缺少关键内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1739
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中遗漏了上海国投资本这一重要发起方，且表述不完全准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1725
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于病例密接传播的关键信息，仅概括了传播链条的清晰性，忽略了病例29密接传播22例的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1734
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key detail of total revenue amounting to 5835 billion dollars and focuses only on the growth rate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1738
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the mention of the dual pandemic situation with both新冠 and流感, focusing only on the flu vaccine effectiveness issue.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1732
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output on the source (证券日报 vs 证券时报) and omits the detail about improving service to the real economy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1740
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical information about the transactions not involving the main shareholders and management, as stated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1737
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了单日新增病例的预测，但遗漏了防疫部门将探讨以流感防控模式应对新冠的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1742
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the housing supply goals and the establishment of a housing guarantee system.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1733
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了公司按照深交所规则披露信息且不存在选择性披露的关键信息，但用词稍显冗长，比预期输出多了细节描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1745
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了销售生猪的数量，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1746
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在重要细节缺失，未提及FDA紧急授权批准信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1744
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了预期输出的内容，但增加了更多的细节和分析，这超出了预期输出的要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1741
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了推进跨境电商综合试验区建设，但遗漏了提升服务水平和营造良好环境等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1751
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了疫苗是非洲首个mRNA新冠疫苗的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1749
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了鸿海订单爆满的信息，但并未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1748
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the net profit range and the exact percentage increase provided in expected output, leading to less accurate information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1752
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits '各地掀起冰雪消费热潮', reducing detail accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1753
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了会议讨论的主题，如安全局势，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1747
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了预期输出中关于供应紧张将持续2023年全年的具体时间描述，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1754
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'预计'一词，导致标题不够准确，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1743
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但增加了美达电器的具体名称，这在预期输出中并未提及。长度稍长但未明显增加实质信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1735
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by incorrectly stating '本土25例' instead of mentioning '新增本土无症状1例' from Jiangxi, and omits the key fact about the addition of a new local asymptomatic case in Jiangxi.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1757
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少北向资金抢筹的重要信息，且没有提及具体的板块和行业细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1759
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like '大规模报复性空袭' and casualty information from expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1763
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts and omits the important details from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1771
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1756
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中的关键信息，如在线教育行业进入元宇宙的背景，以及商标申请的具体分类。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1760
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但省略了增长速度和时间范围的具体数据，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1758
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了德国外长再次呼吁加强对话这一重要细节，仅提到了德国不会向乌克兰提供武器。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1755
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出省略了萨默斯对加息次数和可能一次性加息超过25个基点的预期，仅提到需要更大幅度的收紧政策。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1765
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出没有提及公司正在积极采取措施要求移除名单，遗漏了重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1750
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出中的事实与预期输出中的事实相矛盾，实际输出表明欧佩克+同意小幅增产，而预期输出表明欧佩克+同意维持小幅减产。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1767
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'实际使用外资'中的'实际使用'部分，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1764
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了市场猜测的内容，但缺少了具体的时间背景和IMF的建议，且比预期输出多了无关细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1766
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits crucial details about Bloomberg's incorrect headline and subsequent deletion, focusing only on the UN spokesperson's statement.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1762
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了额外的机构信息，但遗漏了对2025年目标的具体描述，且未提及改善民生和新发展格局的作用。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1775
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于Meta滥用市场支配地位的重要信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1768
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了股东减持5%股份的关键信息，但省略了具体减持的股份数量和减持的具体方式，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1761
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含新闻来源'港股'，且语言简洁但略显信息不足，缺少'基于全体股东利益最大化的原则'及强调未作出决定和未申请批准的内容。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1779
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the number of people tested and their negative test results.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1770
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the specific time (18:30) and the type of cases (light and common type), which are mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1774
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了部分关键细节，如恢复运营的具体日期和城市名称的完整表述，但没有出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1772
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the units and individuals' strong sense of responsibility and the positive impact of their actions, as outlined in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1777
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但使用了'暗示'而非'称'，导致表达略有差异。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1780
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关键细节，如洛威可能强调实现充分就业的机会，以及对通胀水平判断错误的风险。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1769
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了工厂的产能信息，而预期输出未包含这些细节，但两者均传达了核心信息。实际输出略显冗长，但并未对事实造成误导。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1776
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes all important details from expected output but adds '我国服务外包产业继续保持较快增长，全年' which is not present in expected output and adds minor value.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1782
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on a different topic and does not summarize the input news correctly.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1778
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及全面实行股票发行注册制这一核心内容，且细节上有所缺失，未能准确反映预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1781
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了变异株类型，但遗漏了疫情初步判断为境外输入的关键信息，并且与预期输出内容差异较大。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1787
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了与日本多家公司积极接洽的重要信息，导致准确度降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1788
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出虽然提到了就业率的增长，但缺少了经合组织的标识和持续增长的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1791
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了净利润的具体范围信息，即2亿元-2.3亿元，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1773
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了重要信息，但遗漏了其他关键领域，如校外培训、老年消费等。同时，长度上也比预期输出多了不少内容，且这些额外内容并未增添实质性的价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1786
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output omits crucial details from the expected output, such as the specific measures to address demand contraction and the emphasis on policy initiatives.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1783
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出内容基本一致，但实际输出省略了装车地点上海港和到达时间3月的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1789
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the requirement for submitting proof and does not mention the timeframe or alternative health tests, contradicting important details in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1792
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了航班取消的具体数量，且没有明确指出积雪的影响，与预期输出相比重要信息缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1798
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details about the business scope of the new subsidiary as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1797
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，也没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1795
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了重要信息，如项目总投资60.71亿元和建设内容，仅提及增资11.87亿元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1801
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了耐克的目标评级和目标股价信息，且未完整传达分析师对收购可能性的具体理由。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1793
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the key opinion from industry insiders and does not fully convey the expected message about A股投资者逐步进入北交所市场。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1790
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key points such as encouraging financial technology innovation and steadily advancing the high-level opening of capital projects, which are mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1806
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了经营范围新增的信息，且没有提到具体的增幅，这使得输出不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1803
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键的贷款金额信息，且未提及贷款支持的时间范围和优惠政策等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1785
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但实际输出中使用了'拨款400亿美元用于桥梁修复和更换'，而预期输出使用了'修缮桥梁'，后者表达更为简洁。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1796
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the key detail that the case is being heard in the Australian Federal Court and does not explicitly mention the cancellation of the visa in the context of a court case as expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1784
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by reporting only 1 new case instead of 7, and omits crucial details about the total number of cases and the fact that there were 6 positive cases from close contacts and 1 from other risk personnel.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1814
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中的关键信息，即被开除党籍。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1802
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提及了研发投入金额，而未包含预期输出中关于研发投入强度和OECD国家平均水平的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1804
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出提供了具体的累计确诊数字，但省略了'超过1102万例'的表述，与预期输出略有不同。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1799
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了具体基金名称（汇添富MSCI中国A50互联互通ETF），且对新闻内容的概括不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1794
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未包含预期输出中的关键细节，如稳外资利好密集释放，仅简述了外资企业加码在华布局和中国扩大开放的信号，缺少对外资持续看好中国的表述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1807
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未提及汇像信息的业务范围及其成立时间，且未明确说明汇像信息是检验检测自动化服务商。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1808
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出遗漏了关于权益类和固收类产品基金经理的具体排名细节，且未提及具体的8位基金经理人数。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1809
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了股票升幅的概率范围（70%至80%）和增持评级这两个重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1811
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific reasons for the price increase, such as subsidy reduction and raw material price hikes mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1800
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key information about the hope for UN Security Council members to seriously consider China's suggestions and the call for efforts to stabilize the situation, build trust, and restart dialogue.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1805
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output does not mention the investment scale of the ongoing major water conservancy projects, which is a key detail from the expected output, leading to a significant omission of important information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1826
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without any contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1815
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于数据资产证券化等金融创新服务的重要信息，且未能全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1821
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了新闻的主要事实，但细节不如预期输出详细，特别是缺少项目公司的具体名称。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1816
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有包含预期输出中的关键细节，如净利润至少140亿和第四季度利润接近前三季度总和的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1810
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in timing (收评 vs 午评), details on index performance (集体跌超1% omitted), and introduces vague language that reduces accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1819
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as patent exposure and achieving the energy density target, and is significantly shorter than expected output, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1820
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中关于稳增长政策和工业金属需求提升的关键信息，且没有提到能源金属的蓄势待发。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1823
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific percentage of 37.4% decrease in passenger turnover and provides less detailed information compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1817
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了10000辆量产车下线和首款电动轿车亮相的信息，但用词稍显不同，且缺少了时间信息和新的产品市场布局的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1813
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the date, the type of meeting, and the specific instructions regarding the prioritization of the construction tasks. The output is significantly shorter and less detailed than the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1818
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出相比，仅将'全资子公司'简化为'子公司'，去掉了'之全资子公司'和具体名称，但信息核心未变。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1828
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the restriction on travel to and from high and medium-risk areas, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1831
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中未包含预期输出中的关键信息，如强热带气旋袭击和死亡人数可能继续上升的提示。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1834
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关键细节，如NASA计划在2026年发射火箭的时间点以及火箭的具体名称。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1824
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="实际输出虽然包含了利润总额年均增速8%以上的关键信息，但缺少了发布规划的九部门和'重磅'这一强调性质的描述。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1827
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了关键的时间段和不良资产处置金额，但使用了'五年'而非具体年份，与预期输出略有不同。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1829
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提及总统恩巴洛已掌控局势，且省略了关键细节，如总理和一些部长离开大楼的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1812
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了所有重要细节，但添加了不必要的信息，如'这是谱尼测试在连续多年获得上汽大众、一汽大众实验室认可的基础上，谱尼测试获得大众汽车最高综合性认可'，使得长度略显冗余。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1837
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了碳酸锂的具体价格增长信息和时间范围，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1822
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出虽然省略了部分细节，但并未出现事实上的错误，且长度适中。不过，缺少了关于具体参与人数和场地数量的具体数据，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1835
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提及马斯克后悔停产旧款Model X，也没有提到停产对特斯拉的影响持续至今，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1833
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于新冠治疗概念集体上涨的信息和君实生物新冠特效药获得授权使用的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1825
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on different aspects of the report and missing important details such as the establishment of the Shanghai state-owned capital investment fund and the timely formation of new state-owned enterprise groups.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1832
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及中海集团成功发行30亿元中票的关键事实，且未包含万科和美的注册新额度的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1841
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by focusing on wage growth and interest rates, while the expected output suggests a different stance regarding the Fed's actions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1839
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了百度第四季度业绩预期和业务复苏的信息，但遗漏了维持买入评级和目标股价的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1845
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了核心信息但省略了正式版的描述，略微偏离预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1836
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及利率下调的具体数值，且未明确指出利率下调的事实，仅提到了日期和一个笼统的发布信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1840
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details about the purpose of the investment and the specific amount in RMB, contradicting the expected output on these points.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1842
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及银保监会同意平安人寿投资新方正集团这一重要信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1848
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了税收收入稳中略降的关键信息，且没有明确提到国家税务总局。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1843
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了市长姓名覃伟中以及特别措施的内容，且未明确指出是关于放宽市场准入的特别措施。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1846
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了非农就业的具体数字和意外好于预期的关键信息，且美股期指的整体情况描述不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1830
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出强调了跨境人民币收付金额突破3万亿元，而预期输出强调了企业贷款加权平均利率达到有统计以来的最低水平。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1838
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了一些预期输出中没有的关键信息，如加息50个基点的考虑，但忽略了预期输出中的主体部分，即英国智库的观点，导致内容不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1851
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到小米关联公司入股，但缺少对经营范围的描述，且与预期输出的关键信息不完全吻合。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1850
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the specific market predictions and the shift in the central bank's stance, making it less accurate.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1852
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了主要事实，但详细信息略显不足，如具体授权日期和使用范围未提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1861
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少注册资本5亿元的重要信息，且未明确指出是绿色建材公司。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1855
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extra details not aligned with expected output, and introduces ambiguity by mentioning the role of the governor without matching the concise expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1857
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，也没有遗漏重要细节，且长度相等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1859
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了死亡人数的细节，而预期输出仅需总结确诊病例数，导致信息超出预期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1844
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及了美国国债将受益于通胀回落，但未明确指出是债券多头的观点，且省略了美联储行动对经济增长的阻碍和外国投资者的吸引力等关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1854
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits '公司' which is an important detail from expected output, but there are no contradictions or significant length discrepancies.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1858
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但缺少了发布通知的主体信息'上海'，导致信息不完全。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1853
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与期望输出不符，实际输出未提及国务院新闻办发布的白皮书名称，且包含了未在输入中提到的新信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1860
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少北京冬奥组委的引用和详细措施说明，仅提供了最终结论。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1865
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits that炬光科技是荷兰ASML光学设备核心供应商A公司的重要供应商，减少了关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1862
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="The actual output omits key information about other companies' performance and the significant decline in several stocks, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1856
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1849
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预期输出的关键信息，如降准预期，但省略了降息主要考虑因素（提振企业预期和稳定就业），长度上较为简洁但略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1864
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了启动3.0阶段建设的时间和具体细节，仅提及示范区扩展。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1847
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了启明维创及其一致行动人的减持信息，而预期输出中并未提及；并且实际输出中的减持比例为4.4998%，远高于预期输出中的2.16%，导致信息不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1868
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，未发现任何事实矛盾或重要细节遗漏，长度也完全匹配。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1866
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like '严防带病闯关' and '撤单并非上市节奏放缓', leading to less accurate representation of the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1871
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少'刷新纪录'这一重要信息，且没有提及'强制接种令'的效果。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1878
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了航班是援助汤加的重要信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1863
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='Actual output omits the mention of新增2例无症状感染者 and珠海市, and does not include广东珠海, leading to less accurate information compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1867
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了恒瑞医药的净卖出情况，但遗漏了招商银行的净买入信息，且净买入金额有轻微偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1880
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及具体城市里约市，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1874
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details about the continuous improvement of 5G network coverage mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1869
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits specific details about the timing and entity making the announcement, as well as the specific measures mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1873
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了向控股股东出售全部资产与负债的重要信息，且没有提及主营业务变更的具体内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1872
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中缺少了'国家级'和'高新技术企业'的重要信息，尽管传达了核心事实，但不够全面。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1870
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及恒生科技指数跌1.76%和教育、基建板块逆势走强这两个重要细节，且与预期输出存在较大差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1879
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about macro policy implementation and specific measures to boost demand and stability, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1886
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了猪肉价格的具体数值，仅提到了价格变化百分比。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1876
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含治愈和死亡病例信息，且病例数字未采用概数表达方式，与预期输出相比信息不完整且表述方式有差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1877
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键事实，但比预期输出详细，未提及年龄组的具体范围，且未明确指出儿童群体成为最高感染率的群体。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1892
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有遗漏信息或事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1889
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了股东信息和公司成立的具体投资方，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1883
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output lacks the key information that this is a '再次' (again) application, contradicting the expected output which emphasizes the repeated application attempt.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1896
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了电影的完整名称，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1882
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了成分股Meta的表现和对通信板块的影响，且标普500指数的跌幅表述不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1897
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits production details and exact sales figures, focusing only on sales growth percentage.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1885
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中包含了一些预期输出未提及的信息，导致重要细节的缺失；同时，实际输出并未完全涵盖预期输出中的核心内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1884
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details from expected output, such as the impact of Netflix on the美股科技板块 and the overall reason for the decline in the stocks.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1875
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The Actual Output contradicts the Expected Output by using a different source name '经济日报' instead of '人民财评', and does not accurately summarize the news content as specified.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1891
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the remaining space for further adjustments in the deposit reserve ratio, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1888
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键细节，如2022年Wi-Fi 6、6E的全球市占率接近六成。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1887
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output regarding the specific measures mentioned, such as '减免房租给予奖补'. Actual output is also less detailed compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1890
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the expected asset increase from both projects and focuses only on the timeline for one project, missing the main point of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1894
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason="实际输出缺乏'稳投资'这个关键点，且没有体现'快马加鞭'的紧迫感，因此遗漏了重要信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1893
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about A股政策面资金面均有支撑 and春季行情仍值得期待, which are important in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1899
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提到了疫苗接种贡献，忽略了预期输出中的国际合作呼吁和气候变化等重要议题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1881
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及了科技股短期前景黯淡，而预期输出则需要解释长久期和每股收益表现对科技板块的两面夹击，实际输出遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1903
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了预期输出的所有关键信息，但增加了不必要的细节，导致略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1900
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the 7700 emergency code and details about the fault, reducing accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1901
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了公司加大预制菜产品研发和投放以及提高产品附加值的关键信息，且未提及公司的业绩影响不确定性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1898
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by missing the key point of '辩证对待' (dialectically dealing with), leading to a less accurate representation of the original message.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1895
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output includes more details about the compensation plan and its reception, which are not in the expected output. It does not contradict the expected output but adds extra information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1909
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含预期输出中的关键细节，例如Waymo希望对其无人驾驶碰撞数据保密以及这些信息包括商业机密的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1907
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了转换为确诊病例的无症状感染者数量的具体描述，且未提及新增的境外输入病例，与预期输出相比不够详尽。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1908
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key information about the pilot projects in Zhangjiakou and Xiongan新区 and focuses only on the green exchange, which was an additional point.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1905
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by focusing on the wrong variant (Delata instead of overall cases) and missing key details about the total number of cases and the Omicron variant.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1906
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的关键事实不符，且包含了未提及的额外信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1910
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于员工贷款的具体细节，包括贷款类型和还款期限等重要信息，且表述不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1912
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了有关扩大国债期货试点银行范围的研究部分，且与预期输出相比内容不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1916
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了李克强的具体考察内容和对企业的期望，只提及了一部分内容，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1904
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits key information such as '中国信登' and the specific growth percentage compared to the previous month, but does not contradict any facts in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1914
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了对居民收入增长与消费扩大关系的描述，仅提到了促进共同富裕的制度政策体系。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1917
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出虽然传达了主要信息，但缺少了'分析事故对生产影响'这一细节，且表述略显冗长。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1911
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到加税建议，遗漏了重要信息；并且实际输出比预期输出更简略，没有包含预期输出的所有关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1921
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中未提及没收违法所得的具体金额，且罚款金额与预期输出有轻微差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1925
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了净利润的同比增长范围，但略去了主营业务收入大幅增加的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1919
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了评级下调的具体目标价，但遗漏了香港的公司名称和平均目标价的对比信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1902
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中的关键信息，如Nsp13蛋白质的详细信息及其作为药物研发新靶点的重要性，仅仅提到了发现三种化合物，忽略了对Nsp13的具体描述和其潜在的药物研发价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1930
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出缺少预期输出中的'该合同'一词，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1923
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contains specific company names that are not mentioned in expected output, leading to less accurate representation of the content.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1926
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中省略了时间范围和物联网IPv6连接数等重要细节，且引用的机构错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1913
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了为资本设置‘红绿灯’和严防银行保险资金被用于盲目‘加杠杆’这两个重要细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1915
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出不符，实际输出只是会议召开的简单陈述，而预期输出强调了会议中关于房地产金融的具体要求和指导方针。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1929
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出的信息基本相符，但缺少了一些细节，例如具体的排名和市场份额数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1918
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了加强大宗原材料供需对接和集中力量解决汽车等领域芯片短缺问题的重要细节，且只反映了部分内容，未能全面总结新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1920
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中提到的降级地区数量与预期输出一致，但未提及调整后的高中风险地区总数，且略去了新闻中关于其他地区风险等级不变的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1922
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了将BA.2认定为VUI的事实，但未提及这是奥密克戎毒株的新亚型，与预期输出相比缺少重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1931
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the departments involved and the overall goal of improving regulatory enforcement capabilities.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1928
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于目前放松警惕为时过早的重要信息，且长度明显短于预期输出，影响了信息的完整性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1933
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分事实，但遗漏了具体加速倍数和相关成果发表的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1938
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='遗漏了注册资本12亿的重要信息，且标题长度不足，未能全面反映实际内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1935
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes additional details about the loss reduction percentage compared to expected output, which is not aligned with the expected level of detail.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1934
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的内容不符，未提及交易员缩减美元押注的情况，且重点偏离了预期输出的要点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1936
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the release of the '创新型中小企业评价和培育办法' and other important details mentioned in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1932
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the total amount of 1200 billion yuan and does not specify the timeframe of '去年以来' (since last year), making it less accurate compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1924
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在来源机构上存在差异，实际输出提到的是国家发改委，而预期输出提到的是中煤协。实际输出涵盖了保障煤炭供应的部分内容，但未提及预期输出中的一季度稳定供应工作的具体内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1941
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the decline of large tech stocks and the performance of oil prices, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1943
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the information about the 4新增无症状感染者 and their origins, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1927
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的内容不一致，实际输出强调了数字经济的引领势能和产业布局优化，而预期输出则侧重于政策提振和数字产业发展利好，两者侧重点不同，且实际输出未涵盖预期输出的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1944
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未提及一径科技提供全固态激光雷达解决方案这一重要信息，且长度上没有多余冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1939
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details such as the number of bridges that need repair and the distribution of funds, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1942
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了BA.2变异毒株在美国传播比例低，忽略了输入中提到的具体哪些州发现了病例的重要信息，且没有提到病例数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1955
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details about the ongoing negotiations and the uncertainty regarding the integration into specific Tencent departments.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1954
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及罚金总额，少了重要细节；且与期望输出的内容重点不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1957
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键信息，即投资者可以积极布局上半年行情。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1948
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'左右'一词，导致与预期输出在措辞上略有不同，但没有引入实质性错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1945
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the key detail that 华中数控接盘南宁产投转让的股权, which is crucial for understanding the transaction.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1937
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的句子虽然传达了部分信息，但与预期输出相比，措辞有所不同，且缺少了关于美国不放弃幻想的具体表述，导致信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1949
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及特高压、配电网等重点领域，且使用了不同的表述方式，导致关键信息缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1956
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了10家银行业绩快报亮相的具体信息，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1952
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全符合。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1940
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits critical information from the expected output, focusing only on the capacity reduction for new oil refining projects while ignoring the requirements for new steel and aluminum projects. This results in a significant omission of important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1950
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific date of the announcement, the start date of the new policy, and the requirements for unvaccinated travelers.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1951
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只提到了公路口岸恢复出口业务，忽略了铁路口岸恢复进口业务的重要信息，且未提及业务恢复的有序性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1947
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中包含了关键信息如短期利空空窗期和春季躁动，但缺少情绪底渐近这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1960
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出缺少了'综合整治'这一重要细节，但没有引入事实错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1953
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the specific price of $92 per barrel and the current record high, leading to less accurate representation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1959
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中缺少了'健康有序发展'这一重要细节，但没有引入事实错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1958
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了批复同意通过验收，缺少了期望输出中正式投入运行的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1946
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含与预期输出不符的事实，未提及VV993是可口服抗新冠病毒候选新药，且实际输出中包含了预期输出未提及的额外信息，如合作的具体内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1962
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但添加了不必要的细节，如省的名称，使输出略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1968
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出不符，缺少构建首个贸易数字化创新服务平台的关键信息，且内容过于简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1971
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了具体年份和解决就业人数的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1964
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于提振信贷需求和降低融资成本的重要信息，且没有明确提到温彬的名字。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1963
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提到了子公司的中标金额，但忽略了与新疆中部合盛硅业签订的4.26亿元合同，且与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1973
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出省略了'策略差异将产生外溢风险'这一重要细节，导致信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1970
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了所有关键事实，但比预期输出多了具体日期和官网提前启用新名称的信息，导致略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1966
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了预期增速的具体数值3.5%，且没有提到下调的幅度，这使得信息不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1961
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output omits crucial details like the number of website platforms约谈,警告 and暂停功能或更新, and only provides information about fines, which does not align with the expected output's comprehensive detail.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1989
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without any contradictions or omitted important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1977
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits information about the number of high-risk areas, reducing accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1980
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中关于产品可在欧盟市场销售的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1979
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有包含与新冠感染者接触的人不需要隔离这一关键信息，且整体内容过于简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1987
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了增长率这一重要信息，且来源机构为工信部而非中国信通院。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1982
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the detail of forming a cluster and the supporting systems mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1981
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the specific investment amount of 21.5 billion yuan mentioned in the expected output, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1983
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了碳中和目标和20%时程提前的重要细节，影响了信息的完整性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1986
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于两个版本设计的关键信息，以及没有提及分析师的名字和他对车型调整的预测。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1974
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits specific case count of 50030 and focuses only on the trend, resulting in less accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1965
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the detail that Zhang Yiming is卸任(ceased to be) the legal representative and does not explicitly state he is stepping down, which is a key point in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1976
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了预期输出中的关键细节，如投资者情绪、市场策略和具体建议板块，仅概括了部分信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1969
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在事实上的偏差，实际输出过分简化并偏离了原始信息的重点，忽略了加息步伐谨慎的关键点，且添加了对美元构成支撑这一不是新闻简述重点的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1991
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了猪粮比价进入过度下跌二级预警区间的细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1975
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details from expected output such as the impact on market confidence and overall economic support, and does not fully capture the essence of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1978
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output accurately reflects the key points of the expected output but includes more details. No contradictions or omissions, yet it is slightly longer than necessary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1985
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含宜昌新材料创新产业园项目一期工程的具体内容，但遗漏了福建泉港60万吨/年环氧丙烷项目的相关信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1992
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含拜登提名这一关键信息，且长度显著短于预期输出，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1967
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on '霸权霸凌' instead of '保护主义、单边主义', and omits the phrase '只会损人害己'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1972
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the potential legislative impact on Meta and its competitors, focusing only on the market value drop. Expected output hints at a potential change in antitrust status based on the market value threshold.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1988
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了'27家药企获准仿制'的重要信息，并且实际输出中没有明确提到全球范围内获准仿制的药企数量。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1984
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了票房总额和领跑影片的信息，但超出了预期输出的内容范围，而预期输出仅要求票房破60亿元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1993
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="Actual output includes more specific details of client companies and product applications than expected, which is not aligned with the expected output's brevity.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1996
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the cumulative death cases and重症住院患者信息, which are present in the expected output, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1994
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于股价涨幅为自1月4日以来最大涨幅的关键信息，且添加了上调全年预期的原因，这与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1998
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='忽略了预期输出中的具体商品名称和涨幅，如菜粕涨超2%，仅提到了焦煤的跌幅。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2003
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出遗漏了加快交通运输现代化示范区建设的重要信息，且表述不如预期输出详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2008
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出省略了BCM产品具体名称，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2004
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual Output omits the fact that there were no新增本土新冠肺炎确诊病例, which is an important detail in Expected Output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2002
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output omits the expert's quote and the prediction about the significant years' advance, reducing accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2000
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的主要信息，但使用了稍微不同的表达方式。实际输出比预期输出多了一些细节，但并没有引入事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1995
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output includes additional details about the meeting and context not present in expected output, leading to a slight deviation from the concise requirement. However, it does not contradict any facts from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1997
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='The actual output omits key details such as the company name, the involvement of吉比特, and the specific capital amount, leading to less accurate information compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2013
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了对公司全年业绩不构成重大影响的关键信息，且长度明显少于预期输出，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2017
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中未提及'逐步乐观起来'这一重要细节，并且与期望输出中的'反击条件已经具备'不符。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2005
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the timeline of events and the specific number of members who resigned, as well as the positive sentiment expressed in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2006
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the gradual decrease in tsunami threat and the specific mention of disaster assessment instead of just assessing tsunami impact.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2007
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但实际输出中包含的'芯原股份：'并非新闻原文所给内容，略显多余。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2011
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the location (Germany) and the name of the center (Forschungszentrum Jülich) mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2010
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出忽略了独董特别委员会的调查结果以及贾跃亭年薪削减的信息，这些是预期输出的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2015
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了利率下调的背景信息和二套房利率信息，且未提及利率调整不意味着房地产政策转向，减少了信息的完整性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2012
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了注册资本的具体数额和公司名称的完整描述，这些细节在预期输出中是重要的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2024
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出基本一致，但缺少了启动的具体日期和“今日”这一信息，使得信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2009
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含重要但不全面的信息，未提及美债收益率走低和黄金上涨的关系，且比预期输出更详细但未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1999
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the involvement of the Guangcheng Automotive Group and the specific mention of it being a new investment in Shanghai. The title is also less descriptive compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2021
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含浙江富润成为中国广告协会数字元宇宙工作委员会副主任单位的关键信息，仅提到了个人职务变动，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2016
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键人物和事件，但包含了更多职务细节，未完全遵循预期输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2022
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了高盛的预测，但未明确提及策略师的观点和对成长股风险的有限性，且表述较为笼统。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2018
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了部分事实，但遗漏了关于非冷冻入境物品导致感染证据不足的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2026
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="实际输出缺少了'当前'这一重要时间描述，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2027
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by omitting critical information such as total cases and location details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2023
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中遗漏了广东省相关企业数量最多和2021年新增1万余家创历史新高的重要信息，且长度较短但关键细节不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_1990
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到德国计划为能源行业提供豁免资格以避免切断俄罗斯银行的美元结算交易，但预期输出仅提到德国希望在实施金融制裁时对能源业进行豁免。实际输出增加了关于美元结算交易的内容，这与预期输出不符，且遗漏了关于德国担忧能源供应威胁的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2001
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了2021年险资大类资产配置的具体变化，但遗漏了运用余额的具体数值和增长情况，且未提及2021年末险资运用余额的具体数值和增长情况，与预期输出相比，缺少关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2014
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about industry performance and specific sectors, focusing only on the number of companies and their growth, while expected output highlights the overall industry 'vitality' and mentions specific sectors performing well.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2020
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2031
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details about investment growth and energy demand from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2034
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2025
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出忽略了高盛预测布伦特原油价格在第三季突破100美元的重要细节，且缺乏对连续7周上涨和创7年新高的描述，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2035
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, no contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2019
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits '美国防部：' at the beginning and does not mention '美国' continues to provide military supplies, but the core information is retained without factual contradictions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2033
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中没有提及发布的是第三代车辆，且缺少了计划量产的时间点，导致信息不完全。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2047
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output precisely without omitting any details or introducing contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2029
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出基本一致，但实际输出中省略了'可能会采取'这一细节，导致略显直接。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2028
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the stock ticker (AAPL.O) but includes all other critical information from the expected output. The length is appropriate and does not introduce factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2045
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits specific case numbers and death count, but there is no factual contradiction.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2038
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含中国电信，而预期输出中未提及中国电信，导致信息冗余且与预期不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2036
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了净利润的具体范围和同比增加的具体金额，未能完全反映预期输出中的关键财务信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2030
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the 2021 growth rate and the overall positive investment situation, focusing solely on the 2022 plans.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2037
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the exact number of cases and the single-day increase, but does not introduce any factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2052
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了募集资金的具体用途，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2032
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the detail that the product is used in the treatment of幽门螺杆菌感染, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2049
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了通信服务板块走强的信息，并且未提及股票涨停对整个板块的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2040
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及诊断速度的突破，且忽略了发表在《新英格兰医学杂志》上的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2055
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但添加了不必要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2039
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了闭环管理的信息，但遗漏了开始时间和具体为今日零时开始的重要细节，且表述冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2057
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on冷链物品关联而非发展阶段。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2053
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了拨款数额、研发细节和法案具体目标等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2041
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及与GDP的比例和基础研究经费的具体数值，且表述较为简略，缺乏预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2044
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出和预期输出基本一致，但实际输出包含更多细节关于业务发展情况，虽然增加了信息量但并非关键信息，略有冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2042
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出相比，未包含刚果（布）首都布拉柴维尔的具体信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2043
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含主要信息但省略了具体地点和持有者信息，且比预期输出略长，但未引入错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2056
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少转让价格和预计净收益的具体数额，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2058
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中提到的坚持增产计划的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2061
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了预期输出中关于整体估值仍处于历史低位的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2048
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output contains less detail than expected output, missing the specific action of '通报批评' and '限期整改', but does not contradict any facts.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2054
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual Output omits key details about the judgment criteria for future business opportunities and revenue from数字货币业务, significantly deviating from Expected Output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2060
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中关于着眼于群众最期盼的生育养育教育等工作的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2059
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key information about trade growth and the initiative for high-quality, sustainable economic cooperation, focusing only on direct investment.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2050
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在内容上有所偏差，实际输出侧重于描述签署合作协议，而预期输出强调了中俄各领域务实合作的推进。实际输出未完全反映预期输出的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2046
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出虽提及新增确诊病例总数及本土病例数，但遗漏了新闻来源和具体新增本土确诊病例数的官方来源，即'国家卫健委'，且未提及无新增死亡病例和无新增疑似病例的信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2065
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有引入额外的或不准确的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2066
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'本土确诊病例'中的'病例'二字，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2070
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只包含了部分内容，忽略了争取上半年完成全部地方政府专项债券发行工作的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2067
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了公司回应不知情的重要信息，且在传达市场传闻方面不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2071
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits critical financial performance details from expected output and only partially summarizes the news content.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2064
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关键人物和组织名称，仅提到了会面事实，而预期输出中明确了双方代表的职务和姓名。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2073
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了反垄断和反不正当竞争执法的重要内容，且标题过于简略，未能涵盖新闻的主要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2074
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about expanding the domestic demand strategy and proposing measures to invigorate industrial operations as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2063
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了收购价格和雅居乐、世茂的具体股权比例，且未提及总持股比例73.33%。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2079
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，只是百分比的小数点处理不同，没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2062
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output includes specific details about the subsidiary and the acquired equity percentage, but adds unnecessary information about the acquiring price being 0 yuan and the remaining equity holder's share.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2077
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了国家名称的顺序，但没有出现事实上的矛盾，也没有引入模糊语言或矛盾意见。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2075
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了时间和地点的具体信息，且未提及无症状感染者。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2076
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅包含了文件印发的信息，而预期输出要求的是部署推进数字乡村相关工作的内容，实际输出缺少了预期输出的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2068
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits crucial details such as the number of涨停股 (tizhang gu) and the industries they are concentrated in, which are highlighted in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2080
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output only restates the title and omits all important details about the four key tasks outlined in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2084
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键细节，如科技巨头业绩欠佳的信息以及信用风险升高的具体时间段。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2078
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits some details about the percentage of total shares, cost, and price range but does not contradict any facts from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2069
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing solely on the restart of the conditional quarantine-free entry policy and omits the broader proposal to relax防疫 restrictions mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2051
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits details such as '长白山和平雪场、火山遗址风景区、长白天地度假酒店、南山雪场' and '开启北麓乃至长白山全域旅游度假新格局', which are present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2082
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了净利润的具体范围，但没有引入事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2081
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了具体的地理位置信息，即“广西百色”，这使得信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2072
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及人均GDP未达高收入国家标准，而预期输出强调我国人均GDP与发达国家相比差距较大，实际输出忽略了这一重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2087
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及易方达、招商、南方、广发四巨头的领先情况，且与预期输出的主要信息不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2086
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出未包含预期输出中强调的'一体推进冬奥防疫与城市防疫'和'确保涉奥人员同社会面完全分离'的关键信息，导致准确性降低。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2091
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2088
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含发行新票据的信息，但遗漏了敦促持有人交换票据的重要信息，且没有提及公司未支付本金和利息的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2089
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未包含财政部长官的具体声明，且省略了债务的具体数值29.8万亿美元，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2092
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='缺少关于科技股、内房股和物业股集体暴涨的信息，且标题长度较短，未能全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2083
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及节前资金谨慎这一关键细节，仅强调了A股长期向上的动力，与预期输出相比，缺少重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2090
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了关键技术达到国际领先水平的信息，但遗漏了新产品技术鉴定证书的关键信息，且未提及证书的颁发机构和鉴定委员会的意见。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2101
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'已经'这个词，导致表达不如预期准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2110
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未提及阳性感染者的具体来源，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2085
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了具体吞吐量数量435万标准箱，且未提及散杂货吞吐量的佳绩，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2100
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the agreement type and the entity signing the agreement, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2099
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中缺少了'一季度经济走势有望超预期'这一重要信息，但未引入事实性错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2102
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了'情绪底'和'市场底'共振的关键信息，但并未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2113
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了来源CFTC和时间范围的具体描述，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2095
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits critical details such as the date, the name of the meeting, and the key figure involved, leading to a significant loss of important information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2112
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出中包含的信息与预期输出不符，且遗漏了关于集团客户授信限额的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2111
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the question asked to the White House press secretary and her additional comments, reducing its accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2093
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits details about the specific model F-35C and the injuries to the water soldiers, reducing its accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2106
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output omits details about the window for interest rate cuts not being closed, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2097
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="Actual output omits key points about 'grasping the breakthrough of core technologies' and 'actively expanding resident consumption and effective investment', contradicting the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2107
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=None, reason=None, strict_mode=False, evaluation_model='Custom vllm Server Model', error='Evaluation LLM outputted an invalid JSON. Please use a better evaluation model.', evaluation_cost=None, verbose_logs=None)]

======================================================================
Test Case: test_case_2108
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key information about market expectations for a March rate hike, which is present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2096
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific percentage mentioned in the expected output, such as 0.9996427%, and does not mention the full explanation provided by拼多多.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2104
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the detail that the quarterly growth rate of total social electricity consumption will show an overall upward trend, which is included in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2094
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了绿色低碳主题卡产品助力双碳目标的信息，但遗漏了47款无界数字银行卡产品发卡量突破3200万张这个重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2116
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='包含关键机构但未概括债券发行情况，且信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2098
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the year 2022 and the specific goal of the action to improve cross-border trade facilitation. The length is concise but lacks important information from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2117
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on skiing ticket sales growth instead of the growth in Olympic licensed merchandise sales.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2119
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有多余的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2109
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及三菱东京日联银行的预期，且未提到欧元一季度将跌至1.1000水平的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2105
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了2022年春节档票价与2021年和2019年相比的具体情况，且没有突出最贵春节档的描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2114
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了额外的信息，虽然没有违背预期输出的内容，但增加了项目合作的目标描述，这使得输出略长且包含非必要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2115
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了新闻来源和发言人的身份，缺少了'法国财长：'这一部分，但保留了关键事实。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2118
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含俄联邦海关局的数据来源，但未出现事实矛盾，且未显著增加冗余信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2126
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific types of venues mentioned in expected output and is less detailed.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2121
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the specific mention of the US draft and Russia's basic concerns, focusing only on the three key demands.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2120
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及全球经济复苏和下游需求旺盛等关键因素，且未明确指出半数公司净利润翻倍，重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2128
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了部分预期输出的内容，但遗漏了对多国能源成本影响的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2139
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, with no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2132
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的关键信息，但略去了分析师的具体观点，且略有不同的措辞。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2127
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on increased market volatility rather than stating the limited impact of the Federal Reserve's interest rate hikes.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2130
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了净利润增长的具体百分比，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2142
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少建议关注配置价值的重要信息，且未提及两条选股线索。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2122
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the eternal theme of risk prevention in fiscal work and the statement that this theme should never be relaxed, as specified in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2123
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits the detail that it was a rumor about the Shanghai headquarters being under control measures, and simplifies the携程回应部分至'正常协查'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2131
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about Beijing and Shanghai's banks having sufficient quotas and the specific rate decline in Guangzhou to the '5' era.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2103
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出在表述上略有不同，但并未出现事实上的矛盾。实际输出侧重于强调打击虚开发票的行为，而预期输出更侧重于强调依法打击偷逃成品油消费税的违法犯罪行为。两者在细节上有所不同，但均传达了打击偷逃税行为的核心信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2137
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output includes additional details not present in expected output, but omits key phrases such as '防止资本无序扩张'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2143
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific exchange names and the status of night trading closing, which are mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2135
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提到价格超过泡沫时代的高点这一关键信息，且与预期输出相比，缺乏关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2134
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了预喜率和超过市场一致预期的公司数量等重要信息，且未体现预喜率接近六成的关键数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2136
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the payment of cash consideration, the withdrawal of listing status, and the exchange of equity shares, contradicting expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2124
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了错误信息，如特斯拉将搭载比亚迪刀片电池，而预期输出未提及这一信息。实际输出比预期输出多出关于电池的具体描述，但这部分内容是与预期不符的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2129
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了彭博经济研究的具体内容，但遗漏了GDP跟踪指标的关键信息，且未提及任何机构分析，与预期输出相比，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2125
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the phrase '目前公司的' which was present in the expected output, indicating that it misses some detail about the current status of the company's production capacity. However, it does not introduce any factual errors.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2141
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output does not contain the key information about the lowest level since February last year, omitting crucial details from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2144
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未提及新能源汽车补贴退坡这一重要因素，只提到了原材料价格上涨，遗漏了部分关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2145
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中包含了扎克伯格财富损失的信息，但遗漏了Meta股价暴跌的细节，且损失的具体数值和排名信息不完全准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2151
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出缺少了专家估计市场规模的具体细节以及'料商'的完整引述，但没有出现事实上的矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2148
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了建设全球动力之城核心区的重要信息，同时内容长度与期望输出相比不匹配。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2133
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details such as the 1.7% drop in the Nasdaq 100 index futures and the exact yield of the US 10-year Treasury note, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2146
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出虽然提到了俄方的观点，但忽略了美国国防部的宣布这一重要事实，且未完全反映俄方对美国决定的评价。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2140
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中虽然提到了利好债券发行人和投资者，但未提及互联互通机制的具体进展和对债券市场高质量发展的助力，缺少了预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2138
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the source of the information, which is '伊朗外交部' (Iran's Ministry of Foreign Affairs), and lacks detail about the conditions for reopening the embassy as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2172
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradiction or omission.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2152
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2147
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on the origin of the infection rather than the fact that all cases are part of the same transmission chain.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2153
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits details about the specific timeline and the retiring judge but does not contradict any facts in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2155
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output in source attribution and key content, missing crucial details from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2150
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the event being a one-year anniversary press conference and the source of the news. The output is also shorter, missing essential information from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2149
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output discusses blockchain and新能源车板块 performance, which does not match the expected output about major indices performance. There is a factual contradiction.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2157
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出省略了美国市场销售业绩大幅增长的重要信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2167
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the total number of cases and the distribution of cases across different areas, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2175
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出一致，没有包含额外无关信息或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2156
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the percentage increase in 2021 chip shipments and the comparison to overall semiconductor shipment growth.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2154
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了康德莱全资子公司投资入股美械宝的信息，但缺少了股权投资和“美械宝”是医美上游企业的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2160
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about vaccine-driven demand recovery and OPEC+ plans, focusing narrowly on supply issues without matching the expected output's emphasis on both supply and demand.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2170
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到新闻中关于VV116是否会在年内申请上市的关键信息，且缺少新闻来源的提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2161
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output contains additional information not aligned with expected output, deviating from the concise summary format.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2166
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了业绩预告中亏损的原因描述，即大宗商品供需形势持续吃紧导致燃料成本大幅攀升，控股和参股电厂盈利能力下降的背景信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2174
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅涵盖了疫情防控的一小部分，忽略了预期输出中关于毫不放松防疫工作和能源物资运输的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2158
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了RJO Futures的引用和对黄金表现的预期，且未提及乌克兰危机加剧的具体影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2163
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未包含预期输出中的专家观点和政策效果，且缺乏具体政策细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2168
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output regarding the source and content, and omits key details such as the risk提示和预测报告的具体名称及内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2177
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了比亚迪回应中标的消息属实这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2159
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出未包含'专项检查由中国银保监会非银行机构检查局负责统筹组织实施'这一重要信息，略显简略；但并未出现事实上的矛盾，长度适中。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2173
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific actions planned by the US and the involvement of global resources, and introduces vague language not aligned with the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2176
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少安阳新增本土确诊病例的详细信息，未能完全符合预期输出的要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2162
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出与预期输出仅有细微差别，缺少'以'字，但未引入新的事实或矛盾，且长度一致。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2180
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未提及GDP预期从3.8%下调的具体信息，缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2165
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了维尔康市场的具体名称，但未提及新闻的来源（济南时报微博）和建议市民进行核酸检测等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2169
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少关于中方对美方决策逻辑表示不满的重要信息，并且对美方人员是否被要求回国的描述不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2184
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出的信息不完整，缺少了多家银行推出虚拟数字人的具体内容，且表述不如预期详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2171
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output includes factual details from expected output but omits the cause of the red light phase (奥密克戎毒株持续蔓延).', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2182
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出的主要事实一致，但实际输出省略了净利润的具体金额范围，略显信息不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2183
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有矛盾的事实，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2190
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少具体地点无锡，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2179
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the team leader (金贤敏) and the fact that it is the largest scale reported, reducing its accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2185
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了重要细节，如丹麦成为欧洲首个接种第四剂疫苗的国家和主要针对高风险人群的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2181
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出遗漏了与首款产品募资金额大幅减少的重要信息，且未提及'贝盈A股二期'是贝莱德建信的第二只权益产品。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2189
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits critical details about solar photovoltaic peak power capacity and contradicts the expected output by focusing on a different metric.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2164
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes factual inaccuracies by mentioning '常用有色金属冶炼' and '生产性废旧金属回收；再生资源回收等' instead of just '有色金属冶炼业务'. Additionally, important details like date and company name variations are omitted.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2188
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，且遗漏了欧洲央行官员对加息计划的预期，导致信息偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2205
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了消费大幅增长的重要信息，导致准确性下降。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2186
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提到债务豁免旨在使净资产转正这一关键点，且未提及背后可能存在的利益安排，缺少了预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2196
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details about strengthening maternal and child health and implementing management norms, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2187
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了重要细节，如坚持制造业高质量发展主攻方向和聚焦补链延链强链，仅涵盖了部分内容，未能全面反映新闻要点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2178
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了恒指上涨2.06%，但预期输出中是2%，且实际输出中提到铝业股领涨，而预期输出中提到互联网科技股集体反弹，两者信息不一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2198
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但实际输出中包含'-W'符号，而预期输出中未包含。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2193
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少油价上涨的关键信息以及页岩油企增加支出预算的情况，仅提到了增加钻机和压裂工作人员。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2192
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出包含了规划的发布信息，但遗漏了预期输出中关于督促流通企业依法依规保障劳动者权益的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2197
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关键的专家预测信息，且未能体现比特币未来几年将进入萧条期的预期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2194
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的细节不符，且遗漏了关键信息，如多元基准利率体系雏形初具。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2199
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含外媒来源，且没有明确指出这些卫星是新发射的，这与预期输出相比缺少了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2201
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，缺少了关键细节，如倡议书的具体内容和提出的四点建议，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2204
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中关键的盈利范围信息，且未提及同比扭亏的具体数字。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2195
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits crucial details about the initial diagnosis of the infection stage and focuses solely on the travel history of the case, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2200
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits current case numbers and contradicts expected output by not providing the latest status of both confirmed cases and asymptomatic感染者数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2191
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the境外上市计划and the specific related work such as ODIC备案及审批手续,签署投资协议等, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2203
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits key details such as the effect of dollar weakness and the performance of other metals, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2208
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出所描述的内容不符，实际输出只提到了一个目标值而没有提及计划发布的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2207
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了核酸检测试剂的信息，但忽略了防疫总方针仍然有效的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2209
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出缺少了对病例是'后续'8例的描述，以及它们为同一传播链的信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2213
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key recommendation details from expected output and focuses on a different aspect of the input text.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2217
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了人口增长的具体数字，且未提及统计局发布数据的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2206
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific actions taken by Russia and the intent to send a message to Putin, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2202
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到字节跳动、宁德时代和美团的价值增长了一倍以上，但与预期输出相比，实际输出忽略了增长的具体描述，且表述不完全准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2212
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了制定具体规章的重要信息，且没有提及全面实行股票发行注册制的决策部署。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2211
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by omitting key information about Western countries' purpose and instead includes unrelated details about Ukraine's actions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2219
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了预期输出的主要信息，但语言略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2216
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出没有包含虎元素商品热销的信息，而预期输出强调了这一点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2210
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific amount of 4.25亿美元, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2214
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about contract months and price movements, and does not mention the specific days or dates as in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2224
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提供了营业收入信息，忽略了行业总体恢复性增长、利润增长等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2220
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于XR产业可能的增长预测和对于元宇宙热潮是虚火还是风口的疑问。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2230
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了控制权变更事项和股票停牌的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2229
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了盈利能力提升和毛利润大幅增加的具体信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2221
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了新闻的主要内容，但使用了'按此前计划'而非'计划'，略微增加了冗余信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2237
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了公司成立的具体地点上海，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2226
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details like the specific timeframe of '2022年上半年' and the context of the announcement, making it less accurate than expected.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2218
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits critical details about the regulation on selling to minors and contradicts the expected output by focusing solely on pricing, rather than the key restriction on sales to minors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2233
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了感染者轨迹复杂的重要信息，且相比预期输出更简洁但不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2215
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output contradicts the expected output by stating the exact single-week decline record since March 2020, while the expected output mentions a significant decline over nearly two years without specifying a record.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2234
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits crucial details such as the share percentage and the recipient of the transfer, only mentioning that the controlling shareholder has not changed.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2238
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了法案未获最终通过和将被送回国民议会重审的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2227
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中遗漏了塔斯卡尼区和广域市的具体信息，虽然传达了主要信息，但细节不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2228
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output correctly states the positive test result but omits details about the specific role and name of the official, as well as the symptoms and self-isolation measures mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2232
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出和预期输出内容基本一致，但实际输出增加了营业收入和每股收益的信息，虽非重要遗漏，但略超出预期简洁度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2243
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少小米关联公司和注册资本的变化信息，且未提及至盛半导体的经营范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2225
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the issue price of 5 yuan, the global leadership in photovoltaic components, and the expected date of subscription. It only partially covers the content of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2236
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='包含额外无关信息，如顺博合金的政府补助，而缺失华大基因产品详细用途等关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2223
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by incorrectly stating '新增本土无症状感染者1例' which is not mentioned in the input and expected output. Also, important details like the specific numbers of cases in each region are omitted.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2222
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了一些预期输出未提及的关键细节，如金融和消费电子领域，但省略了预期输出中明确提到的消费与基建领域的具体推荐，且更长的篇幅未提供额外价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2246
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了关于煤价回落的信息，但忽略了存煤天数的关键细节，且与预期输出的主要信息不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2239
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="实际输出与预期输出内容不符，实际输出强调了'双减'的重要性，而预期输出的重点在于高中阶段学科类培训的执行政策。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2235
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于稳增长、防风险的具体措施和注册制改革的细节，且未提及通过改革稳定预期、增加市场活力的重要性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2244
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了对海淀新技术大厦启动临时封控的重要信息，且与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2247
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中的关键短语“担忧美联储缩过头”，且对具体事件的描述不够详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2245
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了超出预期的内容，但增加了市场预期的具体数值，这在预期输出中并未提及，导致信息冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2250
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the virus strain and sequencing results provided in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2249
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了关于合谋涨价的重要细节，且没有提及航线的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2240
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning the specific event of the equity cooperation agreement signing between Sinograin and COFCO. It only captures a part of the conclusion from the event.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2248
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出相比，只是略去了'时间'一词，但传达的信息是一致的，没有遗漏重要细节或引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2251
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了全员核酸检测和愿检尽检的免费核酸检测，但预期输出只提到了全员核酸检测，因此包含了额外但并非重要的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2242
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason="实际输出中缺少了'老旧小区改造'这一重要信息，只提到了部分具体措施如增设电梯和楼体抗震加固，未能全面反映预期输出中的主要内容。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2255
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了报告来源的重要信息，未能完整体现预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2264
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中遗漏了对居家观察人员加密核酸检测频次的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2257
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含日期和关键的交通管制细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2256
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了累计确诊数量的关键信息，并且没有提及新增死亡病例和住院患者的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2265
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出未包含'三年行动方案'这一重要细节，导致信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2231
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了世界卫生组织的信息，但额外添加了关于传染性和重症风险的数据，而这些并不是预期输出中的内容。同时，预期输出中提到的“一亚型变异株”被简化为“亚型变异毒株”，导致信息不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2252
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了国台办驳斥大陆将开放进口日本核食的具体内容，仅保留了纯属造谣的部分，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2267
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及24亿美元的补贴，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2254
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关键细节，如加快建设国家电力市场的部分内容，以及完善电力交易平台运营管理和跨省跨区市场交易机制等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2258
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits specific net profit range details, but does not contradict expected output. Length is concise and does not add unnecessary information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2260
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了汤加物资供应可能短缺的重要信息，且相比预期输出更为简短，未能全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2259
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了规划出台的背景和主要目标等重要信息，仅提到了5G基站的建设目标，与预期输出相比不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2253
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到立陶宛铁路公司与白俄罗斯钾肥公司的合同被终止，但未提及白俄罗斯钾肥公司起诉立陶宛政府的具体内容，缺少了关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2262
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了对基建投资的支持这一重要细节，且表述不如预期输出具体。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2261
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了预期输出中关于盈利范围的具体数字，且未明确说明同比扭亏的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2273
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about sample destruction and the discrepancy between actual and official case numbers.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2241
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的事实不一致，特别是关于新增病例数量和放宽防疫措施的时间点。实际输出提到单日新增病例超过10万，而输入信息提到的是7天内每10万人发病率达到1426.0，且卫生部长提到的时间点是四月中旬。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2269
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比略简化，但没有关键事实的遗漏或矛盾。只是在措辞上略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2263
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits critical information about the capacity of the新冠病毒检测试剂, which is a key detail from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2268
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，没有遗漏重要细节，且长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2272
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有包含额外信息或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2274
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含重要信息，如年度总出货金额和月度出货金额的环比变化。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2270
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="Actual output includes all necessary details but adds '公司股份' at the end, making it slightly longer without adding substantial value.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2276
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了筛查启动时间、采样人数以及筛查的具体范围等重要细节，且表述不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2286
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, no contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2278
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="实际输出中缺少了'中国人寿集团'的信息，且表述与预期输出略有不同。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2277
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出缺少了'业绩快报'和'同比增长89%'的关键信息，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2275
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details such as the names of the companies, roles of executives, and specific registration capital, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2283
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了预期输出中的重要细节，如保供稳价工作和保持煤炭正常生产等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2281
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output matches expected output closely but omits details about the estimated net profit range and product performance details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2271
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about 14天期逆回购量增价减 and the overall proactive monetary policy, focusing only on a part of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2282
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output lacks the detail that the timing is within the first half of the year and omits the consideration of macroeconomic and market conditions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2279
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出中没有包含预期输出中的关键细节，如“政策合力”和“地产行业三月复苏”，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2288
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少同比增长超过150%的重要信息，且长度显著短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2280
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中的关键细节，如目标年份2025年和具体城市数量60个左右，准确性较低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2285
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现矛盾，也没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2287
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits information about the supply relationship and the strategic partnership between battery and vehicle companies, as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2294
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical information about cumulative confirmed cases and does not follow expected output completely.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2266
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出与预期输出在表达上存在差异，实际输出强调了桥水联席投资长的观点，而预期输出更注重美联储可能容忍的跌幅。实际输出没有完全传达预期输出中的关键信息，即美联储可能容忍的跌幅范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2290
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及了日本央行内部的辩论，但未说明可能的加息时间点及不会很快的实际内容，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2302
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了总统开始恢复正常工作的信息，且没有提到每日晨间新闻发布会。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2295
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '降息'落地和人民币创新高，且表述不如预期具体。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2292
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extra details about the purpose and types of contracts, which are not present in the expected output, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2305
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2293
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中提到的成立总规模542亿和不足去年同期1/6的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2291
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了价格变化的具体信息和时间年份，只提到了报价出炉，而预期输出包括了价格上涨的信息和具体年份。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2297
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2301
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及电动自行车，并且信息量较少，未能充分反映预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2296
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了净利润的具体数值和甲醇市场销售价格同比涨幅较大的信息，且同比增长百分比有细微差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2300
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了通胀加速的信息，但忽略了零售商提价幅度的具体细节，且与预期输出相比不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2284
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的关键信息不符，未提及纳斯达克100指数的表现和Lucid及Zscaler的具体跌幅，且聚焦于中概股而非纳斯达克100指数成分股。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2299
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比，省略了美股三大指数集体收跌的具体描述，但未引入事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2298
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details such as the factory being 'still closed' and the measures taken to ensure supply, contrary to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2310
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了关于赎回金额的具体信息，这是一个重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2311
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了华为菲律宾公司的具体名称，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2306
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少美股休市的信息，且未提及API和EIA原油库存数据的推迟情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2307
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'所有'一词，导致准确性略有下降，但没有出现事实性错误或显著冗长的问题。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2309
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the research and development of multiple forecast products and the provision of meteorological support for the Winter Olympics.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2308
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中Ark基金减持Iridium Communications的信息正确，但遗漏了增持Surface Oncology的信息，且与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2304
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific details about the '女足' search increase and the '中国体育'小程序访问增长, which are critical points in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2289
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的焦点不同，实际输出强调了一次性技术的国产化浪潮，而预期输出关注的是生物制药产业上游原材料的国产化趋势。实际输出包含更多细节但偏离了预期输出的主要观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2316
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in content and structure, focusing on fiscal revenue growth rather than the expected commentary on optimizing fiscal policy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2312
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific deadline of June 30th and does not include the completion of key tasks as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2303
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by stating that the感染者's核酸检测结果均为阴性 instead of focusing on the close contacts and secondary close contacts' first round of核酸检测结果均为阴性.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2318
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含美国产量不足的信息，且略去了市场分析师Irina Slav的具体观点，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2317
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about surpassing宁德时代and does not reflect being the '公募最爱'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2322
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中缺少了'抢运'这一重要信息，未能完全体现新闻中的关键动作。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2314
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了11月原油产量创新高的信息，并且没有提及出口量和产量的具体数字和增幅，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2319
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及首套房公积金贷款额度提高，忽略了二套房贷款额度的提高及不支持购买第三套房的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2313
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少意大利工业家联合会的来源信息以及能源价格飙升的具体影响，且没有提及对2022年国内生产总值的影响，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2321
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有事实上的矛盾，且长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2325
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits important details about Omicron variant vaccine research and clinical trial status in the overseas market.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2320
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含宝龙地产的相关信息，且融创中国和碧桂园的相关细节也有所简化，但没有出现事实上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2332
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少重要细节，如解禁市值、涉及的具体公司等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2323
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，没有重要细节遗漏，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2324
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容不符，实际输出没有提及与法国兴业银行子公司的合资，而预期输出明确提到这一点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2331
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output mentions battery CTC technology which is not in expected output, and omits the detail about investment in Sweden.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2328
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="Actual output lacks specific mention of Berlin prosecutor's office and the names of the officials involved, leading to less accuracy compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2336
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含调查这一重要细节，且语言较为简略，但未出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2327
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出中提到销售收入同比减少53.15%，而预期输出中提到销售收入环比减少5.63%，存在事实上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2326
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了预期输出的所有关键信息，但净利润增长率的范围略有不同。实际输出比预期输出更具体，但差异很小。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2333
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output omits details such as the date and the reason for the emergency declaration, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2329
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output contradicts expected output by stating华润资本领投, which is not mentioned in the expected output and omits the involvement of招商局资本等 investors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2341
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2334
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the joint stance against military action and the emphasis on political and diplomatic solutions outlined in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2337
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the critical detail of the 13-month continuous increase before the decline, which is present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2330
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及南非确认奥密克戎毒株的时间点，且未提及加州和得州的废水样本情况，重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2345
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the absence of new local cases, which is an important detail from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2344
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少召回汽车数量的重要信息，且没有提及召回的具体车辆型号和数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2339
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output lacks specific expected details like the amount and percentage of company revenue, but does not contradict any facts from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2343
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中包含了关键信息，但略去了'申请第二次住房公积金贷款'这一重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2340
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了预期输出中的重要细节，如'稳增长'政策和市场情绪修复的预期，仅提到了情绪底的时间范围。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2347
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'统计局'这一重要机构，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2335
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，实际输出仅描述了数字人民币在北京冬奥会的部分使用场景，而预期输出要求提供关于数字人民币的问答形式内容，涉及冬奥会消费场景。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2338
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output lacks specific information from expected output such as '私募：' and the direct quote 'A股将展现自身的运行韧性 跟随海外市场的几率不大'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2355
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omitted critical details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2348
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific conditions for nuclear and natural gas to be considered sustainable investments and does not mention the technical and emission criteria for corresponding projects.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2342
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出遗漏了摩根士丹利的建议和对美股熊市状态的描述，仅包含了标普500指数的公允价值和日内波动的描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2350
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the focus on socioeconomic development amid the pandemic and does not mention any of the specific issues discussed.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2363
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='遗漏了关于上半年风格预计较为均衡的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2352
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the detail that the inflation rate will fall within the year and does not specify that the current high inflation is temporary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2315
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出内容基本一致，但用词略有不同，实际输出为'预计2021年净利润同比增加211%-233%'，而预期输出为'2021年净利同比预增211%-233%'。实际输出略长，但没有引入新的信息或价值。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2349
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits details about the joint statement on the Nuclear Non-Proliferation Treaty but still captures the main point about transferring blame.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2360
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的信息不一致，且遗漏了重要细节，如合规审查的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2356
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未提及欧元疲软的影响，缺少重要细节；但总体上描述了汽油价格创新高及乌克兰冲突的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2369
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了项目合同的具体内容，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2357
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中阿里巴巴文化娱乐有限公司变更为上海全土豆网络科技有限公司全资持股，与预期输出中阿里大文娱改为间接持股有事实上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2354
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output mentions the vaccine's combination but omits the single dose aspect and the potential launch in autumn 2023 mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2358
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中的重要信息，如南粤银行的两大股东破产情况以及新控股股东的背景信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2359
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits significant details about the specific amounts and entities involved in the增资扩股, which are crucial facts present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2361
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出仅提到了流量增长，但没有提及创新高，且缺少具体流量数据和时间细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2351
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="缺少'中国有色协会'的具体提及，且'单晶硅片价格继续上涨'的信息不够详细，未包含具体涨幅和不同型号硅片的价格变化。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2362
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提到了消费股成为青睐的投资方向，但没有提及医药股被减持和持仓分散化，遗漏了重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2353
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details about the number of institutions and individuals involved in the survey, as well as the specific inquiries and responses, and does not mention the expected growth for 2022.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2365
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the timing of the news and the perspective of private funds, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2367
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关键细节，如合作方和签署协议的内容，仅提到了项目本身。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2346
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出提供了更详细的自购基金公司的数量、自购金额和基金类型，但与预期输出相比，信息更加冗长且没有直接提到'公募年内已自购超5.4亿元'这一关键信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2374
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中的固定利率操作信息，且未提及扭转国债走势。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2364
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含的信息与预期输出不符，遗漏了发行可转债募资的关键信息，且添加了收购股权的信息，这超出了摘要的基本要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2366
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了与金海锂业签订合同的具体类型，即‘设计、设备供货及安装总承包合同’，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2373
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details such as the overall power supply and demand balance, and the range of coal power generation proportion.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2368
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出存在矛盾，实际输出称欧洲股市将表现出色，而预期输出则表示欧洲股市已对欧洲央行的鹰派立场进行了定价，两者信息不一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2370
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及办公室租约的具体细节和预期输出中的计划销售准备信息，且实际输出比预期输出更简洁，但缺乏关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2375
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了中信银行的股票代码00998.HK，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2376
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出提到储能成为多地政府工作报告的重点，但未详细说明是2022年的重头戏，缺少了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2378
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出的主要信息一致，但主体顺序不同，实际输出将黑芝麻智能置于黑莓之前，而预期输出相反。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2371
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output mentions CEO's statement and reasons for price increase but omits the specific number of times the price will be raised this year and the implication of multiple price hikes as indicated in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2372
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出强调了代表人诉讼常态化开展，而预期输出则要求推动相关立法，两者重点不同且实际输出遗漏了预期输出中的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2384
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output omits the key detail of '战略退出热电业务', which is important in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2382
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits details about the specific units and numbers of soldiers mentioned in the expected output, leading to less accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2381
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了企业生产保持稳定的重要信息，且省略了统计局的来源，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2383
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output provides specific locations adjusted to medium risk but is more detailed than expected, which is slightly longer without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2379
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits the '秘书长' (Secretary General) title and the organization '乘联会' (CPCA), which are mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2377
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了京津翼“3+N”联盟的具体名称和集采启动的重要信息，且未提及近90%的降价幅度，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2390
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details about the competition and the shared involvement in battery asset company compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2397
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了多地网友的反馈和具体的修复情况，且未能准确反映网络故障的原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2385
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了对'迫在眉睫的燃料短缺'这一关键细节的描述，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2394
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少大金融板块强势护盘的重要信息，且指明创业板指跌幅居前的信息被省略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2398
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific amount of签约金额 (283.02亿元) and only includes the percentage decrease.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2392
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，仅在注册资本表述上略有不同，但未引入事实错误或重要细节遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2396
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了新闻中关于加息预期和价值股复兴的重要信息，且与期望输出的标题风格不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2386
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了多项重要细节，如推进深层次改革、出台自贸试验区跨境服务贸易负面清单等，与预期输出存在显著差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2395
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the key detail that 7 out of 16 members are listed public companies, which is a crucial piece of information from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2391
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但比预期输出多了一些细节，如订单产品结构复杂、钢材价格上涨等，导致内容略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2389
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中93宗与本地个案相关的描述与预期输出中的100例本土病例数目不符，且遗漏了7宗源头不明的病例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2380
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了所有关键事实，但累计确诊病例的表述方式与预期输出略有不同，实际输出使用了具体数字10889417例，而预期输出使用了约数1088万例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2393
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的是2021年的会议，而预期输出中提到的是2022年的会议，存在时间上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2400
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the context of other mining companies joining the trend and the environmental benefits, which are important details present in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2388
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了提供指导这一信息，但忽略了加密货币对银行业的风险这一关键点，且比预期输出详细得多，却没有提供实质性的额外价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2387
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes an incorrect detail about the Iranian minister's name, contradicting expected output. Also, it omits the critical information about the announcement of the 25-year comprehensive cooperation plan's implementation.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2407
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了预期输出中的签约信息和具体位置湖南省郴州市安仁县，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2399
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中省略了预警系统的重要细节，仅提及扩大监控范围，而未明确指出是针对关键品目预警系统的扩展。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2405
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical information about the reasons for closure and the involvement of Toyota, reducing its accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2415
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未提及补偿总额和对上市公司利润的影响，缺少关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2409
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出基本一致，但缺少消息来源（美媒）和消息人士的具体描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2410
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了开年以来的时间点和京沪深三大交易所的具体信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2404
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the specific areas designated as封控区,管控区, and防范区, and does not mention the implementation of public activity restrictions as expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2403
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提到了票价上涨18%和观影人次减少了近2000万，但遗漏了春节档票房位列史上第二的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2416
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'上市流通'这一重要细节，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2411
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了白皮书的引用，并且没有包含预期输出中的具体探测任务细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2402
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the number of new stocks breaking even on the first day and the exact increase in the number of abandoned purchases, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2413
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了贸易额的具体数字和增长情况，但忽略了预期输出中关于中国连续第六年成为德国最大贸易伙伴的预测。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2414
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the key phrase '打造社会主义现代化建设引领区', which is crucial as per expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2408
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了病例涉及所有风险点位已完成核酸检测的重要信息，且与预期输出相比，省略了关键内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2406
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits some details about the emergency response mechanism and the employee's area being investigated, but accurately states the status of the flights. The length is appropriate without unnecessary information.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2421
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少了关于犬用注射的信息，且与预期输出对比略显模糊。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2429
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='The actual output matches the expected output exactly, with no contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2417
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了虎元素饰品走俏的事实，但缺少了春节前这一时间点，同时专家观点虽一致但具体描述有差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2424
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning the expansion of global production and the provision of原料药(API) details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2412
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了商务部贸易救济调查局负责人的评论和背景信息，仅提及了希望美国采取行动应对气候变化的部分内容，未能全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2419
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出包含了关键信息，但缺乏对新闻来源的提及和德媒的角度说明，且长度超出预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2420
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键细节，如持有24小时内核酸检测阴性证明的要求，且未明确指出地点为广东珠海。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2425
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了出售价格和其他关键细节，且未明确说明45亿元的交易金额。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2423
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了病例的家庭关系信息，但忽略了病例的确切位置三河市，且未提及日期和来源。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2422
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关键细节，如联电2022年第一季度晶圆价格涨幅和整体毛利率的预期，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2433
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the number of regions and the split of the original Southwest region into two new regions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2418
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了该激励计划是2022年的关键细节，且未提及激励计划的具体授予价格和涵盖人员，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2431
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output omits the detail about the price increase per full tank of 12 yuan, reducing accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2401
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific details about the distribution of cases in different provinces and cities mentioned in the expected output, such as the cases in Texas, Guangxi, and other specific locations. Additionally, the actual output does not match the expected output's emphasis on陕西新增5例本土确诊 and 广西新增1例本土确诊.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2432
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出没有包含预期输出中的所有信息，特别是关于乌克兰继续在俄罗斯境内运作的外交机构的部分。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2439
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="Actual output omits the stock code '01347.HK' from the expected output, resulting in less accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2440
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by providing more specific details about the types of vehicles and the production plan, which were not mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2435
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the involvement of multiple departments and the specific theme of the meeting.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2444
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未提及净利润的具体金额范围，但未出现与预期输出相矛盾的事实，且长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2430
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on the pressure on fiscal support rather than the rational and objective view of the fiscal surplus. Additionally, important details from the expected output are omitted.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2434
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键细节，如全力保市场主体支撑就业和支持培养万名企业新型学徒的内容，并且没有提及赵永峰的身份和完整信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2446
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含机构分析，且未提及修正或熊市的具体情况，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2428
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了额外的细节，如减免债务利息和豁免罚息的信息，而预期输出中并未要求这些细节。实际输出与预期输出相比稍长，但没有引入新的错误信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2442
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出遗漏了明珠煤业49%股权和交易总价70.42亿元的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2443
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the 3-year increase in stocks and the total increase of over 1.2 trillion yuan in stocks and bonds.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2441
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了主要的市场表现信息，但缺少了题材板块普跌和超百股跌停的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2426
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了部分重要信息，如黑色系期货夜盘多数上涨及焦炭、焦煤、动力煤领涨，但缺少了铁矿石期货收跌的信息，且与预期输出相比，信息覆盖不全。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2427
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中的陈述比预期输出更确定，直接表示拜登将提名非裔女性，而预期输出中使用了'或'表示可能性。实际输出没有包含普萨基的声明细节，略去了一些重要信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2450
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="实际输出缺少了'十四五'这一关键时间点，使得信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2438
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出仅提到了上证指数的部分数据，而预期输出要求提供春节后首个交易日A股的历史数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2436
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的“年内首次实现正增长”与预期输出中的具体数据不符，且遗漏了关键数据371亿元和2019年农历同期的同比增长率28.6%。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2448
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含盈利能力显著增强和经营业绩大幅增长的重要信息，且与预期输出相比略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2449
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提到了5G基站数量，但未包含预期输出中关于全球占比的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2447
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实性矛盾，未遗漏重要细节，长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2451
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the key information about培育一批装配式建筑生产基地, which is an important detail from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2437
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits the key information about the expected 15万吨新增预制菜产能 by 2022年底 and contradicts the expected output by only focusing on the 2021年预制菜产能.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2456
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未完全反映预期输出的内容，缺少对未来煤价上涨态势的描述，且与预期输出的语句不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2460
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了净利润的增长率，但忽略了净利润的具体金额范围，且长度较短，信息量不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2463
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output mentions the consecutive awards but omits the specific award year and the project details mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2462
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少注册资本的具体数值，只包含了增幅，而预期输出中包含了注册资本增加后的具体数值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2457
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning BioNTech and the expected approval date, and it provides less detail about the vaccine approval process.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2453
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output as it does not mention the price target adjustment or the buy rating, focusing instead on the average selling price of iPhones.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2455
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes key information from expected output but adds more detail about the person responsible for the statement. Length is slightly longer without significant additional value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2445
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中净利增长范围为55%-69%，与预期输出的55%-70%略有不同，但仍保持了主要信息，仅在上限值上略有差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2452
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，省略了美国小盘股与欧洲同类股票相比面临更大风险的关键信息，且未明确指出策略师的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2464
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了超资产规模申购的信息和对网下打新乱象亟待规范的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2459
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='The actual output exactly matches the expected output, with no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2454
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的是T3出行关联公司成立新公司，而预期输出则直接说是T3出行成立新公司，这导致了信息的不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2468
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits most details from expected output and focuses only on one aspect, leading to reduced accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2458
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于2022年营业收入增长率不低于150%的重要信息，且没有提及激励计划的具体业绩考核目标。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2466
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了一些重要细节，如主动和被动型基金费都将下调，以及关于交易客户比例和投资组合再平衡的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2483
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预期的增长率，但未明确指出净利润。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2467
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及Meta对美股科技板块的影响和市值缩水情况，且标题过于简短，缺乏关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2465
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中忽略了关于加强太空交通管理、建设完善空间碎片监测设施体系、信息防护能力等方面的重要细节，仅提及了部分航天器维护工作。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2473
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出中缺少了火灾扑灭和无人员伤亡的关键信息，且没有提及火灾的具体时间以及消防部门的救援行动。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2471
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual Output contradicts Expected Output by focusing on a different article title and adding unnecessary details, while Expected Output is concise and accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2470
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不一致，实际输出提到的是婚育推迟现象，而预期输出的重点是生育旺盛期妇女的减少情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2476
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含期望输出中的薪酬组成部分的详细信息，但没有引入事实错误或显著增加长度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2478
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了Ventana Micro Systems Inc与英特尔的战略伙伴关系的内容，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2479
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key information about digital currency and blockchain pilot projects mentioned in the expected output, leading to significant omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2475
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出提供了预期输出的内容，但增加了公司优化管理、做好疫情防控和安全生产等细节，虽然这些信息增加了文本长度，但没有明显增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2477
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了利息展期方案获通过的具体内容，且未明确提及新闻中的7月29日付息信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2480
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on different key points and omitting important details about creating advantages in publishing, printing, and distribution enterprises.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2486
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the forum and minister's speech, focusing only on the joint initiative release.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2484
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少预期输出中的关键细节，如交易员准备迎接美联储利率决定和互动投资者分析师的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2474
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了投机者的行动和分析者的来源，但与预期输出相比，信息过于具体且引入了额外的细节，而预期输出要求更简洁的总结。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2472
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出强调了一次性技术的国产化浪潮，而预期输出的重点在于生物制药产业上游原材料国产化的趋势。实际输出忽略了预期输出中的核心信息，即上游原材料国产化的趋势。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2490
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了能源板块的具体涨幅和本周的表现，且整体收涨的幅度描述不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2469
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了预期输出的信息，但加入了额外的细节，即VR设备在ToC端社交、健身等领域的应用，这虽然不违背预期输出的核心信息，但并未完全符合预期输出的简洁要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2487
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the detail '第五批' which specifies the batch number, but still conveys the main information accurately.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2493
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits that multiple lithium battery products have already been launched, contradicting important details in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2488
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output includes more specific details about exceeding market expectations but omits specific analyst estimates, resulting in less accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2485
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="Actual output contradicts expected output by denying Chime's partnership with Goldman Sachs for IPO, while expected output suggests they are planning to work together.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2461
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='The actual output contradicts the expected output by incorrectly stating Alysa Liu as the youngest athlete without mentioning the total number of athletes, and it introduces a factual error by not specifying the oldest athlete and incorrectly identifying Alysa Liu as the youngest without proper context.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2491
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了项目落户四川成都的关键信息，仅提到了签署协议，而未提到项目落户的具体地点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2489
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了预期输出中的关键细节，如交易员评估货币政策和经济数据，且实际输出更长但未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2492
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出中的重要细节不符，实际输出提及了证监会，而预期输出指明是央行等部门，且实际输出提供的信息更加详细，但重点偏离。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2497
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少累计确诊数量等重要信息，且长度显著短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2496
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，仅顺序不同，未发现事实性错误或重要细节遗漏，但长度略长于预期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2500
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了投诉涨幅发生的具体年份，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2495
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了英国监管机构对设施适合在英国建设的确认，且没有提及需要深入评估和获得许可的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2506
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key facts from expected output and includes additional irrelevant details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2481
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits '国家' before '发改委', which is a key detail in the expected output. The omission of this detail changes the context and importance of the source of the policy, making the summary less accurate.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2501
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未提及子公司名称和2021年度名单，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2503
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中忽略了预期输出中关于互联网企业要坚持守法经营，努力做大做强的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2499
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出忽略了预期输出中提到的基建项目和市场对信贷增长的乐观预期，仅概括了信贷投放规模预测。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2482
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了关键信息，但使用了更详细的描述，如'重组新型冠状病毒疫苗（CHO细胞）'，而预期输出简化为'重组新冠疫苗'。实际输出没有遗漏重要细节，但略显冗长。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2508
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the target price of 140 HKD, which is an important detail from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2494
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by mentioning房贷利率下调, which is not aligned with the consistent rates in Beijing and Shanghai mentioned in the input. Additionally, it omits details about the varying situations in different cities and the purpose of LPR adjustment.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2515
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了年内偿债压力巨大的重要信息，且没有完全包含预期输出中的关键数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2514
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="实际输出缺少了具体的地理位置信息，即'广东中山'，导致信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2505
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到量化基金集体平仓和公募公司护盘，但没有提及量化基金助推市场下跌这一关键信息，且与预期输出内容不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2521
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有出现任何矛盾或遗漏重要细节的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2511
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及拿下全国独代的重要信息，且长度远短于预期输出，遗漏了关键的销售协议细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2518
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中的净利润具体数值，且措辞略有不同，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2509
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出遗漏了预期输出中的关键细节，如'上半年行情的起点正在临近'，导致信息不准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2504
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了美方呼吁中国利用对俄罗斯的影响力促成以外交方式解决乌克兰危机这一重要细节，只提到了外交部关于《新明斯克协议》的立场。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2512
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by adding unnecessary details about demonstration projects and specific engineering names, which were not mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2502
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅包含了预期输出的内容，但严重遗漏了新闻中的其他重要细节，如减污降碳协同增效、温室气体数据管理、国际气候谈判等内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2517
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output mentions home office but omits the current good state of the prime minister as stated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2527
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了凭绿码进出小区的重要信息，但未引入事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2507
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中省略了新闻来源的详细信息，仅提及了CINNO Research，而预期输出中使用了更通用的表述'机构'。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2516
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by stating that the negotiation has just started, instead of highlighting the positive impact of the potential agreement on bilateral trade.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2510
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含的信息不够详细，没有提及投资与减债平衡的财政政策，且未反映关于经济增长和财政稳定的具体内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2519
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了德意志银行的名称和苹果股票代码AAPL.O，且未提及苹果的增长前景。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2525
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未提及海淀地区，且缺少病例近14天内无外省市旅居史的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2530
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about current capacity and plans to adjust sampling points, introducing less accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2522
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中缺少了关于中标项目的具体描述，即'雨污排水管采购'，这使得信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2524
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output includes additional factual information that is not present in the expected output, introducing extra content without matching the expected summary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2532
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出和预期输出完全一致，但是实际输出省略了合作项目的具体内容，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2498
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by mentioning '国家体育总局发布《冰雪运动标准化白皮书（2021）》' instead of '市场监管总局立项一批冰雪运动国家标准', and omits the key point about the standardization efforts to promote mass participation in winter sports.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2534
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了航班取消的具体数量和受影响的机场细节，仅概括了风暴影响多条航线。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2513
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中包含了世贸组织认定美国措施违反规则的内容，但未明确世贸组织的判决；同时，实际输出比预期输出提供了更多的细节，但这些额外信息并未违背预期输出的核心信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2531
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the specific measures and objectives outlined in the expected output, focusing only on the general statement of three work aspects.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2523
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on the Fed rate hike expectations rather than the change in US stock indices and the divergence in short-term and long-term yields.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2528
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key detail of the total amount due (18.8 billion yuan) and does not specify that the amount includes both principal and interest.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2535
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了'中标'这一关键信息，导致内容不够准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2533
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits critical details such as objectives and improvements in circulation system mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2529
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the celebration of Chinese New Year and the main context of the event, despite including a key figure's action.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2536
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the recovery likelihood and timing compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2520
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了子公司通过安全生产许可的信息，但省略了新疆天河化工有限公司的具体名称和扩能项目的规模描述，而这些细节在预期输出中是明确的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2537
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键信息，但比预期输出长且未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2526
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅包含预期输出的第一句，忽略了预期输出中的详细信息，包括习近平的具体讲话内容以及论坛的开幕信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2543
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有包含额外信息或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2545
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by focusing on price trend instead of capacity gap and average price range.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2538
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及新增本土确诊病例明显下降这一重要信息，导致遗漏了预期输出中的关键事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2542
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含股票代码00258.HK，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2546
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含关键信息，但遗漏了滤波器芯片研发生产的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2541
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output includes specific product types omitted in expected output, but expected output is less detailed. No contradictions found.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2540
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the fact that it was a record-breaking day as stated in the expected output and input data.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2549
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含期望输出中的“表决”一词，略去了该重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2550
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing a different focus, mentioning digital产业集群 instead of green消费支持政策.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2539
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及平台推动全球普及应用的重要性，且未强调这是由合肥市大数据公司与合肥本源量子计算科技有限责任公司共同打造的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2548
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少关键细节，例如具体被撤出的公司名称和持股信息，以及由全资子公司代持股份的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2553
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但使用了确切数字范围而非四舍五入后的范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2551
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了关于解决“卡脖子”问题的具体措施和深化产教融合改革的内容，且标题重点与预期输出有所偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2547
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，但实际输出省略了净利润的具体范围和部分关键细节，如生产成本降低和爆破服务增加。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2561
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关键信息，如顺丰集团的消息来源和商业试运行的详细许可类型。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2555
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了加氢站和绿电供应等重要信息，且与预期输出的主题不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2558
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits important details about the expected ways of greeting and family gathering limits.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2557
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the cumulative confirmed cases exceeding 406 million, which is an important detail from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2544
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了元宇宙虚拟实境装置设计轻巧化的信息，但缺少了'存储器大厂'这一关键描述，且与预期输出相比，信息略显冗余。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2563
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到租船人为航运排放量付费的关键细节，且内容与预期输出的主题不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2562
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing a different target price and missing the rating adjustment.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2554
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了比预期输出更多的具体信息，包括GDP数值和两年平均增长率，但没有完全遵循预期输出的简洁性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2568
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了预期输出的所有关键信息，但是比预期输出更详细，没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2566
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the specific price adjustment range of 1000-7000元不等 mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2569
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出包含了额外的细节，但这些细节并非预期输出所必需。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2560
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了欧洲央行行长拉加德讲话缓解加息焦虑的重要细节，且没有提及收益率上升的具体时间。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2552
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output mentions the wrong variant (Delta instead of Omicron) and omits the key information that the Omicron variant's associated疫情已基本得到控制 (has been basically controlled).", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2573
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific details about the 'mask order' and the behavior of passengers, which are crucial in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2564
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="Actual output omits critical information about the fourth quarter's sales decline and only highlights the annual growth, contradicting the expected output's focus.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2559
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出在关键信息上基本一致，但用词略有不同，实际输出中未明确提到A股有望走出独立行情，略显不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2567
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output omits details about the performance of the oil and gas sector and the overall market sentiment, while focusing more on the infrastructure sector.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2582
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出缺少了年份和交易所名称的重要信息，且表述不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2570
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output mentions a Ukrainian economist's warning but omits the origin of the warning and the specific details from the expected output, such as the name of the organization and the exact warning content.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2565
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了通胀率创20年来新高的事实，但使用了'20年来'这个表达，而期望输出使用了'二十多年以来'，导致时间范围的不完全匹配。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2574
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出中的关键信息，但用词稍有不同。实际输出比预期输出更长，但并未引入多余信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2572
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出省略了具体的净利润范围40.98亿元-48.11亿元，导致信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2580
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了预期输出未提及的具体修订内容，导致信息冗余；同时遗漏了向社会公开征求意见的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2575
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的跌停信息与预期输出不符，且错误地将自然人买入金额101.57亿元误认为是中小投资者的买入金额。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2578
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了新闻中关于汤姆猫被调研以及调研方的具体信息，仅提及了业务探索阶段的内容，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2584
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，但实际输出省略了净利润的具体范围，略显信息不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2556
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的主题不一致，实际输出只提到了外资规模创新高，而预期输出强调了中国市场对外国投资者的吸引力增强。实际输出缺少了预期输出中的重要信息，且未体现中国市场的吸引力和外资引力稳中有升的主题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2581
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了地缘政治风险和供应不足的关键细节，只提到了油价达到100美元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2576
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到比特币和以太坊‘不可能比较’，而预期输出强调了对两者保持高度信念。实际输出缺少了对两者都保持高度信念这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2589
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details from expected output, such as the specific conditions for外出 and the resumption of business activities.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2590
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了具体的日期信息和撤离人员的家庭成员，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2577
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the发言人身份 and the specific quote about positive dialogues needing action, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2595
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了资金用途的具体项目信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2571
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了一些重要信息，如依法依规严肃惩戒，但比预期输出多了具体措施，且未提及违反后的具体后果，如追究法律责任和失信惩戒，因此略显冗余且遗漏关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2579
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及了澳元兑新西兰元可能进一步上涨，而预期输出则包含更多具体信息，如新西兰防疫措施可能收紧和汇率上探5月高点的预期。实际输出遗漏了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2591
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了年产10万吨的具体信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2585
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但缺少了一些预期输出中的具体信息，例如年度和亏损范围的表达方式略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2583
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the total出资额of 5000万元 and the specific roles of two subsidiaries, which are important details present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2586
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含特定地点名称和防控措施，但未提及风险等级调整的具体信息，且比预期输出详细得多，但未完全涵盖预期输出的关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2587
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the specific phrase '拆东墙补西墙' which is crucial to convey the exact situation described in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2597
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了重组事项的关键信息，仅提到了吸收合并，而预期输出中明确提到了重大资产重组。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2592
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了一些重要细节，如雅居乐出售股权给中海的具体信息，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2588
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了美股期货上涨这一重要信息，只提到了国债抛售缓和的部分，且未能反映预期输出中的机构分析视角，因此准确性不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2593
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the fact that it's the first decrease in 20 months and does not specify that it's related to the housing loan rate, which are important details from expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2596
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the reason for the ban and the nature of the protest, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2599
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出忽略了与中融信托进行进一步沟通的重要细节，仅保留了坚持不逃废债的原则。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2601
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'获批国家'这一重要细节，但没有引入事实错误或显著增加冗余信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2603
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the total population and the role of new immigrants in population growth.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2621
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradiction or omission.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2598
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like specific safety management measures and the mention of the Winter Paralympics, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2604
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的事实不符，玉米和大豆期货的价格方向错误，且未提及芝加哥小麦期货的表现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2600
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未提及出资额2.75亿元，遗漏了关键细节；但未出现事实性错误，整体表述简练。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2594
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific detail of China Red Cross providing $100,000 in emergency humanitarian aid, focusing instead on a general commitment to further assistance.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2602
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the number of product specifications and the recent market introduction of the products, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2607
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现事实上的矛盾，也没有遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2606
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了关于公司控制权未发生变化和目前生产经营一切正常的细节，且长度显著短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2611
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output precisely without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2605
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含部分事实但未准确反映预期输出的关键信息，如监管力度和问题公司加速出清等内容缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2609
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，没有遗漏重要细节，长度也相等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2613
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the call for policy flexibility and specific mention of the negative effects on emerging and developing economies, reducing its accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2620
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about the meeting's content and fails to mention the specific areas of cooperation and European security issues discussed.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2615
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关于病例为轻型的重要信息，且未提及具体的日期和病情详情，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2618
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含日期和部长会面的信息，略去了部分重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2610
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the fact that the subsidiary is a '控股子公司' and the增资扩股process. It is less accurate compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2616
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出省略了奥密克戎毒株传染性强和'通吃'的关键信息，降低了准确性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2608
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出与预期输出几乎相同，只是将'非盟委员会'替换为'非洲联盟委员会'，未引入事实错误，未遗漏重要细节，但长度稍有增加。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2617
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键事实，但添加了不必要的细节，如“我国承建”，这在预期输出中并未提及。输出长度略长，但没有引入新的事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2625
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含重要信息，但遗漏了测试赛已使用的细节，且比预期输出更长，未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2634
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了净利润的具体数额和同比扭亏的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2614
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中的关键信息，如具体日期（周五）和调查来源（机构调查），并且没有提到加息的原因和市场对通胀数据的关注。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2622
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少预期输出中的关键信息，如与特斯拉4680电池的比较，且未提及能量密度大增的具体背景和目标客户。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2628
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了调控次数和稳楼市政策的具体措施，未能涵盖预期输出的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2624
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提到了最低工资标准的提高，遗漏了养老金和医保调整的重要信息，且与预期输出相比不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2630
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了同比增长0.3%这一重要细节，且未包含地方和中央预算支出的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2633
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了终止运营的关键信息，但具体日期表述略有不同，且未完全采用预期输出中的表述方式。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2645
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='缺少转让方信息，未明确指出首创集团是转让方。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2626
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了微信支付的信息，而预期输出未提及，导致信息多于预期。但实际输出并未遗漏关键信息，且未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2636
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出缺少了病例的具体小区名称和密接者的信息，但没有出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2627
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，实际输出强调了新兴市场受益于加息，而预期输出表示加息不再注定对新兴市场是厄运。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2629
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少一些重要细节，如西班牙与葡萄牙的申办背景和英足总的退出。但没有出现事实上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2612
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的内容不符，实际输出提到了证券时报的评论，而预期输出要求的是经济日报的内容。实际输出虽然提到了土地出让溢价率的调整，但并未准确反映预期输出中‘房住不炒’的核心主题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2637
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含斯迈洛夫为新任总理这一细节，但未发现其他矛盾或冗长问题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2632
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中未提及增持次数及'木头姐'的称呼，且缺少具体增持细节，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2623
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the concern over yield curve flattening and the economic slowdown in 2023, and introduces a simplified view that does not fully represent the complexity of the expected output's message.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2631
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts the expected output by mentioning the year 2025 instead of 2023 for the initial establishment of the standard system.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2638
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by including information not present in the expected output and omits key details from the input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2647
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少预期输出中的关键信息，如智能汽车创新发展和燃料电池汽车示范应用。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2619
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的主题不符，实际输出强调了中长期向好的趋势，而预期输出侧重于外部冲击导致的回调和风险偏好的修复。实际输出还遗漏了预期输出中关于反弹可期的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2641
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the number of districts involved and the time frame, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2635
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='存在事实上的矛盾，实际输出中提到了取消的是新冠病毒检测或强制接种疫苗的要求，而预期输出中只提到了取消疫苗接种规定。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2639
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中缺少了奥密克戎毒性不可忽略的关键信息，且未提到病例激增可能对社会医疗资源的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2643
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes specific details about the rocket used which are not present in the expected output, making it less concise.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2648
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details about strengthening research成果转化和推广应用力度 and providing strong technological support, which are crucial elements from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2646
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及从哈萨克斯坦撤离的事实，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2649
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了核酸检测结果均为阴性的关键信息，且与预期输出相比不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2644
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出基本一致，仅缺少一个中文逗号，未引入新的事实，也未遗漏重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2642
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容不符，实际输出仅提到了关于复产的信息，而预期输出则需要维持买入评级和给出目标价，缺少关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2652
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出遗漏了'冰火两重天'这个关键描述，未能全面反映新闻内容。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2651
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出的核心信息一致，均指出芯片供应紧张将持续较长时间，但实际输出略长且细节略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2654
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有事实矛盾，没有重要细节遗漏，长度也一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2653
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少新闻来源和招标金额的具体信息，与预期输出相比略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2640
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含'外媒'和'政客'等关键信息，且标题中的动词使用'提出'比预期输出中的'提'更具体，但缺少'新议案'和'欲阻'这样的细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2657
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了Peloton的定性描述和潜在收购背景，降低了信息的完整性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2670
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有提及丰田以及其他企业的停产计划，缺少了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2660
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing on overall export figures instead of the proportion of exports from specific provinces.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2667
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了所有重要信息，但比预期输出更详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2650
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by not mentioning '国家卫健委', and omits critical details such as '昨日新增本土确诊病例104例'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2656
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了斯托克欧洲600指数的具体跌幅，仅提及了最大跌幅，与预期输出相比不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2662
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出的细节不符，如指数变化方向和幅度不同，且遗漏了大金融板块的表现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2674
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details about Warren Buffett's wealth increase and his performance compared to other billionaires.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2659
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output on the time frame (午后 vs 早盘) and the leading sectors (煤炭 vs 大金融).', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2666
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的航班取消地点和数量不准确，且缺少恶劣天气的影响这一关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2661
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了关于激光雷达需求量的具体预测，而只包含了市场规模的信息，未遵循预期输出中的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2671
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提及的开学时间与期望输出不一致，且忽略了具体年级的开学时间安排。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2668
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了更多的细节，但略显冗长，未完全遵循预期输出的简洁性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2655
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes all key details from expected output but adds unnecessary information about the company's board approval and NFX's investment areas, making it slightly less concise.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2664
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少引导外资投向具体领域的信息，且没有提及2022年的具体年份，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2675
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了收盘价较前一日下跌0.07%的重要信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2676
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了投资信息，但遗漏了建造至少两家半导体制造厂的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2673
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了航班取消的信息，但遗漏了多州进入紧急状态的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2669
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical detail about the location of the本土确诊病例 (Rizhao report) and does not specify the date mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2658
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了关键信息，但增加了'央行副行长'的职位描述，虽然这并不错误，但与预期输出相比略长且未增加实质性的信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2663
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了斯洛文尼亚领导人具体言论的内容，仅提及挑战一个中国原则，而预期输出中包含了斯洛文尼亚领导人称将与台湾互设代表处这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2672
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出和预期输出几乎一致，只是预期输出中包含了'公司'一词，而实际输出省略了该词，但不影响整体信息的传达。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2678
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的主要事实，但缺少了扩展到美国和每年开发额外容量的具体数字，以及交易完成时间等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2665
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只提到了纸企提价和利润避险，以及一季度提价的可能性，但遗漏了多家纸企发出涨价函、产能增速不及需求和纸浆涨价传导等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2677
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出包含了农业农村部的声明，但省略了汤加海底火山喷发未直接影响我国远洋渔业捕捞的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2679
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details about Peace and Securities, and Essence Securities obtaining the qualification, and does not mention the specific names of the 12 firms.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2687
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了欧洲央行加息预期降温的关键信息，且未提及意大利国债领涨的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2680
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason="实际输出缺少重要细节，如'十四五'期间的目标和计划，且未提及建设50个中医药国际合作基地等内容，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2681
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了净利润增长的预期范围，但略微简化了细节，如具体产品的收入增长情况和疫情对净利润基数的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2683
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about attracting and guiding foreign investment into clean and low-carbon energy sectors, focusing only on the incentive mechanism.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2688
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了关于多名网友分享类似经历的重要细节，且标题较为平淡，未能突出新闻的核心问题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2682
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了风城油田是中国最大超稠油油田这一重要信息，仅提及了累计生产原油超2000万吨。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2693
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了病例数首次超过5万的重要信息，且未提及连续5日创新高的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2686
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details about the construction of the酱香白酒品牌舰队and the mention of the specific brand '茅台', which are crucial elements in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2691
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少净利润的预计范围'2.5亿元-3.1亿元'以及公司业务发展的详细信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2685
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the increase in total number of trips and the recovery percentage of domestic tourism revenue, which are included in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2694
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，但实际输出中包含了具体的暂停通行措施，而预期输出较为简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2698
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含上游产销量稳步增长这一重要信息，且与预期输出相比略显简化。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2702
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出没有包含预期输出中的关键细节“备足子弹”，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2684
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details about the specific actions expected from internet companies, such as advancing the transformation and upgrading of traditional industries and reducing the operating costs of participants in the platform economy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2690
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了公司紧抓契机加大国际业务布局的重要信息，仅提到了依托火眼实验室平台的部分内容，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2701
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少发行价格这一重要信息，且未提及支付方式，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2696
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本相符，但实际输出省略了公司2021年净利润的具体范围，仅提及了同比增长百分比。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2689
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出的核心信息一致，但实际输出中包含了净利润的具体范围（1.4亿元-1.64亿元），而预期输出未提及这一细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2700
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于14项税费优惠政策延期的细节，且标题未能准确反映新一轮减税降费政策加快落地的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2697
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the mention of the specific date (March 1st) and the requirement to register the source or purpose of the funds, as outlined in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2699
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing a simplified version of the news content rather than a reiteration of the stock rating and target price as specified in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2703
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by providing details about growth hormone products instead of the impact of the centralized procurement, which was the focus of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2708
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts the expected source and introduces a different organization name, while omitting important details about the market focus and potential risks to gold price.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2714
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含刷新疫情以来新高的信息，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2695
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了保障性租赁住房贷款不纳入房地产贷款集中度管理，而预期输出要求提到全国已有20多个城市调整公积金贷款，实际输出遗漏了重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2692
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了北交所为专精特新企业开辟上升通道的事实，但未提及符合北交所上市标准的89家企业这一重要信息，且标题形式与预期输出不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2706
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by suggesting a continued rise in yields without acknowledging the peak near current levels and the expectation of a stable yield.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2707
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits some details such as the source (日媒) and the specific measures mentioned in expected output, but does not contradict any facts.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2712
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits information about cumulative deaths and recoveries, and uses exact numbers instead of a rounded approximation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2704
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，只是符号略有不同，没有引入事实错误。但长度上实际输出略长，因此扣分。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2709
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the notification for the Spring Festival and community epidemic prevention and control, focusing only on general health service assurances.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2705
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出偏离了新闻简述的核心内容，没有提及2022年贸易顺差对人民币汇率的影响，且引入了不同的主题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2710
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中提到的'超19亿元A轮融资'与预期输出无关，且引入了未提及的事实。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2722
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了关于免费订购的信息，但没有引入错误的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2718
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2711
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了购买金额，但遗漏了专业技术服务的重要细节，且比预期输出更长而未增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2713
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits crucial details like the reason for visa cancellation and the source of the information, deviating from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2719
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但多了“几款”的描述，略微冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2715
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出的内容基本一致，只是在句子结构上略有不同。但是，实际输出中缺少了关于融资规模和新增上市公司的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2723
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预中标金额和中国移动的信息，但未明确提及河北公司项目，略显不够详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2724
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有提到债券的具体到期年份和涨幅的具体数值，而预期输出中提到了这些重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2717
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中缺少法国CAC40指数、英国富时100指数和意大利富时MIB指数的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2731
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了与RCEP其他成员国之间的明确关联，导致信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2726
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中的“含预售”和“创影史最快纪录”的关键信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2730
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='缺少访问基辅的信息，且未提及斡旋俄乌边境危机的目的。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2716
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及新增100万例的5个半月时间范围，且未包含该时间范围内的增长情况，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2721
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了具体的信息，但与预期输出不符，缺少对防范化解经济金融重大风险的整体描述，且预期输出未提及具体实施方案。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2720
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the origin of the virus being from境外物品传入 (imported items from abroad), which is mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2729
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details such as the specific holding period for the fund and the announcement nature, reducing its accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2725
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by providing a single figure for market sales and year-over-year growth, while expected output includes a range of values for both.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2734
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中只包含了伦铜和伦镍的信息，忽略了其他金属的价格变化，且伦锡的跌幅信息也没有体现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2727
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in terms of the summary content, focusing on a specific aspect of冷链物流通道 rather than the broader modern logistics system.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2736
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，无任何事实性矛盾或重要细节遗漏，且长度适中。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2740
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了来源标注和活动名称的具体描述，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2732
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及与暴雪娱乐合作的具体产品和没有推出周边商品的计划，遗漏了关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2728
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未能涵盖预期输出中的关键信息，即各银行业金融机构要准确把握和执行好房地产金融审慎管理制度，导致输出准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2743
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了关于美国释放石油储备的具体表述，且没有明确提及受访者的具体言论。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2733
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出和预期输出内容基本一致，只是在'新车'一词上有所省略，未引入事实错误或重大遗漏。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2747
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了俄石油公司的声明性质，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2738
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但增加了产能利用率接近满负荷的内容，这虽然增加了细节但未造成冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2737
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于丰台区和房山区的具体描述，未能完整反映预期输出中提到的两地调整为中风险地区的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2741
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by not mentioning the hospital's involvement in medical disputes or its association with a public company. Additionally, it omits important details from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2739
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific sentence and the total amount of money involved, and introduces vague language that does not fully convey the severity and specifics of the case as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2749
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了关键的亏损信息，但措辞略显冗长，未完全匹配预期输出的简洁性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2752
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the fund name and potential发行时间, reducing accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2750
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'连续'这一重要细节，导致信息不完全准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2754
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the '北交所' prefix, which is an important detail from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2742
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key financial details like the total amount of 1946 billion dollars and the number of bonds issued, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2735
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on index stabilization and rebound instead of deep V-shaped market movements. Additionally, it omits key details about market bottoming out and deep V-shaped recovery as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2760
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出包含了预期输出的所有关键信息，但包含了额外的项目描述，略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2744
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出仅有细微的文字差异，且未遗漏重要信息。但实际输出中“收购”一词相较于预期输出中的“购买”略显模糊，可能引起理解上的细微偏差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2746
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出相比，仅在政府级别描述上略有不同，使用了'人民政府'而非'政府'，但未引入事实错误或遗漏重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2753
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits key details from the expected output and introduces new, unrelated content not aligned with the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2751
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于券商估值提升的预期空间这一重要细节，且未能准确反映业绩喜人的整体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2745
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the significant detail about 2021's high growth rate of 5G related enterprises and does not mention the year-specific information present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2748
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出相比，仅在措辞上有细微差异，未发现事实性矛盾或重要细节遗漏。但实际输出略长于预期输出，因此略有扣分。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2756
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了预期输出的关键信息，但添加了‘国家中医药管理局’而不是简写的‘国家中医药局’，增加了不必要的长度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2761
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少了净利润的具体金额范围，但未引入事实错误，语言简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2758
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出未提及新年期间猪肉价格不旺的现象，并且没有使用比喻'棉袄'来形象说明成本管控的重要性，信息不全面。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2764
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与期望输出基本一致，仅在标点符号上略有不同，未引入事实错误或重要细节遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2763
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了新增确诊病例和累计确诊的具体数字，仅提到了累计确诊的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2766
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output mentions the 2022 GDP target ranking instead of the 2021 GDP ranking as expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2759
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了广泛的内容，但未具体提到预期输出中提到的中小金融机构兼并重组和支持加快不良资产处置的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2757
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的时间（明年年底）与输入中的时间（今年年底）不符，且实际输出中对事件的描述过于绝对，而预期输出则更加保守和符合原文。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2768
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出缺少了'近一年'的时间范围描述，且没有明确指出是'申请破产重整'，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2755
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了对票房增长的预测，但缺少了预期输出中的具体数字85亿元和对票房可能达到的描述，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2770
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in terms of source and key message, focusing on a different angle compared to the expected summary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2765
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the detail of checking 450 internet game companies, which is an important fact from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2769
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了超短融占比过半的重要信息，并且没有提及具体的年份，准确性不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2775
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中缺少了博彩股上涨的信息，且恒指下跌的百分比描述不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2767
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output lacks details about the government's plan to adjust the medical system and the percentage increase in daily cases, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2762
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但预期输出中的百分比范围略有不同，实际输出为148.35%到183.51%，而预期输出为148%-184%。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2777
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on the short-term prediction instead of the mid-term investment advice.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2771
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了近10年春节前后上涨概率均是70%的重要信息，且长度明显短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2776
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了电煤库存超过1.62亿吨和较去年同期高4000万吨的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2778
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含陈光明和限购额度调整的具体倍数等关键信息，且没有反映放宽限购的要点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2782
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了中国公民的安全情况，但是增加了公司员工的信息，而预期输出只提到中国公民。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2783
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the specific company names and the scope of the partnership.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2779
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了净利润预期范围和下降比例的具体信息，且未提及净利润下滑的具体原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2772
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in terms of details provided and omits key information such as the comparison with 2021 and the specific tax rates.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2780
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了5年期主力合约的具体涨幅和现价信息，且2年期的变动未被提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2773
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于美股更大跌势和跑输世界其余地区股市的重要细节，且未能完全传达预期输出中的悲观论调。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2774
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits crucial details such as '全国首部' which specifies it is the first of its kind in the country, and introduces a less accurate summary compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2788
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了所有关键事实，但数字表述方式与预期输出不同，未采用亿为单位。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2785
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于全固态电池自主研发的重要细节，且未提及与SES合作的具体目标。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2784
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在重要细节的遗漏，未提及宁德时代动力电池业务处于高速成长期及具备中长期投资价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2786
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及公司回应上游硅料涨价的原因，且与预期输出的关键信息不完全吻合。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2793
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了控股子公司被诉的具体原因和涉案金额等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2791
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了关于延长产假的信息，但遗漏了关于研究出台更多积极生育支持措施的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2789
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the specific city name '百色市' from the expected output, but does not introduce any factual errors or contradictions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2787
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出基本一致，但将'八省市'简化为'8省市'，略微减少了信息的正式性和准确性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2794
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键风险地区数量信息，且与输入内容不完全吻合。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2792
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含上海地产接手这一重要信息，且长度较预期输出略短，但未出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2781
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific location '杭州' and does not mention '企业年会、婚宴等人群聚集性活动给疫情传播带来一定的放大效应', which are important details from expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2796
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中没有包含居民核酸初筛呈疑似弱阳性的关键信息，仅提到了小区的管理措施。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2798
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits '英国' and '稍晚时发表', and is less accurate compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2800
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了超出预期的内容，但遗漏了净营收的具体数值和市场预期，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2801
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the phrase '正式启动' which was present in expected output, indicating less accuracy but no factual contradiction or unnecessary length.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2809
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了配合调查和生产经营未受影响的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2790
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by mentioning the wrong authority (Changsha County Public Security Bureau instead of Hengyang County Supervisory Committee), and omits the fact that he was under investigation for misconduct.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2795
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual Output omits details about the net profit range and the improvements in the company's main business, but it does not contradict the Expected Output. The length is shorter without substantial loss of factual accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2803
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了调整日期和调整目的，但缺少了具体的信用卡持有数量上限，且比预期输出多了不必要的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2814
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes additional details not aligned with the expected output, introducing unnecessary information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2806
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含关键信息但使用了'不超'而非'不超过'，略显模糊。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2811
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及融资细节和投资者退出难的问题，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2808
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了关于补贴政策的具体提及，但整体意思没有偏差且简短精炼。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2799
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出缺少了对'腾讯下一步或减持'这一重要细节的描述，且来源从'彭博'变为'机构'，但并未引入事实性错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2804
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中未提及票价调整的具体数值和降价的原因，且与预期输出中的高票价吓退观众的信息不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2805
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了企业数量的信息，但缺少了旅游人数的预测，且未提及2021年的增长情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2797
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing a range of reduced net profit (4861万元到5861万元) instead of the positive range of 2000万-3000万元.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2816
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含具体楼号和建筑面积，而预期输出较为简洁，未提及具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2807
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中提到腾讯关联公司入股北京心域科技并成为大股东，但未明确持股比例52.98%，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2812
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output in terms of the vaccine dose description, missing the simplified '超30亿剂次' summary.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2815
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了制定碳达峰行动方案和推动大宗货物运输向铁路转移的重要信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2823
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about multiple routes and the potential long-term impact on the trade market.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2821
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的净利润同比增长率与输入信息不匹配，且没有明确指出扭亏为盈的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2822
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes unrelated details about ship crew activities and omits the key information about expected launch frequency.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2802
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出中的重要事实不符，实际输出称收益率曲线出现负值差，而预期输出称收益率曲线达到最平坦，并提到交易员考虑3月升息50基点的可能性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2825
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少发起设立者的信息，只提及了持股比例，而预期输出强调了发起设立者。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2817
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键信息，但比预期输出详细，提供了具体的日期和年会主题，因此略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2819
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出缺少关键人物'邓晓峰'和公司'高毅资产'的信息，导致标题不够准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2813
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了额外的累计确诊数字，但遗漏了新增死亡病例和正在接受治疗的患者数量，不符合预期输出的简洁要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2828
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，且遗漏了预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2824
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出几乎一致，仅缺少一个中文标点符号，不影响核心信息传达。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2820
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中包含了风暴警报的信息，但包含了额外的风暴详情，导致比预期输出长，且略去了停电和航班取消的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2826
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出缺少了'开年'和'或将持续下行'这两个重要细节，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2818
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出的内容不符，实际输出的内容偏离了新闻的核心信息，没有提及美国将中国实体列入未验证清单的具体事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2810
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预期输出的关键信息，但略去了部分细节，例如鉴定评审的具体机构和创新性、实用性等描述。实际输出比预期输出更简洁，但可能略显信息不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2838
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中缺少了'继续减持'这一重要细节，这使得整体准确性有所下降。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2830
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output omits key details from the expected output and introduces a fact about revenue growth which was not the focus of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2831
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及氢能被列入重点攻关专题这一重要信息，并且没有提到最高资助金额，遗漏了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2837
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对美联储加息和市场情绪的具体描述，且未提及历史性反弹昙花一现的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2835
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details like CFO's name and specific weekly orders, and the year 2022 is not mentioned.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2836
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output omits details about company's cash flow being充裕, which is present in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2834
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含大部分重要细节，但添加了具体的地点'宁明县'和处理措施，导致信息略显冗余。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2832
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未完全涵盖预期输出中的关键点，如盈利创纪录和无耻抬高物价的描述，且语气较为温和。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2839
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the duration of the visit, the delegation accompanying the president, and the planned meetings and speeches.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2849
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'年度'一词，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2852
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='缺少CEO的信息和扩产的具体描述，但未发现事实上的矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2851
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有明确提到审批决定不会在短期内做出，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2855
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about EB and other commodities mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2843
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出与预期输出仅有细微差别，即'超过420%'与'超过420%'的不同，不影响整体意思。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2846
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了美联储发言引发市场杀盘的重要信息，且未完全体现跌幅和对市场的具体影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2844
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出不符，遗漏了关键信息，如蒋卓庆的报告内容和浦东新区法规的制定。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2833
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="The actual output contradicts the expected output by changing '副总理' to '联邦副总理', and omits important details such as the context of the speech and the specific actions being advocated.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2841
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出虽然包含了公司获得三星级认证的信息，但与预期输出相比，额外包含了认证的具体类型和星级，导致信息量超出预期输出的要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2853
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出未包含预期输出中的缩写'文旅部'，导致信息略显冗长但未引入错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2840
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了一些重要细节，例如具体的发债规模和摩根士丹利的发债规模，以及高盛的发债规模在美国银行业的历史排名。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2850
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output includes key details but omits the 14-day self-health monitoring and reporting requirement mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2829
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了重要的事实信息，但增加了'滑板底盘公司'这个具体名称，而预期输出并未包含该名称，且实际输出使用了'亿元'而非预期的'亿'，导致细微差异。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2847
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the specific names of the locations and the actions taken by the involved individual, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2856
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as revenue, basic EPS, and specific date, while being less precise in phrasing.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2848
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by stating a decrease in the Baltic Dry Index this month, while expected output highlights a significant daily increase due to cape-sized vessel rates上涨。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2857
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了新闻中的关键细节，如中国联通美洲公司被美国政府以国家安全为由终止经营授权的具体事件，以及外交部的具体回应内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2842
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的核心信息，但额外提及了FB2001为注射用蛋白酶抑制剂，这虽然不是错误信息，但与预期输出相比略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2854
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到纳斯达克暂停了金融界的美国存托股票交易，但预期输出中提到纳斯达克退市，两者存在事实上的不一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2827
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the prediction that inflation will be above 2% for most of the year and the expectation that it will fall to around 2% by the end of the year if the pandemic is controlled, contradicting the expected output which highlights the prediction of inflation returning to 2% by year-end.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2858
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key information about the一季度将成为包括货币政策在内不少宏观政策的操作窗口 and contradicts the source being 中国金融时报 by not mentioning it.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2845
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes additional information about the education department's requirements, which is not present in the expected output, leading to extra details beyond what was asked for. However, it omits the timing detail '截至今日12时', reducing its accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2861
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出省略了病例的具体位置和新增境外输入无症状感染者的信息，且未明确病例数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2862
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes unnecessary location details which were not present in the expected output, but no contradictions or significant omissions are found.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2864
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了关键事实，但缺少了'创历史新高'这一重要信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2868
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含主要的增长率信息，但表述略有不同，未完全匹配预期输出中的具体词汇。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2870
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes specific information about the Canadian embassy, which was not mentioned in expected output, adding unnecessary details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2869
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了业务正在稳步推进的信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2865
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了预期输出之外的信息，且没有预期输出简洁，尽管包含了预期输出的关键点，但增加了不必要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2860
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出提供了具体的粮食总产量数字，但缺少了对产量增长的描述，未能体现预期输出中的'再创新高'这一关键信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2863
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output includes extra information about the automotive production and sales figures which are not in the expected output, and it is longer without adding substantial value.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2867
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提及拉加德关于逐步行动的承诺，也没有提到欧央行不需要大幅收紧货币，因此遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2871
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出省略了时间细节，如'去年'，导致信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2859
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了GDP同比增长的具体数值，并且使用了不精确的表达方式（5.39万亿元代替了精确的53850.79亿元），这使得信息不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2880
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了累计确诊病例和死亡人数，但忽略了新增确诊病例数这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2874
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了关于新型消费快速发展的信息，而预期输出没有提及这一点，同时缺少了消费重新成为经济增长第一拉动力的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2875
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits important details such as the international lunar research station and future planetary exploration projects mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2885
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出缺少了'大关'这个词，但没有引入事实错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2876
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output introduces a factual detail about the lead investor that was not present in the expected output, leading to an omission of the company name and other details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2866
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于合同额连续三年超过50亿美元的重要信息，且未提及完成营业额达到56亿美元创历史新高的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2872
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="Actual output omits '市' from '天津市', but does not contradict any facts in expected output. The omission is minor and does not significantly impact the accuracy of the information provided.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2878
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中缺少了预期输出中提到的'努力实现促投资和防风险的平衡'这一重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2877
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关于不良文化导向的具体内容，且只提到了部分导向问题，未能全面反映预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2883
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as total vaccination numbers and the fact that about one-third of the population has received the booster shot.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2873
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on the probability of加息 rather than the clear tendency towards加息 in the statement, and includes additional unrelated information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2882
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及20%以上的销售下滑，且未明确指出是白酒销售，重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2881
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出包含了不必要的来源信息'民生证券'，而预期输出没有提及具体来源，且实际输出省略了关于持仓占比等重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2886
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的主要信息，但略显冗长，未完全精简至预期输出的简洁形式。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2889
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about damaging market liquidity and the impact on relative values in the interest rate market, as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2890
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details about the lack of large machinery and the slow progress of the cleanup work mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2888
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了购买基金的持有期限信息，且未明确指出购买的是权益类基金。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2887
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出中缺少积极财政政策提前加码的关键信息，且未能充分反映护航经济行稳致远的含义。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2891
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了票房超过59亿和刷新单周票房纪录的信息，但缺少了春节档票房第二名的具体排名。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2895
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出省略了建议人的具体职位和对全省范围覆盖的描述，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2892
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the source '国家发改委' and the word '争取', which are present in the expected output, leading to less accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2884
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含拉皮德共同主持会议的信息，但预期输出中并未提及拉皮德。实际输出比预期输出提供了更多细节，但这些额外细节并非预期所需。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2900
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes details about the project location and type that are not present in the expected output, making it less concise.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2879
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于严守“两高”行业能耗煤耗只减不增底线和实行闭环管理的重要信息，仅提到了新增“两高”项目需提报窗口指导这一部分内容，导致信息不全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2894
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含股票代码NTES.O，缺少重要细节；长度与预期输出相比没有显著增加，但略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2898
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits '五大整车厂商' and '销量同比减', but does not introduce contradictions or unnecessary length.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2899
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了对能源危机的关键讨论，且未提及雅各布森的具体观点和量化加息建议，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2893
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的乐观展望和良性调整的表述，且未明确指出创新药产业可能出现的积极转变，仅概括了现状和行业趋势。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2901
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了服务对象的具体信息，即社保参保地为苏州市级的规模以上工业企业以及政府确定的其他重点企业。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2909
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the specific location '内蒙古满洲里' from the expected output, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2902
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含预期输出中的“2021年度净利润预增”这一重要细节，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2896
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了特定国债（德国、意大利和英国）下跌的具体信息，以及货币市场对加息押注的具体细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2897
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出虽然提及了奥密克戎毒株的传播情况，但遗漏了关键信息，即过去30天全球上传基因序列超过半数为奥密克戎的具体比例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2906
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出中提到的所有关键信息，但实际输出比预期输出多了一定的文字描述，虽然准确但略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2917
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出缺少了香港需要持续提升竞争力这一关键信息，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2914
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on market expectations rather than summarizing the policy signals from the central bank and analysts' forecasts.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2913
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中未包含累计确诊超过874万例的具体表述，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2915
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及白尾鹿这一关键物种，且未提到可能成为新毒株潜在来源的信息，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2905
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了新闻来源，即交通运输部，这使得信息不完整；同时实际输出比预期输出更为简洁，但遗漏了关键的信息来源。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2911
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output in terms of the year mentioned and omits key details about the anxiety of top brands and the emergence of star entrepreneurs.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2908
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output in key phrasing and details, omitting the focus on '锚定新年良好开局' and '稳增长举措蓄势待发'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2910
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='The actual output misses key details such as the ranking positions of other Chinese companies like Tencent, Alibaba, and Xiaomi, and the overall structure of the ranking by The Fortune magazine.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2904
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the critical detail about the 25-year-old auditor's sudden death, which is mentioned in the expected output. Additionally, the actual output is less specific about the context of the lawsuit.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2920
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output in terms of the growth rate and the total sales figure for the year.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2918
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中缺少了'一致行动人'的具体信息，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2922
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少恒生科技指数的跌幅信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2919
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by not mentioning the overall context of the meeting or the expected details about the survey and the specific topic of the conference.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2903
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中虽然提到了德国10年期国债收益率逼近2019年4月的顶部，但忽略了欧元区其他主权债收益率上涨的情况，且未提及普遍上涨及通胀超预期的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2926
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the average interest rate information provided in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2921
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key facts about the unexpected interest rate cut and the signal of easy monetary policy, focusing only on the economic growth forecast.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2924
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少重要细节，如已有3只可转债上市及专家对存量规模的预测。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2925
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the '中金公司' prefix, which is present in the expected output, leading to less accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2929
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by not mentioning the absence of new本土 cases.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2931
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了关于节后第一个交易日大概率高开的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2916
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有提到A股风格突变，且没有具体提到绩优基金经理加仓银行和地产两大低估值板块，存在重要信息的遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2927
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了额外的信息，如需求韧性和渠道改革的影响，但没有完全遵循预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2907
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by mentioning '泡泡玛特关联公司' instead of '泡泡玛特(09992.HK)成立商贸公司', and omits the crucial detail of the company being a newly formed entity on 1月19日.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2930
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by introducing unnecessary details about industry competition and future trends, while omitting crucial information about the current chip shortage.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2934
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了净利润同比增长的具体数值和非经常性损益的影响，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2928
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes unnecessary details from the input, such as the specific name '刘国强' and his position as deputy governor, which are not in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2932
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及每日盈利的具体数额，且未包含CCFI指数和货运量的增长情况，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2938
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出没有包含预期输出中的'首破4万亿元大关'和'外贸进出口'的关键细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2923
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出与预期输出相比，仅在评级用词上略有不同，将'维持买入评级'误写为'重申买入评级'，但并未改变核心意思，且未遗漏重要信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2944
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到两伊领导人之间的电话讨论，遗漏了预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2940
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出一致，但缺少了预期输出中的完整信息，如其他合约的价格变动详情。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2933
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了CEO的职位信息，但未引入事实错误；实际输出比预期输出短，但没有减少实质内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2936
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中遗漏了'全面战略合作协议'的具体名称，且简化了合作内容和目标，降低了准确性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2912
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="实际输出中提到电动车销量增长100%，但未完全体现期望输出中的'电动车销量即将起飞'这一积极趋势描述。同时，实际输出中提到产能可能成为限制，这与期望输出中的'受到产能掣肘'一致，但缺乏对供应短缺细节的描述。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2945
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中省略了'率先'这一重要细节，这使得信息传达不完全准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2935
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key details such as total box office revenue and market share increase, focusing only on a part of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2943
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了呼吁结束枪支暴力这一重要细节，并且与期望输出相比显得不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2947
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了预期输出的所有关键信息，但加入了不必要的组织名称'统计局'，使得内容略显冗长。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2951
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅有轻微措辞差异，未引入新的信息或错误，但略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2946
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extra details about net sells of specific companies which were not present in expected output, making it less concise.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2939
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到3月大幅加息的可能性存疑，且未强调美联储不会对经济踩急刹车，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2942
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出的内容不符，实际输出只提到了单日新增确诊病例数量，而未提及新冠检测阳性率和部分学校要求停课检测的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2937
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the key detail that the澳门特区民航局已恢复接受波音737MAX飞机的航班申请，但主要事实正确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2956
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了关于经常账户差额将保持在合理均衡区间的部分内容，降低了准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2948
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了私募机构的乐观态度，但缺少了关于市场调整可能已接近尾声和超过七成私募选择持股的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2954
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及小米长江产业基金作为新股东的具体信息，且表述为小米旗下公司，与期望输出存在细节上的不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2960
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output precisely without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2963
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2949
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，且缺少关键信息，如商务部部长王文涛和《求是》刊文的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2955
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但略显简化，缺少了一些细节，比如政府和专家的具体说法。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2959
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出不符，缺少关键信息如会议日期、地点以及会议的主要内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2952
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出虽然简短但提到了发起337调查的关键信息，但遗漏了申请是由美国企业发起这一重要细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2961
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details like planned measures and the intention to stabilize prices, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2950
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了埃克森美孚伊拉克有限公司这一重要合作方，同时合同金额表述为20亿元也与预期输出不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2962
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含治愈与死亡病例信息，且病例数字未使用概数表达，导致信息不全面且不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2957
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual Output contradicts Expected Output by mentioning the wrong variant (Delata instead of Omicron) and incorrectly stating no new cases for Omicron when it is about Delta variant cases.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2967
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在重要信息的遗漏，没有提到规范培训收费行为和推动校外教育培训监管立法这两点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2953
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the successful completion of the system对接 with CSDCC北京分公司 and the specific services provided for 北交所 and 新三板, while being less detailed than expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2972
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了试验进入最后阶段和全球首个使用专门船只运输液化氢气的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2969
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出中提到了加快重大项目建设，但缺少积极布局'新基建'项目的细节，与预期输出存在重要信息的缺失。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2965
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the specific name '紫鸾平台' mentioned in expected output, but does not introduce any factual errors or contradictions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2958
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键信息，但缺少了MLCC大厂的描述，且包含了超出预期输出的信息，如产能受影响的具体领域（车用、工控等高阶MLCC）。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2970
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output omits specific details from expected output, such as '美国将遏制中国影响力当成在联合国的主要任务和成绩'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2966
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific details about the expert's name and the role of the central bank, and includes information not aligned with the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2976
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output by focusing on new installations instead of the total capacity.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2973
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了总投资额约98亿元的关键信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2941
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as specific institutions involved, the adjustment in stock price, and the question about the future of the sector. Additionally, the expected output introduces new information not present in the input, such as冯柳的减仓和板块未来机会, which is not covered in the actual output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2964
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到德国四季度GDP萎缩接近技术性衰退的事实，且未提及德国复苏步伐不及其他欧洲国家，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2974
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了净利润的预期范围和同比增长率，但遗漏了营业收入的具体数值和同比增长率，以及内销和外销业务的增长情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2971
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the expression of gratitude from Musk and does not reflect the full context of his selection by NAE.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2968
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing solely on energy物资运输保障，which omits the core content about strengthening epidemic prevention and control during the Spring Festival travel rush as specified in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2983
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了净利增长的具体百分比范围，且与预期输出的百分比范围有细微差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2980
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中注册资本增加的比例表述为220%，而预期输出中为增加至约29亿，缺少具体金额信息，且比例表达不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2985
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the phrase '将推动' which is in expected output, but does not introduce any factual errors or contradictions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2975
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by focusing on a different aspect of the news summary and omitting key details such as the '十四五' trade performance and the challenges faced in 2022.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2981
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提到了精炼钴的产量数据，而未涵盖预期输出中提到的供需两旺格局和产品价格大幅上涨等关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2979
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了主要的公司名称，但省略了具体的公司名称和交割厂库的库容信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2977
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the specific sales expectation下调和物流挑战等重要信息，且与expected output在表达索尼前景的态度上有所差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2986
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了发行人信息披露的具体要求，但遗漏了上交所发布的通知目标和年份信息，导致整体内容不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2989
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了更多具体信息，如24英寸iMac和原始M1 iMac，但超出了预期输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2982
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了净利润的范围信息，但遗漏了净利润增长率的具体百分比范围，且增加了收入预测信息，这超出了预期输出的内容范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2991
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='Actual output omits the detail about over 15 million people being under extreme cold weather alerts, but does not contradict any key facts from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2987
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing a generalized statement about inventory reduction without mentioning specific metal inventories, and omits all important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2998
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中省略了'本土确诊病例'这一重要细节，导致信息不够准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2978
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='Actual output omits the specific net profit range of 2.1 to 2.3 billion yuan and the information about increased orders for large diameter single crystal silicon materials for etching machines, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2990
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了新闻来源和国家航天局的表述，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3000
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes unnecessary details about the investors, contradicting the concise nature of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2995
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits the critical detail about the current production capacity of 500,000 tests per day and only mentions the similarity to Nine Biotech's product.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2984
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出省略了策略师团队的具体建议和VIX指标的预测准确率，且没有提及触发信号后标普500指数的平均涨幅。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2992
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少重要细节，如同比多增4162亿元的信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2994
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了总体到发旅客数量和到达量的重要信息，仅提到了发送量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2996
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少预期输出中的关键细节，如规范非学科类校外培训和坚决抵制应试应考培训等行为的具体倡议内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2988
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出忽略了大类资产类ETF的表现和多个ETF的具体涨跌情况，只提到了公用事业ETF领涨，与预期输出相比信息量不足。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3002
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了产能紧张和客户催单的关键信息，未能反映春节期间金刚线企业的繁忙情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2993
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like GDP growth rate and breakdown of the GDP by sectors, while being significantly shorter than expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3006
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on a specific measure rather than the overall goal of reducing personnel movement in risk areas.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2999
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出相比，缺少了'新建'一词，但没有引入新的事实错误或显著增加冗余信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3003
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key detail of total net buy of 45.2 billion yuan and includes irrelevant information about Shenzhen Connect net sell.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3004
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits reference to the committee and does not specify it as the source of the information, making it less accurate compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3011
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有发现矛盾或遗漏重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3010
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未提及汽油库存减少，且未明确指出是API报告，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_2997
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出描述了高端冷轧汽车用钢的产销情况，而预期输出则侧重于短期国内钢价的预测。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3007
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了资产规模增长的具体百分比（49%），且未明确指出从2020年到2021年的大幅增长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3001
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by incorrectly naming the source as '荷兰国际集团' instead of '荷兰国际银行'. Also, important details from expected output, such as the potential impact on dollar pressure, were omitted.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3005
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了节前资金趋紧的重要信息，并且仅提到了节后的市场预期，未全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3017
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output includes unrelated details about production loss and omits key information about resuming production.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3015
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the increase in Amazon's market value and completely misses Meta's performance.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3014
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含现任总理科斯塔将获得连任的重要细节，且比预期输出更为简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3013
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键事实，但略去了建议避免前往的细节，且表述稍长于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3008
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了关键细节，如新的规则开始实施的具体日期和调整旅行限制的目的，且未完全反映预期输出中的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3009
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了高管回应的信息以及律师团队的准备情况，但比预期输出多了关于影响有限的细节，且长度更长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3018
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及特许生产商的准入门槛及资本加持情况，缺少关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3029
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks specific details from expected output and does not mention the strategic themes highlighted by Scotiabank analysts.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3016
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提及蔚来汽车的跌幅，忽略了小鹏汽车和其他新能源汽车股的跌幅信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3026
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by not addressing high rental costs and the possibility of buying the ship after three years of renting.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3023
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了时间、事件背景（冬奥会期间）和具体应用（手机POS应用试点）等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3025
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出缺少股票代码AAPL.O，但没有引入新的错误信息，主要内容一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3028
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the date and the fact that it is the fifth approved vaccine in France.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3020
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details about the patient's contact with and handling of the North American package, and the possibility of infection from exposure to contaminated items.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3021
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提及了对部分煤炭价格虚高企业的约谈提醒，但缺少了会议部署煤炭保供稳价工作的关键信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3012
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了新增数字人民币支付方式不会对收单业务规模和经营业绩产生重大影响这一关键信息，但缺少了控股子公司海科融通的具体名称，且比预期输出多描述了收入来源未改变的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3032
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the exact net profit range and slightly differs in growth percentage compared to expected output, but does not contradict any facts.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3022
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含预期输出中提及的关键利率信息和最快放款时间，且长度较预期输出更长，但未提供额外实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3039
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了额外的个人信息，但并未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3031
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了预期输出中关于认购户数最低不足700户的关键信息，且未能准确反映基民投资热情下降的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3024
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出一致，但实际输出包含了更多细节，如净利润增加的具体数额和主要矿产品产量的增长，这超出了预期输出的内容范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3019
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了中金的观点和南下资金流入港股提供缓冲空间的信息，但未提及2022年的具体年份，且表述为2022年有跑赢可能性的细节有所欠缺。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3034
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details such as the volcanic eruption causing a tsunami and the term 'international communication'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3036
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the nature of the violations and the legal actions taken, focusing only on the investigation and punishment.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3048
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关键细节，如分发的疫苗数量等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3027
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未提及法案的具体目标对象（如苹果和谷歌等应用商店），缺少重要细节；同时实际输出长度明显短于预期输出，未充分传达法案的相关信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3030
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中包含了'四个并存'的内容，但忽略了预期输出中提到的紧抓新赛道、新动能和持续招引重大产业项目的重要细节。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3033
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了联邦基金利率区间的信息，但遗漏了具体的加息时间点和鲍威尔的言论，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3037
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了苹果重回市场头把交椅的信息，但遗漏了5G手机发展的关键信息，且添加了与预期输出无关的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3042
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中没有涵盖预期输出中的关键细节，如通过市场化方式化解房企债务风险，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3040
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing on 2022 plans instead of summarizing the 2021 achievements.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3045
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了负债的划转及具体子公司数量的信息，且未提及账面净值等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3041
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出的内容严重不符且遗漏了关键信息，如新能源发电出力和能源安全稳定供应等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3038
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了所有项目名称，但缺少了总投资额的关键信息，且比预期输出长得多，没有增加实质价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3050
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中遗漏了基金经理所属机构景顺长城基金，降低了内容的准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3044
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits detailed net profit figures for the top three companies and fails to mention the industry differentiation observed, contradicting important details in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3047
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含二读审议的关键信息，略去了法案的具体审议阶段，但整体上没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3054
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少分期增资和最终股权比例的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3035
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output lacks specific detail about the negative results for both the controlled and managed zones, as mentioned in the expected output. It does not include the location detail '河北三河市'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3055
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了'局势能在控制之下'这一重要细节，降低了准确性。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3043
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output regarding the source (analyst vs. American Bank) and omits critical details about the increasing risk to the S&P 500 index.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3057
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits information about the shortage of medical personnel and resources in multiple public hospitals in Brazil.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3051
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the EU's confirmation of Spain's compliance with the recovery plan and the specific amount of funds received.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3046
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the detail that Buffett will personally host the event and does not specify the year of the event as 2022, which are key points in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3049
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出包含了关键信息，但比预期输出多了'生效'和'海关'等细节，虽然这些细节没有错误，但增加了输出长度。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3060
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output lacks key information about the growth rate of freight volume as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3052
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中包含了居民收入的具体数值，但忽略了增长与经济增长基本同步的关键信息，且未提及年份，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3053
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific sales growth details and does not mention the exact 700% increase in sales of the same brand's equipment as stated in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3058
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了对A股乐观情绪以及经济增长超预期的关键信息，且标题长度与期望输出相比有所欠缺。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3066
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中包含的信息与预期输出不匹配，且遗漏了预期输出中的核心政策举措内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3064
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了全球债券抛售导致日本国债收益率上升的重要信息，且没有提及通胀风险的具体证据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3071
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3068
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了Meta股票的具体跌幅和它对其他社交媒体股的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3056
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及RSI指标触及三年低点这一重要信息，且未明确表达纳斯达克100指数前景看涨的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3059
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中提到了房价涨幅创七个月新高，但没有提及生活成本压力上升这一重要信息，导致部分预期内容被忽略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3067
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了停电影响的家庭和企业的具体表述，且未提及气温警告。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3063
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对网络直播标准的完善和倡导理性健康的直播文化等重要细节，且与预期输出的主要焦点不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3061
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了累计确诊的数据，但遗漏了新增死亡病例和累计死亡数据，且与预期输出不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3070
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出包含了具体的街道名称和调整日期，但缺少了调整后的全市风险地区总数，与预期输出相比信息不够简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3079
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到15米高的海啸，遗漏了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3069
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了对'金融十条'的具体提及，且没有明确提到疫情防控期间到期的贷款延期或展期的政策，信息不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3065
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by omitting key details such as 'biden nominated' and 'vice chair', and also does not explicitly mention 'strong tool' to curb inflation.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3072
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出包含了累计确诊病例和累计死亡病例，但缺少了日增病例的信息，未能完全反映预期输出中的新增确诊病例超过百万的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3062
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了五粮液、招商银行、中国平安的净买入信息，但遗漏了三一重工净卖出的信息和招商银行的具体净买入金额，且长度与细节冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3080
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了不应有的细节，即拜登未准备好取消关税的信息，而预期输出仅需表达商务部的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3078
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了具体减持数量的关键细节，仅提及了百分比，而预期输出明确指出了减持350万张。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3076
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits some important details from the expected output but does not contradict any facts. The length is comparable and does not introduce vague language or contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3077
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于苹果2022财年Q1财报的预期收入和每股收益上调的信息，以及对财报积极内容的关注点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3086
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, with no contradictions, omitted details, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3075
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="Actual output contradicts expected output by mentioning Mitsubishi UFJ instead of economist Yuki Masujima and does not convey the key points about the balanced inflation risk and the central bank's stance.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3074
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中仅提到了铜的价格上涨，但忽略了锌、镍、铝、锡和铅的价格上涨，与预期输出相比，缺少了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3084
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了会议的内容和两个聚焦点，但忽略了重点发展社区养老托育服务等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3085
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits important details about the resumption of commercial activities and the specific measures for various businesses mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3089
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提供了疫苗接种剂次的信息，缺少老年人完成全程接种的具体人数，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3093
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output lacks specific mention of the survey and omits details about the trend during the pandemic.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3087
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了冷链从业人员的信息，且未明确提及阳性样本的具体数量和类型，与预期输出相比不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3083
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="Actual output includes all key details from expected output but adds '不超过971万股' which is not in expected output and slightly increases the length without adding substantial value.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3081
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出非常接近，只是将'俄罗斯'替换为'普京'，这略微改变了原意，但总体上仍传达了主要信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3082
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未完全涵盖预期输出中的重要细节，如客户亏损状态下不能提取超额业绩报酬的规定，且内容较为概括，未详细列出监管要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3100
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了吉电股份投资成立公司的信息，且表述不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3088
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了供需不平衡加剧的具体原因和分析，且未明确指出价格进入亏损区间的详细情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3094
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits specific areas of cooperation mentioned in expected output and is vague about the details of the signed documents.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3090
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Omits important details such as the percentage decrease and recovery rate compared to 2019.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3073
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes specific details such as '奄美大岛' and '27个航班停飞' which are aligned with the expected output, but it provides more specific information. However, it is slightly more detailed than necessary, which could be seen as adding unnecessary length.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3099
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the monetary value of the stolen Ethereum and the ongoing negotiations with the hacker, which are important details from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3096
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output lacks key details such as Minerd's name and the specific recommendation to reduce the balance sheet first, instead focusing only on reducing the money supply.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3095
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含黄楚平当选省人大常委会主任和王伟中当选省长的重要信息，导致关键事实缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3091
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了曹宇副主席的具体表述和综合运用监管手段的内容，仅提到了加强监管能力建设，与期望输出相比，缺少了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3097
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未包含克里姆林宫的回应这一重要信息，且其表述较预期输出更为个人化，缺乏官方回应的正式性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3102
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含'同类首创药物'这一重要信息，且未明确指出是在中国获批上市。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3092
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about expectations for the first rate hike since 2018 and the impact of investor concerns on gold prices, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3103
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了董承非正式告别兴证全球基金的重要信息，且未提及离职的具体公告。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3121
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3098
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在关键事实细节上不符，实际输出仅提到收益率接近顶部，而预期输出强调了收益率上涨和央行信号的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3107
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了净利润同比增长的范围，但未提及预计的具体净利润数额和市场需求旺盛的信息，略显简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3101
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific amount of 5.46 trillion yuan and the fact that the pressure on bank deposits is increasing, not just becoming harder.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3109
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output is concise and captures the key message but omits the year '2021' specified in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3106
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="实际输出缺少了对华润城作为'最强网红盘'的描述和'打新'盛况不再的信息，且没有提及润玺一期的相关背景。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3115
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，也没有遗漏重要细节，长度也相当。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3119
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少注册资本和法定代表人等重要信息，且未完全反映公司的全称。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3105
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出包含了增加的天然气量信息，但忽略了通过远东天然气管道运输的具体细节，且比预期输出更长，没有显著增加价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3122
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific减持数量和方式, and does not mention the exact percentage of shares reduced.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3112
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了净利润的具体金额范围和销量信息，仅包含了净利增长的百分比，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3120
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了地点杭州和疫情社会面风险已基本得到控制的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3118
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了深交所公开谴责的内容，且没有提及具体的补偿金额，遗漏了重要的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3113
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到陈宇庭管理的基金，而预期输出中没有提及；实际输出遗漏了具体日期和每位基金经理管理的产品数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3117
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分预期输出的细节，但遗漏了日期信息和无症状感染者的数据，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3110
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the座谈(h座谈t座谈会t) between the two company leaders and their discussion on global cooperation in the new energy field, leading to a less accurate summary.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3108
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output incorrectly mentions 2020 and The Fortune 500 instead of 2021 and the Hurun China 500 as indicated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3130
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了"日常"一词，但未引入新的事实错误或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3123
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="The actual output omits the specific location '石岩街道' mentioned in the expected output, leading to less accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3104
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及日本央行不会重新审视政策参数，但未包含预期输出中提到的‘鸽派阵营’和‘日元维持跌势’等重要信息，且风格和来源与预期输出不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3111
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits the fact that in 2021, the company supplied the main part of the ritonavir intermediate to Dishenao, and focuses only on the situation since January 2022.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3126
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output contradicts expected output as it does not mention any analysis from institutions or changes in interest rate bets.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3124
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了发展壮大市场主体的32条措施，但遗漏了推进数字广告、零售药店、医疗器械、化妆品等产业高质量发展政策落地见效的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3125
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on a different aspect of the content instead of detailing the push for upgrading traditional industries, which is the main point of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3129
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提及随迁子女就学工作，忽略了预期输出中的关键信息，如免试就近入学全覆盖和公民同招政策。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3114
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的净买入规模为750亿美元，而预期输出中提到的是4800亿元人民币，存在数值上的不一致；实际输出还遗漏了关于资本市场开放和改革的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3128
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes incorrect information about the absence of new cases, which contradicts the expected output and input.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3132
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了视频会议的关键信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3131
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output does not contradict expected output but omits the specific date range mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3116
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到39家公司发布了业绩预告，但预期输出中只提到30家公司预增，且实际输出遗漏了预盈2家、预降2家、预亏3家的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3127
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by not mentioning the contract with the government of Yutai County, Shandong Province, and instead focuses on the investment scale and product details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3138
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了新增封控区和管控区的具体位置及核酸检测范围的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3137
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关于公募基金管理规模被视为甜蜜负担的事实，以及行业普遍存在限购现象的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3133
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on biometric recognition instead of QR code payment usage ratio. It omits key details about QR code usage surpassing 90%.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3134
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the春运结束日期,疫情防控政策提醒等, while providing only basic information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3135
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出存在重要细节缺失，实际输出仅提及不再自建集租房和注销项目公司，而未强调公司不进入房地产行业的承诺。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3147
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output omits the detail about preventing capital's disorderly expansion in financial fields, reducing overall accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3145
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，且遗漏了推广绿色电力证书交易的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3136
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了重要细节，如60岁及以上人口的具体数量，仅提到了比例而未提供人数。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3142
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了年份和具体内容，虽符合原文大意但未完全遵循预期输出的格式要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3141
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by stating a definitive plan not to withdraw, while expected output only mentions no confirmation from the US State Department.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3148
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了票面利率5.3%的重要细节，且表述顺序和预期输出略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3143
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details about the real estate industry and instead focuses on financial risk management, contradicting the expected output which emphasizes housing market policies.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3139
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了关键信息，但使用了更详细的表述方式，如具体提及了证监会的批复文件名称，而预期输出则更为简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3146
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中提到的2022年底前完成供应商选择的重要信息，且未提及Apple Car项目。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3140
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extra details not present in expected output, but omits key information such as the public consultation feedback and the emphasis on privacy and use against illegal activities.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3149
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output mentions key points but omits critical details like the reversal of market gains and the specific impact of the Fed's hawkish stance.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3157
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'杭州市'这一重要细节，但没有引入事实错误或矛盾。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3150
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了拉美股市的总体涨幅，但遗漏了巴西股市的具体涨幅，且未提及新兴市场的整体表现对比，信息不全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3144
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the specific event being commemorated (尼克松访华暨《上海公报》签署50周年) and does not match the expected level of detail.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3152
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了预期输出中的关键细节，如硅料整体价格持稳微涨和供应相对紧缺现状持续的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3160
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, no contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3165
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了'美股并未达到危险区域'这一重要细节，导致信息不全面。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3164
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contains contradictory facts and omits important details from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3167
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出和预期输出完全一致，没有矛盾，没有遗漏重要细节，且长度相当。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3151
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key information such as the specific LPR rates, the adjustment sizes, and the implications for the real estate and实体经济市场。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3155
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出侧重于政策落地，而预期输出强调研究出台政策措施促进数字贸易等高质量发展。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3153
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了部分预期输出的信息，但遗漏了发改委出台10大举措的关键事实，且未能准确反映促进消费的政策背景。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3158
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about美方未表现出任何解决俄方关切的意愿and introduces vague language without full factual coverage.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3159
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了金属锂的具体涨幅信息，且未包含其他材料的具体涨幅，重要信息缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3154
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了新闻的具体人物'交通运输部部长李小鹏'，并且未完全表达出新闻中李小鹏的具体要求和指示。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3163
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key details such as the push from global central banks and the urgency to meet the original deadline, reducing accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3172
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含增资的具体金额，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3162
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about implementing specific防疫 measures for international and domestic mail from epidemic areas, as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3169
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific unemployment rate of 4.2%, which is a key detail in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3170
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了补充担保措施的信息，但缺少确保质押权人不会采取平仓手段的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3168
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了预期输出中关于中韩双方应加强联系的关键信息，仅提到了中国将实行更加积极主动的开放战略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3177
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少冬奥会和冬残奥会期间这一重要背景信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3175
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中没有包含'部分董监高'这一重要细节，导致信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3171
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中省略了投资者这个关键角色，且用词稍显模糊，未能完全反映预期输出中的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3161
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出中包含了八部门联合部署的内容，但缺少了'单位'一词，略去了'开展'的具体描述，导致与预期输出存在细微差异。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3166
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了北京新增病例的信息，但没有具体说明感染的工作人员数量，且预期输出中提到的具体感染人数信息在实际输出中缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3181
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了候选人数量和公示期等重要信息，且未提及入选人数。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3174
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含关键事实但略显冗长，未使用更简洁的表达如'累计确诊超304万例'。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3156
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出不符，实际输出侧重于描述供应链因素引发的长期通胀，而预期输出强调2022年央行所面临的复杂形势。实际输出缺少了预期输出中提到的关键信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3173
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了关于每年8000吨石墨供应量的重要信息，并且没有提及特斯拉关键电池原料的供应需求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3182
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the total consumption amount and the ranking of top countries.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3179
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅有用词上的细微差别，未发现事实性错误或重要信息的遗漏，长度也合适。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3180
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了同比涨幅回落和房价稳中有降的关键信息，仅反映了环比下降的趋势。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3193
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on different metals and providing different percentage declines.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3178
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中未提及新闻中关于中央会议审议通过意见的细节，且未明确提及制度落地进入倒计时的状态，导致信息不够完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3189
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出基本一致，仅在表述上有细微差异，无重要细节遗漏或矛盾。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3185
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了中国石化的前缀，与预期输出不同，且省略了地理位置四川和具体的生产目标。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3184
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details about the location and method of discovery of the cases, and does not accurately reflect the expected output's terminology.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3183
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的年度计划投资额为3640亿元，与期望输出中的3452亿元不符，引入了事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3195
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='缺少阿里文娱退出股东的关键信息，且未提及股份转让的具体比例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3187
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the specific risk management measures and the comprehensive nature of the discussions, focusing only on the issuance of a suggestion.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3190
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出内容不符，实际输出总结了新闻内容，而预期输出则是对消费者信心指数的具体预测值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3197
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少发射质量和发射成功率的信息，且未能准确反映发射次数和发射质量均创新高的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3176
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出与预期输出内容不符，实际输出侧重于'A股开门红难觅'，而预期输出强调'A股回撤'，且实际输出未提及私募、量化和理财的状态。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3188
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了预期输出中的重要细节，如加强充换电技术创新与标准支撑，推进新技术研发，推动统一换电标准等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3194
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the highest value in 8 months and the weekend curfew in many regions as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3199
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了全国市场主体突破1.5亿户的重要信息，仅提到了个体工商户的数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3186
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了部分细节，忽略了大部分重要信息，如规范报告工作、特别重大变化、法律调查、国际制裁及负面舆情影响等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3191
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the order growth and positive outlook for the semiconductor market in 2022, as mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3198
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出没有提到具体指控人数和可能的刑罚，遗漏了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3196
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少重要细节，如一月份共完成18.3亿元ABS到期兑付的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3192
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by not mentioning that习近平出席2022年世界经济论坛视频会议并发表演讲, instead it only summarizes part of the content without providing the context of the event.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3209
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits specific net profit range and revenue growth details mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3203
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了与新冠病毒共存的长期计划和控制病毒的概念，且表述不如预期输出准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3205
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了员工总数接近10万的重要信息，并且没有完全按照预期输出的格式生成标题。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3200
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='Actual output omits details about other aspects of the semiconductor industry but does not contradict expected output. The length is significantly shorter without major factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3204
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing an incomplete summary that does not include the specific increase in the SPDR Gold Trust holdings or the exact date.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3202
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing on集成电路and software policies instead of highlighting the implementation of policies related to fuel cell vehicles and the construction of hydrogen stations.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3206
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key information about creating a worry-free living environment for talents, which is a crucial part of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3213
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未完全包含预期输出中的关键信息，如世贸组织框架下的磋商，且信息量较少。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3208
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于暂停在中高风险地区招用工的重要信息，且与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3201
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output includes additional details about '九大攻坚' which were not present in the expected output, leading to an omission of key phrase '贵州茅台' from the beginning of the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3211
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出不符，缺少国家税务总局厦门市税务局的具体回应，且未提及以正式文件为准的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3214
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关键细节，如IPO募资同比增长的情况，且没有提及深市国企的整体表现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3217
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits crucial details about the product and its specific market, leading to less accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3216
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有出现事实上的矛盾，也没有遗漏重要细节，且长度相当。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3215
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含赤字率下行的信息，导致重要细节缺失；但并未出现与预期输出相矛盾的事实。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3219
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但缺少了增持股份的具体方式和时间范围等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3221
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了人民币升值至6.1的关键信息，且未提及美元指数的变化情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3218
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了专家的身份，但未引入事实错误；实际输出比预期输出短，但信息核心未变。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3225
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中包含了关键信息，但过于详尽，超出了预期输出的要求，因此略有冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3210
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出遗漏了多个重要细节，如热卷、螺纹期货、焦煤和动力煤的涨跌情况，仅包含铁矿石期货和焦炭的部分信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3231
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的猫年与预期输出中的虎年不一致，且实际输出缺少了海外市场大涨的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3207
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出没有包含预期输出的关键信息，如'高价倒卖'和'行政拘留'。虽然实际输出中包含查获了三人这一事实，但缺少了对高价倒卖和行政处罚的具体描述。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3229
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了预期输出的部分内容，但缺少了关于实施方案审议和推进的具体措施，内容过于简略。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3233
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预期输出的主要观点，但添加了额外信息，使其略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3220
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits specific details about the number of troops and the发言人柯比的引用，且未提及抵达人数为'几百人'。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3223
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits the key information about the first day of zero新增本土病例 and the current stage of the pandemic, making it less accurate.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3222
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output lacks the location '黑龙江绥芬河' and details about '生活保障物资无接触式配送', leading to omission of important details.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3232
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了可能导致第二次感染高峰的重要信息，并且没有提及BA.2亚种的传染性更强以及对免疫反应的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3212
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了Kazaks的名字和关于结束刺激计划的信息，而预期输出没有这些细节。此外，实际输出中提到的信息虽然部分符合预期，但增加了不必要的细节，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3230
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on different aspects of the news and omits important details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3237
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output lacks key details about the loan and payment process mentioned in the expected output, leading to less accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3234
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='Actual output matches expected output but includes additional details about the percentage changes, which were not omitted but not required according to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3235
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='缺少关键信息，如市长的具体职位和发言内容，且没有提及碳达峰专项行动的具体措施。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3224
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未包含长津湖系列电影总票房达到87.44亿元这一重要信息，且实际输出中的票房冠军描述与期望输出中的刷新纪录描述不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3227
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output in content and omits key details about the total fund size reaching a new high of 25.57 trillion yuan.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3226
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，虽然传达了北约对俄罗斯的言论不令人惊讶的信息，但忽略了预期输出中的关键内容，即俄罗斯正在尽一切努力让美国和北约履行国际义务。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3236
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了关键的跨境电商增长信息，但使用了'2021年'而非'去年'，导致与预期输出略有不同。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3241
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分关键信息，但遗漏了暂停业务的原因和背景，且长度明显短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3240
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about creating products and focusing on user needs, and does not mention '元宇宙' as in expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3239
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了玉米和小麦期货上涨的信息，但缺少了大豆期货的具体涨幅和南美干旱天气对收获量预期的影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3228
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预期输出的关键信息，但添加了更多具体领域，如反恶意炒作和反不正当竞争。虽然这增加了信息量，但并未直接影响到核心信息的准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3253
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了疫情拐点已经出现的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3243
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对AA级企业激励措施的具体信息，且未提及整体激励措施的背景，与预期输出相比信息不全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3242
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the specific price points and the 3x price increase mentioned in the expected output, focusing more on general factors like demand and cost.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3245
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the detail about increasing the housing fund loan额度 for three-child families and giving them priority in the disbursement, which is present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3247
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出未包含所有重要细节，例如未明确提及'网吧'和'KTV'，且表述略显模糊。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3255
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅有细微差别，对项目描述准确，未遗漏重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3246
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了积极发展产业数字金融这一重要信息，仅聚焦于个人金融服务数字化转型。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3254
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出缺少了'续签'这一重要细节，未能准确反映新闻的延续性合作协议。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3238
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含预期输出中的所有关键信息，但股票数量的描述略有不同，实际输出为6978.71万股，而预期输出为6978万股。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3256
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits important details such as '健全地方政府债务限额管理机制' from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3257
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'近年来'这一时间限定词，但并未引入事实错误或显著增加冗余。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3249
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了关于看跌情绪上升的重要细节，且摘要长度明显短于预期输出，未能全面反映原文内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3248
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及公司名称为美年大健康产业（集团）有限公司，且未明确指出该公司为美年健康的子公司，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3252
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits crucial details about the legal basis and necessity of the '安慰函'制度 in China, as highlighted in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3250
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了访问中国石化公司的信息，但未提及具体调研内容，且与预期输出的描述不完全吻合，缺乏关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3265
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the procurement method and the expected outcomes mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3266
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中包含了倡议使用的具体内容，但省略了运动员适用的全部项目，略显不够全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3244
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not providing the specific percentage increase or the potential record high, and omits key details such as the exact percentage rise in the Jakarta Composite Index and the potential for a record close.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3258
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出中提到了邢台矿西井项目的投产时间，但遗漏了焦煤价格变化的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3271
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中罚款金额不准确，且缺少责令停止违法行为的处罚决定。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3261
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '上证报头版' and 'A股估值合理偏低', leading to a less accurate summary.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3267
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了多余的累计确诊病例数，而预期输出中并未包括此信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3260
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及油价下跌和市场对伊朗核谈判的谨慎态度，忽略了原油期货的具体价格和跌幅等重要信息，与预期输出相比信息不全面。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3268
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了5人受伤的重要细节，且未提及枪手的身份为国民警卫队成员。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3251
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预期输出中的主要信息，但添加了更多细节。然而，它比预期输出更长，且包含了预期输出中未提及的内容，如清洁能源交通工具的具体类型，这可能导致信息冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3263
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了意大利国债持稳的重要细节，且没有提及德国和英国国债的情况，整体信息不准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3262
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了合同金额的具体数值，而预期输出并未提及该细节。实际输出略多于预期输出，但没有引入新的事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3272
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含预期输出中的多头宣称内容，且表述不够明确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3264
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like the specific unfairness mentioned by Guterres and the comparison between high-income countries and African nations regarding vaccine distribution.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3269
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output omits the detail that the工作组 was '第一时间' (immediately) dispatched, as mentioned in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3259
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the location '雄安新区' and the fact that it was completed ahead of schedule, making it less accurate compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3274
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了波兰赔偿4500万欧元的重要信息，且未提及具体的赔偿金额。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3280
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有提到兑付公开市场产品的细节，仅提及偿还债务，缺少重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3276
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了高管的姓名和坠亡原因，这些信息在预期输出中有明确提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3278
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了具体股票名称如贵州茅台等，且未明确提到前5名个股，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3281
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了在管总建筑面积的关键信息，且没有明确提到港交所聆讯这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3286
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有增加不必要的长度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3283
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the number of launches and the time period, leading to less accurate information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3291
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及封控措施和全员核酸筛查工作，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3285
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少预期输出中的关键信息，如市场面临重大风险及预期与现实可能性的差异。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3298
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3275
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes specific name '米利' which is not in expected output, but the core information matches. The inclusion of name does not introduce factual errors but adds unnecessary detail.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3273
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提到欧洲央行发出信号，今年不会加息，这与预期输出提到的央行决策者试图打消激进加息押注以及多国债券上扬的事实不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3284
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by focusing on fixed asset investment growth instead of industrial investment recovery speed, which is the key point in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3288
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了累计确诊数量这一重要信息，且未提及累计确诊人数超过1604万例。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3292
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及比特币不是通胀对冲工具，这与预期输出的重要细节不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3287
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未提及预期输出中的关键失业率数据，且未提及具体月份和下降幅度。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3270
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中包含了油价短期易涨难跌和有望冲破90美金的信息，但缺少了期望输出中的'涨势不休'和'挑战高点'等描述，因此略显不足。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3299
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3277
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the need to revise regulations based on market changes and the specific measures like prohibiting unlicensed exchanges. It is also shorter and less detailed than the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3279
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了部分信息但遗漏了关键细节，如国台办的回应和民进党当局的恐吓行为，且长度与预期输出相比过长，未能精简。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3293
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中没有提到高铁途经杭州没有影响的重要信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3296
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output lacks critical details such as the origin of the satellites, their specifications, and the specific launch location mentioned in expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3289
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中未包含完成评审的具体时间，且与预期输出的表述有细微差异，导致准确性略低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3294
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了加薪的具体人数和受影响的部门细节，且未明确指出加薪范围仅限于拜登能够掌控的联邦员工。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3282
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提供了具体的夜间消费额和同比增长，但与期望输出相比，期望输出只要求超过3790亿元，而实际输出给出了精确数值，因此存在冗余信息且未完全符合期望输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3297
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了重要细节，如年屠宰量150万头和南乐生鲜的投产信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3302
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the inconsistencies in the statements to investors and does not fully capture the findings of the special committee.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3304
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出中省略了'星火·链网'的具体地点佛山市，导致信息不够完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3295
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了部分重要细节，例如公司的数字虚拟人和数字资产库的相关信息，以及这些资产如何结合区块链技术进行加密和标识所有权。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3306
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的信息不够详细，缺少了证券时报的引用和具体的省份数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3290
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by stating OPEC+ will not provide comfort instead of agreeing on a 400,000 barrels per day increase as expected.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3305
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了航班取消的信息，但忽略了积雪对航班的影响，且具体取消航班数量不符，遗漏了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3300
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中包含了新闻的主要观点，但缺乏对久夛良木健的具体评价，即元宇宙与匿名留言板无异的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3311
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出没有包含预期输出中的基金名单，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3301
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the number of companies with pre-estimated profits and the number of companies expecting profit decreases or losses. It also introduces vague language that does not fully capture the content of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3303
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少关于法案针对谷歌广告技术业务的具体信息，且未提及犹他州共和党参议员迈克·李的角色。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3314
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="Actual output omits the word '所属' which is present in expected output, but does not introduce any factual errors or contradictions.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3316
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出缺少了关于累计发现69起家庭聚集疫情的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3323
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出仅在同比增长的表述上存在细微差别，不影响整体准确性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3318
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output uses '国家发改委、能源局' instead of '两部门', which is slightly less concise and does not add substantial value.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3325
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, no contradictions or omitted details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3317
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the detail about potential change in company control, which is mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3309
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只包含了中标东莞市沙田医院的项目，而没有提及预期输出中的其他两个项目，导致重要信息缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3320
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但预期输出中的净利增幅范围更精确，实际输出略显概括。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3321
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了同比增长10.7%的重要信息，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3312
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the part about cumulative deaths and patients under treatment, but does not contradict expected output. The length is appropriate and does not introduce vague language or contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3307
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了预制菜数据来源券商研报，但忽略了引起监管部门关注这一重要信息，且未反映上市公司试图将责任推给券商研报的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3308
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by mentioning '中证报' instead of '经济日报', and it does not accurately reflect the content related to '稳刚需'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3319
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出的数据略有差异，但未出现事实矛盾。实际输出略显简略，缺少了毛利率增加和产品价格上涨的具体信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3310
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出与预期输出相比，省略了'央行'这一重要细节，仅提到'央行副行长刘国强'，导致信息不完全。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3313
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提及岗位空缺总数，忽略了预期输出中强调的熟练技术人才缺口问题，且未提及缺口急剧扩大的情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3326
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了决议这一重要细节，且未明确指出是对华裔移民的道歉。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3334
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出省略了预期输出中关于毛利率和营业利益率的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3324
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing unrelated information about S&P 500 and NASDAQ indices instead of the required information about the Dow Jones Industrial Average.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3331
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含离职原因及过往经历等重要细节，但未发现与预期输出的矛盾之处。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3315
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the '两室一厅' mode and does not mention that the overall structure of 神龙汽车 will be retained, leading to less accuracy compared to the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3328
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as the fund size, the fund management company, and the total fund size context provided in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3337
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details about the number of locations adjusted, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3338
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the specific timing and details of the event, and introduces additional information not aligned with the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3329
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出相比缺少了来源（媒体）和对日本政府行为的具体描述（准备向欧洲转运LNG），但没有引入新的矛盾信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3332
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output includes correct new cases but omits death and recovery statistics, and uses exact numbers instead of the expected format '超416万例'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3342
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits revenue details and growth percentages, focusing only on net profit growth.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3330
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了纽约市员工回归的具体日期，且没有提及纽约州、新泽西州和康涅狄格州员工的回归日期要求，以及对于美国其他地区的计划。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3340
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中省略了货币政策宽松周期和降息降准空间的重要细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3327
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出中缺少了预期输出中的关键信息，如'3日内公募自购已超过15亿元'，并且没有提及公告的具体内容，包括持有时间不少于1年的承诺。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3349
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的银行名称与预期输出不同，且缺少关于加息的具体描述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3335
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出侧重于证券日报的评论，而预期输出则强调了业界对改革的热议和其对资本市场的作用。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3339
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits details about the '缺芯' issue and the plan to produce vehicle-grade chips, contradicting expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3322
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了预期输出的所有关键事实，但增加了不必要的细节，如“按可比口径恢复至2019年春节假日同期的71.5%”和“实现国内旅游收入1678.49亿元”，这些在预期输出中未提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3341
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details about the issuance of the technical specification by the National Health Commission and focuses only on the efficiency improvement aspect.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3343
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了追溯调整后的具体细节，且未明确指出同比增长基于追溯调整后的数据。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3348
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="实际输出与预期输出标题不符，缺少'时评'和'高质量发展'的关键信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3333
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键信息，如业内人士的观点和LPR下降的积极信号，且未提及“房住不炒”的改革基调。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3347
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键的货物吞吐量信息，但遗漏了集装箱吞吐量的增长情况，且表述与预期输出略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3345
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提供的数据与预期输出中的六万亿美元规模不匹配，且缺少了关于“十四五”外贸开局良好的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3344
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了病例的确切数字表达方式，使用了全数字而非科学记数法，且长度明显短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3355
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出省略了电力装机总量、各类能源的具体装机量以及持续保持全国最高的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3354
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了与前一日相比下跌3.25%的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3351
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于创新金融审判机制和支持保障国际金融中心核心区建设的重要信息，且与预期输出的内容不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3346
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了新冠病例激增和住院人数破纪录的具体描述，只提到了住院人数突破10万人，缺少重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3336
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出省略了对2022年A股市场的具体评价，仅强调了对国内权益市场长期看好的态度，与预期输出相比少了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3350
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只提到了一个高风险地区的调整，忽略了三个中风险地区的调整，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3353
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出没有包含预期输出中关于会议的具体提及，且未明确指出是结束债券购买计划，但没有出现事实性错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3359
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未提及购买的具体基金数量和名称，与预期输出的详细信息不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3352
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the key detail about inflation spiral concerns and does not mention the purpose of controlling inflation as stated in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3358
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含总理的姓名和新闻发布会的具体信息，略去了这些细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3366
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了创业板估值信息，而预期输出未提及，导致信息冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3363
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the detail about submitting account information to the authorities and ongoing investigation.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3357
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的净买入金额与预期输出存在细微差异，且遗漏了亿纬锂能、国电南瑞和药明康德的相关信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3372
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了更多细节，但遗漏了《冰雪奇缘》的具体信息，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3364
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了具体电商平台的不合格率信息，尤其是得物和快手的具体不合格率，且与预期输出中的具体不合格率数据不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3375
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output without contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3380
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了联合国等组织的反应，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3360
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by focusing on清洁能源建设投入力度 instead of mentioning the release of high-quality coal capacity and guiding market prices.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3356
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by providing incorrect information about the founding company and omitting key details such as the full name of the newly established company and the fact that it is a wholly-owned subsidiary of Ganfeng Lithium.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3370
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了合资公司的注册资本、业务领域和地理位置等重要信息，且未能准确反映合资公司的主要任务和行业布局。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3369
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific company involved (丰田通商) and the inclusion of large machinery, and incorrectly attributes the project to Toyota instead of Toyota Tomen.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3361
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了马斯克的具体言论和推特新功能的细节，如仅限于Twitter Blue订阅用户使用及仅支持iOS设备。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3378
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中没有包含董事和董事会秘书的详细职位，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3388
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='缺少关键细节，如未提及海淀阳性病例及国际邮件，且长度显著缩短。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3368
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the specific model year and the confirmation of AMD Ryzen chip installation, and is vague compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3362
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了浅绿色云团扩散到澳大利亚的信息，但预期输出强调的是火山灰的扩散方向。实际输出提供的信息虽然准确但包含了一些预期输出未提及的细节，导致信息与预期输出不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3365
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on a specific statement rather than summarizing the controversy about the 'North Stream 2' project and its implications on German energy supply.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3371
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key details about the missile launch and the number of launches this year, focusing only on the中方回应 part without capturing the full context of the event as specified in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3383
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有遗漏重要细节，也没有引入冗余信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3367
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='事实相互矛盾，实际输出强调了示范类设施补贴，而预期输出强调了财政支持和运营补贴标准。实际输出遗漏了关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3373
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了老人和工作人员的具体人数和全市384家养老机构已全部封闭管理的关键信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3385
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extra details about public services which were not present in expected output, introducing unnecessary information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3374
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the misuse of national power and unreasonable suppression of Chinese enterprises, as well as the specific term 'FCC' and the nature of the revoked authorization.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3384
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了对未来机器人业务可能比汽车业务更重要的预期，且未提及解决劳工短缺问题和在特斯拉工厂的应用。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3389
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少冬奥会的影响和热门目的地城市的具体信息，且未提及重庆在全国热门目的地和客源地的地位。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3390
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了一些预期输出未提及的信息，但同时也遗漏了预期输出中关于20%跌幅公司的数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3379
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出包含了净利润的具体范围和同比增长率，但未提及净利润同比增长的简化表达方式，且保留了更多原始信息，略显冗余。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3381
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了具体的日期和核酸检测频次调整的信息，但比预期输出更详细，尽管这些细节是准确的，但超出了预期输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3377
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning the key fact of the research conducted by易方达张坤、中欧基金葛兰等, focusing instead on a different aspect of the news.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3386
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the exact profit range (4.5亿元到5亿元) and slightly differs in the percentage range (124.97% vs 125%).', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3393
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出未包含增资金额这一重要信息，而预期输出明确提及增资9000万元。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3387
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the amount of the bid and the specific names of two hospitals, reducing its accuracy compared to the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3397
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了关键事实，但比预期输出更冗长，缺少简洁性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3376
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只提到了2000万元的自购计划，但未提及1月以来已自购的8000万元，也未说明总金额达到1亿元，以及持有期不少于一年的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3382
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分关键信息，如政策底的信号和关注年报业绩超预期个股，但忽略了保持耐心和定力、等待市场情绪修复等重要细节，且内容更为简略，偏离了预期输出的主要意图。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3391
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中包含了公司名称和融资金额，但遗漏了投资方和之前股东的信息。同时，实际输出比预期输出多了关于公司的技术背景内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3392
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on panel price stability rather than TV shipment growth and omitted the expected growth rate and shipment volume.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3403
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出遗漏了预期输出中关于加强放射性药品管理的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3395
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了要求接种加强针的内容，但遗漏了截止日期和健康测试的细节，且与预期输出相比不够详尽。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3400
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了植物油和奶制品价格飙升、食品价格逼近历史高点等重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3394
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出与预期输出在关键事实描述上有所差异，缺少了供需变局的信息。实际输出较预期输出更简洁，但信息不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3399
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了开发8.5代IT产品OLED面板产线的信息，但增加了苹果iPad订单的影响，这超出了预期输出的内容范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3396
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the range of predictions and the divergence in opinions about the pace and endpoint of the hikes, focusing narrowly on the existence of分歧.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3404
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the fact that the round of financing is completed, which is mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3410
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提及关于车船税优惠的内容，仅提到了技术要求的调整，缺少了预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3405
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like the date of the launch and the fact that SpaceX had attempted to mitigate the issue with a specific strategy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3411
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出与预期输出仅有细微差异，但未包含'解决'一词，这可能导致理解上的细微偏差。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3402
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the information about the company turning a profit from a previous loss and the exact figures from the non-recurring benefits, which are crucial details in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3401
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的克服困难和经济运行平稳的内容与期望输出中的价格上行和效益增长显著内容不符，且忽略了期望输出中重要的价格上行和效益增长显著的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3415
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about direct purchasing and specific response from Tencent, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3406
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了博威公司和国联万众的部分股权或全部股权的购买计划以及股票停牌的信息，且长度明显短于预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3408
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但实际输出省略了净利润的具体数额范围，且增长比例略有不同，导致信息不完全匹配。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3409
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了预期输出的所有关键信息，但额外提供了其他股票的卖出数据，这超出了预期输出的范围。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3398
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits details about the volatility and specific reactions of other indices like the Dow Jones and NASDAQ, and does not mention the exact context of the policy statement and inflation concerns as outlined in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3413
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关键细节，如未提及新增病例的具体数字和来源省份，且未提及国家卫健委的明确表述。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3412
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中只提到了会议召开，但未包含督促把好年报“披露关”“真实关”“质量关”的重要信息，导致重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3426
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分事实，但忽略了重要细节，如复飞的具体情况和背景信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3407
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出在表述上略有不同，实际输出提供了具体的数值范围，而预期输出使用了简化的百分比范围。实际输出没有引入事实错误，但比预期输出详细。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3418
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="实际输出中缺少了具体地点'河北省张家口'，并且没有提及奥运会期间的应用和奥运会后氢气的用途。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3417
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output does not contradict expected output but omits the comparison to the previous year's loss and the significant increase in loss.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3419
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了理想汽车1月交付量符合预期的关键信息，且未提及股票代码，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3420
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了快手的具体涨幅和恒生科技指数涨幅扩大的细节，且对阿里巴巴等公司的涨幅描述不够准确。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3414
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by using '收紧控制' which is more specific than '强化网络安全' and omits key details like '零信任' concept and 2024 fiscal year target.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3425
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了预期输出中的关键细节，如新增感染者的身份为奶茶店员工。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3423
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about becoming a leading production, research, and supply base, and does not mention the strategic projects or investment goals.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3421
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中忽略了第四季度的销售金额信息，且与预期输出的措辞略有不同，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3428
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出遗漏了猪肉产量增长和价格下降的重要信息，仅提到了生猪存栏数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3427
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中未提及国家发改委的指导工作，且措辞略有不同，导致信息不完全一致。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3424
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但累计确诊人数的具体数字不同，实际输出更精确，而预期输出使用了近似值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3434
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中忽略了广深地区额度充裕和部分重要细节，且房贷利率范围描述不全。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3432
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning the consecutive days of increase and the impact of other ship types.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3431
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关于连续四个月订单过亿的重要信息，且未提及半导体等电子材料行业的订单增长情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3422
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about new breakthroughs in domestic and foreign trade and the term 'good start' for the 14th Five-Year Plan's business development.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3416
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了资金流入的具体金额和时间细节，仅提到了避险情绪和ETF的资金净流入，没有提到16.3亿美元或100亿元人民币的具体流入金额以及1月21日的具体日期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3433
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extra details about production lines being full and normal operation, which were not present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3430
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出提到采取了临时管控措施，但未提及具体的混检信息，且缺少了对样本由疾控部门研判复核的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3435
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实上的矛盾，没有遗漏重要细节，长度也相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3436
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了GDP总量超过5万亿元的重要信息，仅提到了排名重回全国第7，与预期输出不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3429
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the involvement of a joint investigation team from the State Council and the specific handling of the issue, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3437
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有包含预期输出中关于制裁目标的具体信息，即任何与俄罗斯政权有关联的企业都将被制裁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3438
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了时间范围和病例的具体日期信息，仅提到了基因测序结果，而没有强调病例报告的时间集中性。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3441
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了具体的确诊病例数字，但未采用预期输出中的亿为单位的表达方式，略显冗长且不够简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3444
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了预期输出未提及的详细信息，但未提及预期输出中关键的应用于全球前五大手机终端品牌的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3449
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了合同金额但遗漏了项目具体内容，且比预期输出详细，但未完全遵循预期输出要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3457
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出省略了放款速度加快的重要信息，且专家评论部分缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3445
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'的'字，但并未改变原句意思，且未引入事实错误或冗余信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3448
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='遗漏了时间范围和部分公司名称的具体细节，且未提及更名原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3442
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="Actual output contradicts expected output by focusing on a different perspective and omitting key details like the '稳'字当头 and '进'字发力 from the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3439
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出包含了预期输出的关键信息，但将'今年'改为了'2022年'，增加了具体年份，虽然这并不影响核心信息，但并未完全遵循原文。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3454
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits details about the effectiveness of current vaccines against the Omicron variant, but does not introduce any factual errors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3446
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason="The actual output contradicts the expected output by stating 'short-term market has systematic risk' instead of 'part of the industries are at historical low valuation'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3459
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by mentioning multiple planning efforts instead of the specific '十四五' modern comprehensive transportation system development plan.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3440
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出和预期输出基本一致，但实际输出将'无症状感染者9例'合并为'无症状感染者9例'，略去了'新增本土'的描述，导致信息略显不完整。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3460
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少重要细节，如取消官微渠道发布的信息和具体核准企业的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3450
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details like the cause being the spread of the pandemic and specific dates of the停产, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3443
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了新闻的主要内容，但比预期输出多了一些细节，比如项目的启动时间、对中非合作的意义等，虽然这些细节增加了信息量，但并未明显偏离预期输出的核心内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3452
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出提到头部公募机构自购基金，但未提及市场韧性的增强和持续调整的可能性不大，与预期输出的关键信息不符。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3453
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits critical information about the termination risk and does not mention the potential for negative net assets, revenue below 100 million, and non-standard audit opinion, which are highlighted in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3464
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了发布机构和中美公司表现的重要细节，并且过于简略，无法全面反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3458
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出未提及具体的部长姓名和部门，缺少重要细节；但未引入事实错误或显著增加冗余信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3462
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中省略了净利润的具体范围和行业背景信息，导致内容不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3451
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits critical details such as the company not participating in the project's design, construction, or supervision, and the specific date of the contract signing. It also lacks the context of the accident being an '2·6' safety incident.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3447
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的沪指下跌1.4%，但未提及创指跌幅超过4%。实际输出中未提及旅游和餐饮板块的逆势走强，且重要细节如CRO概念股大跌也未在预期输出中出现。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3463
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到了154家公司被调研，但未提及芯能科技等48家公司获得20家以上机构调研这一重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3455
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了新闻中关于券商板块被称为“牛市旗手”的重要背景信息，以及资金流入的具体金额和公募基金增配的信息，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3466
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output includes extraneous details not present in expected output and omits the critical detail about赛后利用方案 for each venue.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3468
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key information about the demand and production status of the pesticide products, focusing only on raw material pricing factors.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3467
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出在内容上存在显著差异，实际输出省略了关于对话协商和中欧关系的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3471
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by not mentioning the title and main purpose of the document as specified in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3456
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中提到的21900例确诊病例与预期输出中的9200例新增病例存在矛盾，且实际输出中包含了额外的与预期输出无关的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3469
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含中科蓝讯和隆达股份首发获通过的关键信息，且长度上没有提供额外的价值。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3475
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="实际输出省略了'产业基金'这一重要信息，但没有引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3472
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含预期输出中的关键就业人数信息，且长度不匹配，导致准确性降低。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3465
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the fact that both non-academic and academic off-campus training should adhere to educational public welfare attributes and the firm action to curb excessively high fees and excessive profiteering.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3474
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中遗漏了东安汽发发动机销量同比下降18.73%这一重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3473
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits specific details such as the patent being published on February 8 and the interaction method between the wearable device and the vehicle, which are present in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3477
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='实际输出与预期输出完全一致，没有事实矛盾，没有遗漏重要细节，长度也完全相同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3480
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output contains factual information but omits details about the expected loss and the计提减值准备。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3479
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了阳性率下降这一细节，而预期输出则需要描述疫情趋缓和防疫措施的解除，实际输出遗漏了重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3461
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key information such as the involvement of subsidiary companies and the fact that the contract is for 2000万美元 (approximately 127 million RMB) split into two phases. It also does not specify that the initial order is 100万美元.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3490
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details about the drop in oil prices and expert opinions from the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3481
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contains specific figures and growth rates not mentioned in expected output, making it more detailed but also longer. Expected output is vague and omits key details.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3489
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly without omitting any important details or introducing contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3488
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出未包含悦己消费大潮这一重要细节，但未出现事实矛盾，且长度适当。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3470
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.4, reason='实际输出包含了部分重要信息，但缺少了军事演习这一关键细节，并且比预期输出多了一部分内容，如黑海舰队和太平洋舰队的汇合，这在预期输出中并未提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3484
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出与预期输出的主要事实一致，但用词略有不同且省略了部分细节，如能源成本上升和通胀预期调整的具体情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3492
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='Actual output omits the detail about pushing for mergers and acquisitions of two or more listed companies, following only part of the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3483
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出在增长率上略有差异，但未出现矛盾事实。实际输出略去了具体的利润范围，但并未明显影响核心信息传达。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3485
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了净利润的预期亏损范围，但增加了额外的信息，如扣非净利润的亏损范围和部分业务分析，这超出了预期输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3494
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details about the industry's potential and market conditions highlighted in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3482
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason="Actual output omits the contract value of 8.8 billion USD and the significance of the project for post-war Iraq's reconstruction, making it less accurate compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3491
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output omits the official statement source and the disinfection plan mentioned in the expected output, but there are no contradictions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3478
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中的跌幅数值与预期输出有差异，实际输出为1.9%，而输入中的跌幅为1.87%，此外，实际输出缺少了指数的具体数值1731点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3487
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未包含关键细节，如1500V电压系统和三电平技术，且比预期输出详细得多，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3497
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含中标产品Panama&T-train的信息，且对项目描述的范围有所缩减。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3486
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出包含了基金经理对于市场调整带来投资机会的观点和部分行业看好方向，但遗漏了增量资金规模和整体市场乐观预期的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3498
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出缺少了'年度'二字，但没有引入事实错误或矛盾，且长度差异不大。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3493
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the meeting being hosted by the Shanghai Municipal Government and the focus on strengthening the digital standard system.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3505
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出不符，遗漏了关于量子计量和先进测量体系建设的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3507
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了投资额和计划的量产时间细节，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3495
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason="Actual output includes correct pricing but omits the term 'retail guidance price', and is less detailed compared to expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3499
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details such as non-essential travel restrictions and necessary approval processes for leaving, reducing accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3503
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='包含主要事实但遗漏了地标位置（大湾区和深圳）和项目名称（深港国际中心），且语言表达不够精炼。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3496
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason="Actual output omits key details such as the source of the report and the specific date reference to 'last year', but it does convey the main point about the number of charity trusts and their property scale.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3476
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出包含了扩容升级的信息和千亿规模的预测，但提供了更多的具体细节，如建材和有色行业可能成为第二批纳入碳市场的行业，以及石化和化工行业相关企业的数量。虽然这些细节没有被期望输出要求，但它们增加了信息量，略微偏离了期望输出的简洁性要求。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3512
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出缺少了关于粉丝忠诚度可能下降的重要信息，且没有反映出资金流出对粉丝群体的潜在影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3502
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits specific details about multiple company recognitions and the types of products that received green design product certification.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3509
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出中缺少了每日新增死亡病例和累计死亡病例的数据，但总体上符合新闻摘要的要求，只是表述方式略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3504
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了一些输入中的信息，但遗漏了跌幅的具体数值和周跌幅等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3501
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出在表述上略有不同，但没有明显的事实性错误或重要细节遗漏。实际输出略显简洁，但没有引入新的矛盾或模糊语言。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3513
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了中签号码的数量和每个号码认购的股份数量，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3518
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, without any contradictions, omitted details, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3508
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the cause of the interruption (explosion) and the daily output volume, making it less accurate compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3519
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing unrelated details instead of the required information about the investment scale.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3514
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了教师和员工的核酸检测要求，但省略了返校后的核酸检测安排，且比预期输出多了一些细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3515
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output contradicts expected output by providing a different conclusion and omitting the key point that the spring market trend is just delayed and will not be absent.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3516
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中没有提到春季躁动是布局机会，且未提及市场调整的信息，遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3511
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出遗漏了关于上海需要夺得先机的重要信息，且未完全涵盖期望输出中的所有关键点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3520
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits critical details about the arrest and contradicts the expected output regarding the final disposition of the case.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3506
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及短端美债收益率的具体上涨情况，也未明确提到市场对美联储加息50个基点的预期升温，重要细节缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3522
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason="实际输出与预期输出基本一致，但缺少了'已'字，略显不准确。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3517
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但缺少了用于具体用途的信息，如生产基地建设、装备及技术设备更新改造和技术研发投入等。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3510
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='Actual output contradicts expected output by omitting key details such as the number of affected families, the number of cities declaring a state of emergency, and the impact on livestock.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3530
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中缺少了与昨日相比下降0.7%的重要信息，导致摘要不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3521
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the website article and the nature of the discrepancies, focusing only on the accusation of misinterpretation and fabrication.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3527
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及短期反弹的可能性，且并未强调策略师的观点，导致重要信息的缺失。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3526
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出与预期输出基本一致，但省略了归母净利的具体数额和增长原因，略显简洁。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3525
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出不符，提供信息不完整，且未提及计划两年内完成100个沉浸式体验剧场建设的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3531
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出包含了纳指的跌幅和创下的新低，但缺少了美股冲高回落的关键信息，且描述略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3500
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出和预期输出基本一致，但存在细微差距。实际输出为15.925亿元，而预期输出为15.93亿元。此外，实际输出包含了额外的信息，如计提资产减值准备和预计负债，这超出了预期输出的范围，因此略显冗长。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3529
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits important details such as the company's full name, registered capital, and legal representative. It fails to mention the specific business scope including battery sales.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3538
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出未提及暂停生产和销售的信息，且内容比预期输出更为简略，缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3524
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='Actual output omits key details about supporting the construction of a national important liquor base in the Guizhou Province and contradicts the expected output by focusing on a different aspect of the news.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3528
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少了合同项目名称英威达聚合物三期扩建项目，且未提及合同类型为设计-采购-模块化-施工(EPFC总承包项目)，信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3533
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output omits the detail that it is a joint project involving multiple institutions, as mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3535
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及冰墩墩和特许生产和销售企业受益的重要信息，且未反映预期输出中的券商点评。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3534
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出缺少关于基金规模的重要细节，且长度较短，未能全面反映预期输出的内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3523
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing on expert opinions and speculation rather than summarizing the news content about SPAC in HK market. It omits key details such as the advantages and statistics of SPAC in the US market.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3537
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了地点浙江温州，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3540
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了关于补贴政策延续至2025年的具体建议，且与预期输出相比信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3544
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output regarding the source of the comment and the main conclusion.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3536
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output contradicts expected output by focusing only on REITs tax policy and omitting critical details such as supporting REITs pilot programs.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3542
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了对2023年油价预期上调和触及100美元可能性上升的重要信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3541
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the specific date and the fact that it was due to the reduction of the middle-risk area, leading to less accuracy compared to expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3549
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了收入增长的关键信息，且没有提及增长的具体百分比。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3543
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了来源机构和对信息的明确否定，且未提及网传内容的具体性质。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3532
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少招商银行具体净买入金额的重要信息，且长度显著短于预期输出，未包括中国平安和平安银行的净买入情况以及药明康德的净卖出情况。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3539
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出包含了部分重要信息但遗漏了隆基股份的净卖出情况，且净买入的金额有微小误差。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3551
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits important details such as the specific violations and disciplinary actions mentioned in the expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3557
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Omits the location of the volcanic eruption and the time when the tsunami waves were detected, leading to less accurate information.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3545
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出忽略了预期输出中关于针对城区常住人口100万以下的中小城市组织实施云网强基行动的重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3552
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as '需求预期转弱' and '仓单注销压力' from expected output, leading to less accurate summarization.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3550
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出忽略了瑞典议会呼吁政府提交新提案的重要信息，仅延长至3月31日的细节未提及。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3554
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出与预期输出相比，缺少了交易员押注加息的具体细节和分析来源，且表述过于模糊，未能准确反映新闻内容。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3547
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits the names of key parties and details about the agreement, and contradicts the expected output by failing to mention the full cooperation structure involving a参股公司.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3558
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason="Actual output omits information about the company's participation in the digital RMB pilot programs and is shorter than expected output, reducing accuracy.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3546
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出偏离了预期输出的核心信息，暗示CFA资质与长期投资表现无关，而预期输出则明确指出没有CFA资质的基金经理可能长期业绩更好。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3553
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by not mentioning the timeframe and recovery of the issue, and omits the phrase '行程码查询异常' which is crucial to understanding the problem.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3555
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出中缺少了硅基新材料的具体吨数和钴基新材料的具体吨数，但没有引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3548
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits key information such as the current normal operation of business and the explanation regarding job adjustments and hiring needs. It also adds unnecessary details about the salary and rest adjustment of frontline employees.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3559
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中缺少了美银预期今年加息7次的关键信息，且没有提及具体的加息次数或经济影响。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3566
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出省略了净利润的具体范围和精确百分比，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3560
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出中缺少了关于疫情对项目进展影响的信息，且未明确指出是国产大飞机C919。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3570
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.6, reason='实际输出缺少了关于合资公司业务范围的关键信息，即新能源汽车热管理业务。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3564
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='Actual output omits key detail about 92% of SMEs perceiving tax burden reduction, significantly deviating from expected output.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3561
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中缺少了投资额的具体金额，而预期输出明确指出了投资额约为9.6亿元，这使得实际输出在准确性上有所欠缺。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3562
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及2030年产15万辆的目标，且缺乏具体信息，与预期输出相比有重要细节遗漏。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3556
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes all key information from expected output but adds a space after 'RCEP的生效实施', which does not alter the meaning but slightly deviates from the expected format.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3572
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output precisely without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3571
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='实际输出未包含基金投资项目增加净利润的细节，且与预期输出的净利同比增长范围略有不同。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3567
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits key details such as the main goal of building a world-class salt lake industry base and the expected economic growth target for 2022.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3573
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="Actual output includes unnecessary details about the company's focus and services, which are not present in the expected output.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3575
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出未提及消费税传言的具体影响，且未明确指出传言导致板块下跌的原因。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3576
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='Actual output includes all key points from expected output but adds unnecessary details. No contradictions or omissions.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3563
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了俄法两国对欧洲局势有共同安全关切的信息，但忽略了普京与马克龙会谈的具体地点莫斯科，且省略了马克龙的重要发言，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3569
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中未提及特斯拉的声明称此改动不影响安全，且未明确指出这是中国产的Model 3和Model Y，导致信息不完整。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3580
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'周四纽约尾盘'这一重要细节，但未引入事实错误。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3579
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=1.0, reason='Actual output matches expected output exactly, without any contradictions, omissions, or unnecessary length.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3577
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出仅提到了PCCP业务毛利率低于同行业平均水平，但忽略了主营业务和毛利率的具体数值等重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3578
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出没有包含预期输出中的McMetaverse商标名称，且忽略了提交的具体商标名称这一重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3589
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，未提及未来基金主席Costello的观点。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3565
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='实际输出中提到陈荣炼被捕并涉及洗米华案，但提到他曾为太阳城案辩护，这与预期输出中的信息不符，并且实际输出中没有提及安以轩老公曾高调买入港股公司的信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3586
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='Actual output omits details about the 94 employees being查处and the highest reward for reporting corruption.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3574
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出只提到了CPI数据的预期涨幅，忽略了美联储可能加息50个基点的可能性和市场对此的预期，缺少了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3584
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='实际输出与预期输出内容不符，实际输出总结了企业总数，而预期输出强调了去年平均每月成立的游戏相关企业数量。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3587
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了公司成立的信息，但遗漏了化妆品批发的经营范围，且未提及投资成立的细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3592
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason="实际输出省略了'同比'这一重要细节，但没有引入事实错误或显著增加冗余信息。", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3582
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出仅提供了GDP总额和同比增长率，但遗漏了重要细节，如广东连续33年位居全国第一等关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3568
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output by focusing on Grantham's views rather than Spitznagel's detailed warnings about market risks. It also omits key details about Spitznagel's specific points regarding the lack of understanding of risks in both stock and debt markets.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3598
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.8, reason='实际输出省略了全资子公司这一重要细节，但未引入事实错误。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3595
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出未包含店员倡导限量购买的重要信息，且重点偏离了预期输出。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3583
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了非盟呼吁联合国改革，但没有具体提及非洲多国的具体要求，且忽略了外交官讨论的内容，因此遗漏了重要细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3588
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.7, reason='Actual output lacks the mention of the specific date and the role of the speaker, which are present in the expected output, leading to a slight deduction in accuracy.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3591
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.3, reason='Actual output omits the critical detail about the positive test result of the received package and does not mention that the building has been sealed off.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3581
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中包含了额外的信息，如美元走势的预期，而预期输出仅关注美联储加息计划的确认。实际输出比预期输出更长，且未完全涵盖预期输出中的关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3594
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output omits key details such as the call between Russian and French presidents and the discussion on Ukraine's situation, focusing only on Russia's response to the US and NATO.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3599
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.9, reason='实际输出与预期输出基本一致，但略去了一些细节，如辞职原因和生效日期。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3596
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.0, reason='The actual output contradicts the expected output by providing details about the trade value in RMB instead of the expected breakdown in USD and the milestone achieved.', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3585
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.1, reason='实际输出与预期输出内容不符，实际输出仅提到了中国经济成色更足底色更实，而预期输出强调了中国经济总量超过110万亿元且底气更足，实际输出缺少关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3593
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason="Actual output contradicts expected output in mentioning '预计2021年' instead of '去年', and omits the source of the statement as '香港财政司司长'.", strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3597
is success: False
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=False, score=0.2, reason='实际输出中未提及小鹏汽车和理想汽车纳入港股通的具体时间，且提供的信息不完整，忽略了预期输出中的关键细节。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

======================================================================
Test Case: test_case_3590
is success: True
metrics: [MetricData(name='Correctness (GEval)', threshold=0.5, success=True, score=0.5, reason='实际输出中包含了中塞是“铁杆朋友”的事实，但遗漏了武契奇关于塞中是钢铁友谊的评论。实际输出比预期输出更短，也少了一些关键信息。', strict_mode=False, evaluation_model='Custom vllm Server Model', error=None, evaluation_cost=None, verbose_logs='Criteria:\nNone \n \nEvaluation Steps:\n[\n    "Check whether the facts in \'actual output\' contradict any facts in \'expected output\'. If there is a contradiction, the output is incorrect.",\n    "Check if the \'actual output\' omits any important details from the \'expected output\'. If details are omitted, the output is less accurate.",\n    "Evaluate the length of the \'actual output\' compared to the \'expected output\'. If the \'actual output\' is significantly longer without adding substantial value, penalize the output.",\n    "Vague language or contradicting opinions are acceptable as long as they do not introduce factual errors."\n]')]

