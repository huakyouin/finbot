diff --git "a/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb" "b/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb"
index 2443519..ee70280 100644
--- "a/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb"
+++ "b/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb"
@@ -2,127 +2,225 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
-    "## 自造表达式引擎\n",
-    "## 参考：\n",
-    "## https://blog.csdn.net/itnerd/article/details/136041182\n",
-    "## https://zhuanlan.zhihu.com/p/679186652\n",
-    "## https://blog.csdn.net/weixin_38175458/article/details/139828021\n",
-    "import sys\n",
-    "sys.path.append(\"..\")\n",
-    "from utils.qlib_exp_engine import *\n",
-    "import re\n",
-    "import pandas as pd\n",
-    "\n",
-    "\n",
+    "## 数据集转换\n",
+    "import os\n",
+    "data_path = \"../data/cleaned/csi300_stock_feats.csv\"\n",
+    "if not os.path.exists(data_path):\n",
+    "    import qlib\n",
+    "    from qlib.data import D\n",
+    "    # 初始化 Qlib 的数据存储\n",
+    "    qlib.init(provider_uri = \"../data/raw/qlib_data/cn_data\")\n",
+    "    fields = ['$open', '$high', '$low', '$close', '$volume', '$amount', '$vwap']\n",
+    "    df = D.features(D.instruments(market='csi300'), fields, start_time='20160101', end_time='20201231', freq='day')\n",
+    "    df.to_csv(\"../data/cleaned/csi300_stock_feats.csv\")\n",
+    "    print(df)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 25,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "SH600005\n"
+     ]
+    }
+   ],
+   "source": [
+    "## 数据读取+特征转换\n",
+    "import polars as pl\n",
+    "from polars_ta.prefix.tdx import *\n",
+    "from polars_ta.prefix.wq import *\n",
     "\n",
-    "def parse_field(field):\n",
-    "    # Following patterns will be matched:\n",
-    "    # - $close -> Feature(\"close\")\n",
-    "    # - $close5 -> Feature(\"close5\")\n",
-    "    # - $open+$close -> Feature(\"open\")+Feature(\"close\")\n",
+    "OPEN, HIGH, LOW, CLOSE, VOLUME, AMOUNT, VWAP = [pl.col(col) for col in ['open', 'high', 'low', 'close', 'volume', 'amount', 'vwap']]\n",
     "\n",
-    "    if not isinstance(field, str):\n",
-    "        field = str(field)\n",
+    "def fast_linregress(x, y):\n",
+    "            x_mean = np.mean(x)\n",
+    "            y_mean = np.mean(y)\n",
+    "            slope = np.dot(x - x_mean, y - y_mean) / np.dot(x - x_mean, x - x_mean)\n",
+    "            intercept = y_mean - slope * x_mean\n",
+    "            y_pred = slope * x + intercept\n",
+    "            ss_total = np.sum((y - np.mean(y)) ** 2) + 1e-12\n",
+    "            ss_residual = np.sum((y - y_pred) ** 2)\n",
+    "            r2 = 1 - (ss_residual / ss_total)\n",
+    "            resd = np.sum(y - y_pred)\n",
+    "            return slope, intercept, r2, resd\n",
     "\n",
-    "    for pattern, new in [\n",
-    "        (rf\"\\$([\\w]+)\", r'Feature(\"\\1\")'),\n",
-    "    ]:  # Features  # Operators\n",
-    "        field = re.sub(pattern, new, field)\n",
-    "    return field\n",
+    "def func_ts_date(df: pl.DataFrame) -> pl.DataFrame:\n",
+    "    print(df['instrument'][0])\n",
+    "    df = df.sort(by=['datetime'])\n",
+    "    df = df.with_columns([\n",
+    "        ((CLOSE - OPEN) / OPEN).alias('KMID'),\n",
+    "        ((HIGH - LOW) / OPEN).alias(\"KLEN\"),\n",
+    "        ((CLOSE - OPEN) / (HIGH - LOW + 1e-12)).alias(\"KMID2\"),\n",
+    "        ((HIGH - max_(OPEN, CLOSE)) / OPEN).alias(\"KUP\"),\n",
+    "        ((HIGH - max_(OPEN, CLOSE)) / (HIGH - LOW + 1e-12)).alias(\"KUP2\"),\n",
+    "        ((min_(OPEN, CLOSE) - LOW) / OPEN).alias(\"KLOW\"),\n",
+    "        ((min_(OPEN, CLOSE) - LOW) / (HIGH - LOW + 1e-12)).alias(\"KLOW2\"),\n",
+    "        ((2 * CLOSE - HIGH - LOW) / OPEN).alias(\"KSFT\"),\n",
+    "        ((2 * CLOSE - HIGH - LOW) / (HIGH - LOW + 1e-12)).alias(\"KSFT2\"),\n",
+    "        *[(ts_delay(OPEN, i) / CLOSE).alias(f'OPEN{i}') for i in [0]],\n",
+    "        *[(ts_delay(HIGH, i) / CLOSE).alias(f'HIGH{i}') for i in [0]],\n",
+    "        *[(ts_delay(LOW, i) / CLOSE).alias(f'LOW{i}') for i in [0]],\n",
+    "        *[(ts_delay(VWAP, i) / CLOSE).alias(f'VWAP{i}') for i in [0]],\n",
+    "    ])\n",
+    "    for i in [5,10,20,30,60]:\n",
+    "        df = df.with_columns([\n",
+    "            (ts_delay(CLOSE, i) / CLOSE).alias(f'ROC{i}'),\n",
+    "            (ts_mean(CLOSE, i) / CLOSE).alias(f'MA{i}'),\n",
+    "            (CLOSE.rolling_std(i) / CLOSE).alias(f'STD{i}'),\n",
+    "            (CLOSE.rolling_max(i) / CLOSE).alias(f'MAX{i}'),\n",
+    "            (CLOSE.rolling_min(i) / CLOSE).alias(f'MIN{i}'),\n",
+    "            (CLOSE.rolling_quantile(0.8, interpolation='linear', window_size=i) / CLOSE).alias(f'QTLU{i}'),\n",
+    "            (CLOSE.rolling_quantile(0.2, interpolation='linear', window_size=i) / CLOSE).alias(f'QTLD{i}'),\n",
+    "            (ts_rank(CLOSE, i)).alias(f'RANK{i}'),\n",
+    "            (ts_RSV(HIGH, LOW, CLOSE, i)).alias(f'RSV{i}'),\n",
+    "            (1 - ts_arg_max(HIGH, i) / i).alias(f'IMAX{i}'),\n",
+    "            (1 - ts_arg_min(LOW, i) / i).alias(f'IMIN{i}'),\n",
+    "            (ts_corr(CLOSE, log1p(VOLUME), i)).alias(f'CORR{i}'),\n",
+    "            (ts_corr(CLOSE / ts_delay(CLOSE, 1), log1p(VOLUME / ts_delay(VOLUME, 1)), i)).alias(f'CORD{i}'),\n",
+    "            (ts_mean(CLOSE > ts_delay(CLOSE, 1), i)).alias(f'CNTP{i}'),\n",
+    "            (ts_mean(CLOSE < ts_delay(CLOSE, 1), i)).alias(f'CNTN{i}'),\n",
+    "            (ts_sum(max_(CLOSE - ts_delay(CLOSE, 1), 0), i) / (ts_sum(abs_(CLOSE - ts_delay(CLOSE, 1)), i) + 1e-12)).alias(f'SUMP{i}'),\n",
+    "            (ts_sum(max_(ts_delay(CLOSE, 1) - CLOSE, 0), i) / (ts_sum(abs_(CLOSE - ts_delay(CLOSE, 1)), i) + 1e-12)).alias(f'SUMN{i}'),\n",
+    "            (ts_mean(VOLUME, i) / (VOLUME + 1e-12)).alias(f'VMA{i}'),\n",
+    "            (VOLUME.rolling_std(i) / (VOLUME + 1e-12)).alias(f'VSTD{i}'),\n",
+    "            ((abs_(ts_returns(CLOSE, 1)) * VOLUME).rolling_std(i) / (ts_mean(abs_(ts_returns(CLOSE, 1)) * VOLUME, i) + 1e-12)).alias(f'WVMA{i}'),\n",
+    "            (ts_sum(max_(VOLUME - ts_delay(VOLUME, 1), 0), i) / (ts_sum(abs_(VOLUME - ts_delay(VOLUME, 1)), i) + 1e-12)).alias(f'VSUMP{i}'),\n",
+    "            (ts_sum(max_(ts_delay(VOLUME, 1) - VOLUME, 0), i) / (ts_sum(abs_(VOLUME - ts_delay(VOLUME, 1)), i) + 1e-12)).alias(f'VSUMN{i}')\n",
+    "        ])\n",
+    "        df = df.with_columns([\n",
+    "            (pl.col(f\"IMAX{i}\") -pl.col(f\"IMIN{i}\")).alias(f\"IMXD{i}\"),\n",
+    "            (pl.col(f\"CNTP{i}\") - pl.col(f\"CNTN{i}\")).alias(f'CNTD{i}'),\n",
+    "            (pl.col(f\"SUMP{i}\") - pl.col(f\"SUMN{i}\")).alias(f'SUMD{i}'),\n",
+    "            (pl.col(f\"VSUMP{i}\") - pl.col(f\"VSUMN{i}\")).alias(f'VSUMD{i}'),\n",
+    "        ])\n",
     "\n",
+    "        reg = [fast_linregress(x = np.arange(i), y = df[\"close\"][idx: idx + i].to_numpy()) for idx in range(len(df) - i + 1)]\n",
+    "        beta = [None] * (i - 1) + [item[0] for item in reg if item]\n",
+    "        rsqr = [None] * (i - 1) + [item[2] for item in reg if item]\n",
+    "        resi = [None] * (i - 1) + [item[3] for item in reg if item]\n",
+    "        row_n = len(df)\n",
+    "        df = df.with_columns([\n",
+    "            pl.Series(f'BETA{i}', beta[:row_n]),\n",
+    "            pl.Series(f'RSQR{i}', rsqr[:row_n]),\n",
+    "            pl.Series(f'RESI{i}', resi[:row_n]),\n",
+    "        ])\n",
+    "    return df\n",
     "\n",
-    "def compute_feature(df, exp):\n",
-    "    exp = eval(parse_field(exp))\n",
-    "    return exp.load(df, df.index[0], df.index[-1])\n",
+    "pldf = pl.read_csv(\"../data/cleaned/csi300_stock_feats.csv\")\n",
+    "# pldf = pldf.group_by('instrument').map_groups(func_ts_date)\n",
+    "# print(pldf)\n",
     "\n",
-    "def compute_features(df, exps, labels):\n",
-    "    data = dict()\n",
-    "    for label, exp in zip(labels, exps):\n",
-    "        # print(label,exp)\n",
-    "        data[label] = compute_feature(df, exp)\n",
-    "    if len(data) > 1:\n",
-    "        return pd.concat(data, axis=1)\n",
-    "    else:\n",
-    "        return pd.DataFrame(data)"
+    "pldf = func_ts_date(pldf.filter(pl.col('instrument') == 'SH600005'))"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 29,
    "metadata": {},
    "outputs": [],
    "source": [
-    "import qlib\n",
-    "import pandas as pd\n",
-    "from qlib.contrib.data.handler import Alpha158\n",
-    "from qlib.data.dataset.handler import DataHandlerLP\n",
-    "from qlib.data.dataset.loader import StaticDataLoader, QlibDataLoader, DLWParser\n",
-    "from qlib.data.dataset import DatasetH\n",
-    "\n",
-    "## 特征与标签配置\n",
-    "feature_config = Alpha158.parse_config_to_fields(dict(price={\"windows\": [0],\"feature\": [\"OPEN\", \"HIGH\", \"LOW\", \"VWAP\"]},rolling={},kbar={}))\n",
-    "label_config = ([\"Ref($close, -1)/$close-1\"],['LABEL0']) \n",
-    "\n",
-    "\n",
-    "## 加载数据\n",
-    "# qlib.init(provider_uri = \"../data/raw/qlib_data/cn_data\")\n",
-    "# dl = QlibDataLoader(config = {\"feature\":feature_config, \"label\":label_config})\n",
-    "df = pd.read_csv('../data/cleaned/csi300_stock_feats.csv', index_col=[\"datetime\"])\n",
-    "instruments = df.groupby(by='instrument')\n",
-    "# for name, instrument in instruments:\n",
-    "#     print(name)\n",
-    "#     df2=compute_features(instrument, *feature_config)\n",
-    "df = df.loc[df['instrument'] == 'SH600005']\n",
-    "df2=compute_features(df, *feature_config)"
+    "df = pldf.to_pandas()\n",
+    "df.set_index(['instrument', 'datetime'], inplace=True)\n",
+    "features = df[[col for col in df.columns if col.isupper()]]\n",
+    "labels = df[['close']]"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 38,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "[834910:MainThread](2024-11-10 10:42:32,581) INFO - qlib.timer - [log.py:127] - Time cost: 0.010s | Loading data Done\n",
+      "[834910:MainThread](2024-11-10 10:42:32,584) INFO - qlib.timer - [log.py:127] - Time cost: 0.000s | fit & process data Done\n",
+      "[834910:MainThread](2024-11-10 10:42:32,587) INFO - qlib.timer - [log.py:127] - Time cost: 0.016s | Init data Done\n"
+     ]
+    }
+   ],
    "source": [
-    "df = compute_features(df, *label_config)\n",
-    "dl = StaticDataLoader(config=df)\n",
+    "## 数据装载\n",
+    "from qlib.data.dataset.loader import StaticDataLoader\n",
+    "from qlib.data.dataset.handler import DataHandlerLP\n",
+    "from qlib.data.dataset import DatasetH\n",
     "\n",
+    "## 创建数据加载器\n",
+    "dl = StaticDataLoader(config=dict(feature=features,label=labels))\n",
     "## 创建数据处理器\n",
-    "dh = DataHandlerLP(\n",
-    "    instruments='csi300', \n",
-    "    start_time='20160101', \n",
-    "    end_time='20191231',\n",
-    "    data_loader=dl\n",
-    ")\n",
-    "\n",
+    "dh = DataHandlerLP(data_loader=dl)\n",
     "## 创建数据集\n",
     "ds = DatasetH(handler=dh,segments={\"train\": ('20160101', '20171231'), \"valid\": ('20170101', '20181231'),\"test\": ('20180101', '20191231')})"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "test = instruments.get_group('SH600000')\n",
-    "print(compute_features(test, *feature_config))"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 2,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "[834910:MainThread](2024-11-10 10:04:23,026) INFO - qlib.Initialization - [config.py:416] - default_conf: client.\n",
+      "[834910:MainThread](2024-11-10 10:04:23,033) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
+      "[834910:MainThread](2024-11-10 10:04:23,036) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/mnt/disk1/JXH/02_workspace/毕设_量化智能助手/data/raw/qlib_data/cn_data')}\n",
+      "[834910:MainThread](2024-11-10 10:04:37,027) INFO - qlib.timer - [log.py:127] - Time cost: 13.988s | Loading data Done\n",
+      "[834910:MainThread](2024-11-10 10:04:37,034) INFO - qlib.timer - [log.py:127] - Time cost: 0.000s | fit & process data Done\n",
+      "[834910:MainThread](2024-11-10 10:04:37,036) INFO - qlib.timer - [log.py:127] - Time cost: 13.998s | Init data Done\n"
+     ]
+    }
+   ],
    "source": [
-    "dl.load(instruments=\"csi300\")"
+    "# import qlib\n",
+    "# import pandas as pd\n",
+    "# from qlib.contrib.data.handler import Alpha158\n",
+    "# from qlib.data.dataset.handler import DataHandlerLP\n",
+    "# from qlib.data.dataset.loader import StaticDataLoader, QlibDataLoader, DLWParser\n",
+    "# from qlib.data.dataset import DatasetH\n",
+    "\n",
+    "## 特征与标签配置\n",
+    "# feature_config = Alpha158.parse_config_to_fields(dict(price={\"windows\": [0],\"feature\": [\"OPEN\", \"HIGH\", \"LOW\", \"VWAP\"]},rolling={},kbar={}))\n",
+    "# label_config = ([\"Ref($close, -1)/$close-1\"],['LABEL0']) \n",
+    "\n",
+    "## 加载数据\n",
+    "# qlib.init(provider_uri = \"../data/raw/qlib_data/cn_data\")\n",
+    "# dl = QlibDataLoader(config = {\"feature\":feature_config, \"label\":label_config})\n",
+    "# df = pd.read_csv('../data/cleaned/csi300_stock_feats.csv', index_col=[\"datetime\"])\n",
+    "# instruments = df.groupby(by='instrument')\n",
+    "# for name, instrument in instruments:\n",
+    "#     print(name)\n",
+    "#     df2=compute_features(instrument, *feature_config)\n",
+    "# df = df.loc[df['instrument'] == 'SH600005']\n",
+    "# df2=compute_features(df, *feature_config)\n",
+    "# df = compute_features(df, *label_config)\n",
+    "# dl = StaticDataLoader(config=df)\n",
+    "\n",
+    "## 创建数据处理器\n",
+    "# dh = DataHandlerLP(\n",
+    "#     instruments='csi300', \n",
+    "#     start_time='20160101', \n",
+    "#     end_time='20191231',\n",
+    "#     data_loader=dl\n",
+    "# )\n",
+    "\n",
+    "# ## 创建数据集\n",
+    "# ds = DatasetH(handler=dh,segments={\"train\": ('20160101', '20171231'), \"valid\": ('20170101', '20181231'),\"test\": ('20180101', '20191231')})"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 36,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -142,9 +240,32 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 37,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "[834910:MainThread](2024-11-10 10:42:22,031) INFO - qlib.workflow - [exp.py:258] - Experiment 3 starts running ...\n",
+      "[834910:MainThread](2024-11-10 10:42:22,056) INFO - qlib.workflow - [recorder.py:341] - Recorder 62644d9c8f1a4af6af89811efd238155 starts running under Experiment 3 ...\n",
+      "[834910:MainThread](2024-11-10 10:42:22,360) INFO - qlib.timer - [log.py:127] - Time cost: 0.003s | waiting `async_log` Done\n"
+     ]
+    },
+    {
+     "ename": "ValueError",
+     "evalue": "Empty data from dataset, please check your dataset config.",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m R\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m R\u001b[38;5;241m.\u001b[39mstart(uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[0;32m/mnt/disk1/JXH/01_apps/miniforge3/envs/finbot/lib/python3.8/site-packages/qlib/contrib/model/gbdt.py:69\u001b[0m, in \u001b[0;36mLGBModel.fit\u001b[0;34m(self, dataset, num_boost_round, early_stopping_rounds, verbose_eval, evals_result, reweighter, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     evals_result \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# in case of unsafety of Python default values\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m ds_l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreweighter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m ds, names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mds_l))\n\u001b[1;32m     71\u001b[0m early_stopping_callback \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mearly_stopping(\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds \u001b[38;5;28;01mif\u001b[39;00m early_stopping_rounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m early_stopping_rounds\n\u001b[1;32m     73\u001b[0m )\n",
+      "File \u001b[0;32m/mnt/disk1/JXH/01_apps/miniforge3/envs/finbot/lib/python3.8/site-packages/qlib/contrib/model/gbdt.py:39\u001b[0m, in \u001b[0;36mLGBModel._prepare_data\u001b[0;34m(self, dataset, reweighter)\u001b[0m\n\u001b[1;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mprepare(key, col_set\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m], data_key\u001b[38;5;241m=\u001b[39mDataHandlerLP\u001b[38;5;241m.\u001b[39mDK_L)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty data from dataset, please check your dataset config.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m x, y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Lightgbm need 1D array as its label\u001b[39;00m\n",
+      "\u001b[0;31mValueError\u001b[0m: Empty data from dataset, please check your dataset config."
+     ]
+    }
+   ],
    "source": [
     "# 训练模型\n",
     "from qlib.workflow import R\n",
