diff --git "a/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb" "b/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb"
index 2443519..7dde29d 100644
--- "a/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb"
+++ "b/train/\350\202\241\344\273\267\351\242\204\346\265\213.ipynb"
@@ -2,82 +2,128 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
-    "## 自造表达式引擎\n",
-    "## 参考：\n",
-    "## https://blog.csdn.net/itnerd/article/details/136041182\n",
-    "## https://zhuanlan.zhihu.com/p/679186652\n",
-    "## https://blog.csdn.net/weixin_38175458/article/details/139828021\n",
-    "import sys\n",
-    "sys.path.append(\"..\")\n",
-    "from utils.qlib_exp_engine import *\n",
-    "import re\n",
-    "import pandas as pd\n",
-    "\n",
-    "\n",
+    "## 数据集转换\n",
+    "import os\n",
+    "data_path = \"../data/cleaned/csi300_stock_feats.csv\"\n",
+    "if not os.path.exists(data_path):\n",
+    "    import qlib\n",
+    "    from qlib.data import D\n",
+    "    # 初始化 Qlib 的数据存储\n",
+    "    qlib.init(provider_uri = \"../data/raw/qlib_data/cn_data\")\n",
+    "    fields = ['$open', '$high', '$low', '$close', '$volume', '$amount', '$vwap']\n",
+    "    df = D.features(D.instruments(market='csi300'), fields, start_time='20160101', end_time='20201231', freq='day')\n",
+    "    df.to_csv(\"../data/cleaned/csi300_stock_feats.csv\")\n",
+    "    print(df)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "## 数据读取+特征转换\n",
+    "import polars as pl\n",
+    "from polars_ta.prefix.tdx import *\n",
+    "from polars_ta.prefix.wq import *\n",
     "\n",
-    "def parse_field(field):\n",
-    "    # Following patterns will be matched:\n",
-    "    # - $close -> Feature(\"close\")\n",
-    "    # - $close5 -> Feature(\"close5\")\n",
-    "    # - $open+$close -> Feature(\"open\")+Feature(\"close\")\n",
+    "OPEN, HIGH, LOW, CLOSE, VOLUME, AMOUNT, VWAP = [pl.col(col) for col in ['open', 'high', 'low', 'close', 'volume', 'amount', 'vwap']]\n",
     "\n",
-    "    if not isinstance(field, str):\n",
-    "        field = str(field)\n",
+    "def fast_linregress(x, y):\n",
+    "            x_mean = np.mean(x)\n",
+    "            y_mean = np.mean(y)\n",
+    "            slope = np.dot(x - x_mean, y - y_mean) / np.dot(x - x_mean, x - x_mean)\n",
+    "            intercept = y_mean - slope * x_mean\n",
+    "            y_pred = slope * x + intercept\n",
+    "            ss_total = np.sum((y - np.mean(y)) ** 2) + 1e-12\n",
+    "            ss_residual = np.sum((y - y_pred) ** 2)\n",
+    "            r2 = 1 - (ss_residual / ss_total)\n",
+    "            resd = np.sum(y - y_pred)\n",
+    "            return slope, intercept, r2, resd\n",
     "\n",
-    "    for pattern, new in [\n",
-    "        (rf\"\\$([\\w]+)\", r'Feature(\"\\1\")'),\n",
-    "    ]:  # Features  # Operators\n",
-    "        field = re.sub(pattern, new, field)\n",
-    "    return field\n",
+    "def func_ts_date(df: pl.DataFrame) -> pl.DataFrame:\n",
+    "    print(df['instrument'][0])\n",
+    "    df = df.sort(by=['datetime'])\n",
+    "    df = df.with_columns([\n",
+    "        ((CLOSE - OPEN) / OPEN).alias('KMID'),\n",
+    "        ((HIGH - LOW) / OPEN).alias(\"KLEN\"),\n",
+    "        ((CLOSE - OPEN) / (HIGH - LOW + 1e-12)).alias(\"KMID2\"),\n",
+    "        ((HIGH - max_(OPEN, CLOSE)) / OPEN).alias(\"KUP\"),\n",
+    "        ((HIGH - max_(OPEN, CLOSE)) / (HIGH - LOW + 1e-12)).alias(\"KUP2\"),\n",
+    "        ((min_(OPEN, CLOSE) - LOW) / OPEN).alias(\"KLOW\"),\n",
+    "        ((min_(OPEN, CLOSE) - LOW) / (HIGH - LOW + 1e-12)).alias(\"KLOW2\"),\n",
+    "        ((2 * CLOSE - HIGH - LOW) / OPEN).alias(\"KSFT\"),\n",
+    "        ((2 * CLOSE - HIGH - LOW) / (HIGH - LOW + 1e-12)).alias(\"KSFT2\"),\n",
+    "        *[(ts_delay(OPEN, i) / CLOSE).alias(f'OPEN{i}') for i in [0]],\n",
+    "        *[(ts_delay(HIGH, i) / CLOSE).alias(f'HIGH{i}') for i in [0]],\n",
+    "        *[(ts_delay(LOW, i) / CLOSE).alias(f'LOW{i}') for i in [0]],\n",
+    "        *[(ts_delay(VWAP, i) / CLOSE).alias(f'VWAP{i}') for i in [0]],\n",
+    "    ])\n",
+    "    for i in [5,10,20,30,60]:\n",
+    "        df = df.with_columns([\n",
+    "            (ts_delay(CLOSE, i) / CLOSE).alias(f'ROC{i}'),\n",
+    "            (ts_mean(CLOSE, i) / CLOSE).alias(f'MA{i}'),\n",
+    "            (CLOSE.rolling_std(i) / CLOSE).alias(f'STD{i}'),\n",
+    "            (CLOSE.rolling_max(i) / CLOSE).alias(f'MAX{i}'),\n",
+    "            (CLOSE.rolling_min(i) / CLOSE).alias(f'MIN{i}'),\n",
+    "            (CLOSE.rolling_quantile(0.8, interpolation='linear', window_size=i) / CLOSE).alias(f'QTLU{i}'),\n",
+    "            (CLOSE.rolling_quantile(0.2, interpolation='linear', window_size=i) / CLOSE).alias(f'QTLD{i}'),\n",
+    "            (ts_rank(CLOSE, i)).alias(f'RANK{i}'),\n",
+    "            (ts_RSV(HIGH, LOW, CLOSE, i)).alias(f'RSV{i}'),\n",
+    "            (1 - ts_arg_max(HIGH, i) / i).alias(f'IMAX{i}'),\n",
+    "            (1 - ts_arg_min(LOW, i) / i).alias(f'IMIN{i}'),\n",
+    "            (ts_corr(CLOSE, log1p(VOLUME), i)).alias(f'CORR{i}'),\n",
+    "            (ts_corr(CLOSE / ts_delay(CLOSE, 1), log1p(VOLUME / ts_delay(VOLUME, 1)), i)).alias(f'CORD{i}'),\n",
+    "            (ts_mean(CLOSE > ts_delay(CLOSE, 1), i)).alias(f'CNTP{i}'),\n",
+    "            (ts_mean(CLOSE < ts_delay(CLOSE, 1), i)).alias(f'CNTN{i}'),\n",
+    "            (ts_sum(max_(CLOSE - ts_delay(CLOSE, 1), 0), i) / (ts_sum(abs_(CLOSE - ts_delay(CLOSE, 1)), i) + 1e-12)).alias(f'SUMP{i}'),\n",
+    "            (ts_sum(max_(ts_delay(CLOSE, 1) - CLOSE, 0), i) / (ts_sum(abs_(CLOSE - ts_delay(CLOSE, 1)), i) + 1e-12)).alias(f'SUMN{i}'),\n",
+    "            (ts_mean(VOLUME, i) / (VOLUME + 1e-12)).alias(f'VMA{i}'),\n",
+    "            (VOLUME.rolling_std(i) / (VOLUME + 1e-12)).alias(f'VSTD{i}'),\n",
+    "            ((abs_(ts_returns(CLOSE, 1)) * VOLUME).rolling_std(i) / (ts_mean(abs_(ts_returns(CLOSE, 1)) * VOLUME, i) + 1e-12)).alias(f'WVMA{i}'),\n",
+    "            (ts_sum(max_(VOLUME - ts_delay(VOLUME, 1), 0), i) / (ts_sum(abs_(VOLUME - ts_delay(VOLUME, 1)), i) + 1e-12)).alias(f'VSUMP{i}'),\n",
+    "            (ts_sum(max_(ts_delay(VOLUME, 1) - VOLUME, 0), i) / (ts_sum(abs_(VOLUME - ts_delay(VOLUME, 1)), i) + 1e-12)).alias(f'VSUMN{i}')\n",
+    "        ])\n",
+    "        df = df.with_columns([\n",
+    "            (pl.col(f\"IMAX{i}\") -pl.col(f\"IMIN{i}\")).alias(f\"IMXD{i}\"),\n",
+    "            (pl.col(f\"CNTP{i}\") - pl.col(f\"CNTN{i}\")).alias(f'CNTD{i}'),\n",
+    "            (pl.col(f\"SUMP{i}\") - pl.col(f\"SUMN{i}\")).alias(f'SUMD{i}'),\n",
+    "            (pl.col(f\"VSUMP{i}\") - pl.col(f\"VSUMN{i}\")).alias(f'VSUMD{i}'),\n",
+    "        ])\n",
     "\n",
+    "        reg = [fast_linregress(x = np.arange(i), y = df[\"close\"][idx: idx + i].to_numpy()) for idx in range(len(df) - i + 1)]\n",
+    "        beta = [None] * (i - 1) + [item[0] for item in reg if item]\n",
+    "        rsqr = [None] * (i - 1) + [item[2] for item in reg if item]\n",
+    "        resi = [None] * (i - 1) + [item[3] for item in reg if item]\n",
+    "        row_n = len(df)\n",
+    "        df = df.with_columns([\n",
+    "            pl.Series(f'BETA{i}', beta[:row_n]),\n",
+    "            pl.Series(f'RSQR{i}', rsqr[:row_n]),\n",
+    "            pl.Series(f'RESI{i}', resi[:row_n]),\n",
+    "        ])\n",
+    "    return df\n",
     "\n",
-    "def compute_feature(df, exp):\n",
-    "    exp = eval(parse_field(exp))\n",
-    "    return exp.load(df, df.index[0], df.index[-1])\n",
+    "pldf = pl.read_csv(\"../data/cleaned/csi300_stock_feats.csv\")\n",
+    "# pldf = pldf.group_by('instrument').map_groups(func_ts_date)\n",
+    "# print(pldf)\n",
     "\n",
-    "def compute_features(df, exps, labels):\n",
-    "    data = dict()\n",
-    "    for label, exp in zip(labels, exps):\n",
-    "        # print(label,exp)\n",
-    "        data[label] = compute_feature(df, exp)\n",
-    "    if len(data) > 1:\n",
-    "        return pd.concat(data, axis=1)\n",
-    "    else:\n",
-    "        return pd.DataFrame(data)"
+    "pldf = func_ts_date(pldf.filter(pl.col('instrument') == 'SH600009'))"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 44,
    "metadata": {},
    "outputs": [],
    "source": [
-    "import qlib\n",
-    "import pandas as pd\n",
-    "from qlib.contrib.data.handler import Alpha158\n",
-    "from qlib.data.dataset.handler import DataHandlerLP\n",
-    "from qlib.data.dataset.loader import StaticDataLoader, QlibDataLoader, DLWParser\n",
-    "from qlib.data.dataset import DatasetH\n",
-    "\n",
-    "## 特征与标签配置\n",
-    "feature_config = Alpha158.parse_config_to_fields(dict(price={\"windows\": [0],\"feature\": [\"OPEN\", \"HIGH\", \"LOW\", \"VWAP\"]},rolling={},kbar={}))\n",
-    "label_config = ([\"Ref($close, -1)/$close-1\"],['LABEL0']) \n",
-    "\n",
-    "\n",
-    "## 加载数据\n",
-    "# qlib.init(provider_uri = \"../data/raw/qlib_data/cn_data\")\n",
-    "# dl = QlibDataLoader(config = {\"feature\":feature_config, \"label\":label_config})\n",
-    "df = pd.read_csv('../data/cleaned/csi300_stock_feats.csv', index_col=[\"datetime\"])\n",
-    "instruments = df.groupby(by='instrument')\n",
-    "# for name, instrument in instruments:\n",
-    "#     print(name)\n",
-    "#     df2=compute_features(instrument, *feature_config)\n",
-    "df = df.loc[df['instrument'] == 'SH600005']\n",
-    "df2=compute_features(df, *feature_config)"
+    "df = pldf.to_pandas()\n",
+    "df.set_index(['instrument', 'datetime'], inplace=True)\n",
+    "features = df[[col for col in df.columns if col.isupper()]]\n",
+    "labels = df[['close']]"
    ]
   },
   {
@@ -86,19 +132,17 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "df = compute_features(df, *label_config)\n",
-    "dl = StaticDataLoader(config=df)\n",
+    "## 数据装载\n",
+    "from qlib.data.dataset.loader import StaticDataLoader\n",
+    "from qlib.data.dataset.handler import DataHandlerLP\n",
+    "from qlib.data.dataset import DatasetH\n",
     "\n",
+    "## 创建数据加载器\n",
+    "dl = StaticDataLoader(config=dict(feature=features,label=labels))\n",
     "## 创建数据处理器\n",
-    "dh = DataHandlerLP(\n",
-    "    instruments='csi300', \n",
-    "    start_time='20160101', \n",
-    "    end_time='20191231',\n",
-    "    data_loader=dl\n",
-    ")\n",
-    "\n",
+    "dh = DataHandlerLP(data_loader=dl)\n",
     "## 创建数据集\n",
-    "ds = DatasetH(handler=dh,segments={\"train\": ('20160101', '20171231'), \"valid\": ('20170101', '20181231'),\"test\": ('20180101', '20191231')})"
+    "ds = DatasetH(handler=dh, segments={\"train\": ('2016-01-01', '2016-12-31'), \"valid\": ('2017-01-01', '2018-12-31'),\"test\": ('2018-01-01', '2018-12-31')})"
    ]
   },
   {
@@ -107,8 +151,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "test = instruments.get_group('SH600000')\n",
-    "print(compute_features(test, *feature_config))"
+    "dl.load()"
    ]
   },
   {
@@ -117,14 +160,72 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "dl.load(instruments=\"csi300\")"
+    "ds.prepare(['train','valid','test'])"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 1,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "[838556:MainThread](2024-11-10 10:56:44,890) INFO - qlib.Initialization - [config.py:416] - default_conf: client.\n",
+      "[838556:MainThread](2024-11-10 10:56:45,456) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
+      "[838556:MainThread](2024-11-10 10:56:45,458) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/mnt/disk1/JXH/02_workspace/毕设_量化智能助手/data/raw/qlib_data/cn_data')}\n",
+      "[838556:MainThread](2024-11-10 10:57:02,953) INFO - qlib.timer - [log.py:127] - Time cost: 17.494s | Loading data Done\n",
+      "[838556:MainThread](2024-11-10 10:57:02,958) INFO - qlib.timer - [log.py:127] - Time cost: 0.000s | fit & process data Done\n",
+      "[838556:MainThread](2024-11-10 10:57:02,959) INFO - qlib.timer - [log.py:127] - Time cost: 17.500s | Init data Done\n"
+     ]
+    }
+   ],
+   "source": [
+    "import qlib\n",
+    "import pandas as pd\n",
+    "from qlib.contrib.data.handler import Alpha158\n",
+    "from qlib.data.dataset.handler import DataHandlerLP\n",
+    "from qlib.data.dataset.loader import StaticDataLoader, QlibDataLoader, DLWParser\n",
+    "from qlib.data.dataset import DatasetH\n",
+    "\n",
+    "## 特征与标签配置\n",
+    "feature_config = Alpha158.parse_config_to_fields(dict(price={\"windows\": [0],\"feature\": [\"OPEN\", \"HIGH\", \"LOW\", \"VWAP\"]},rolling={},kbar={}))\n",
+    "label_config = ([\"Ref($close, -1)/$close-1\"],['LABEL0']) \n",
+    "\n",
+    "## 加载数据\n",
+    "qlib.init(provider_uri = \"../data/raw/qlib_data/cn_data\")\n",
+    "dl = QlibDataLoader(config = {\"feature\":feature_config, \"label\":label_config})\n",
+    "# df = pd.read_csv('../data/cleaned/csi300_stock_feats.csv', index_col=[\"datetime\"])\n",
+    "# instruments = df.groupby(by='instrument')\n",
+    "# for name, instrument in instruments:\n",
+    "#     print(name)\n",
+    "#     df2=compute_features(instrument, *feature_config)\n",
+    "# df = df.loc[df['instrument'] == 'SH600005']\n",
+    "# df2=compute_features(df, *feature_config)\n",
+    "# df = compute_features(df, *label_config)\n",
+    "# dl = StaticDataLoader(config=df)\n",
+    "\n",
+    "## 创建数据处理器\n",
+    "dh = DataHandlerLP(instruments='csi300', data_loader=dl)\n",
+    "# ## 创建数据集\n",
+    "ds = DatasetH(handler=dh,segments={\"train\": ('20160101', '20161231'), \"valid\": ('20170101', '20171231'),\"test\": ('20180101', '20181231')})"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/mnt/disk1/JXH/01_apps/miniforge3/envs/finbot/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
+      "  from .autonotebook import tqdm as notebook_tqdm\n"
+     ]
+    }
+   ],
    "source": [
     "from qlib.contrib.model.gbdt import LGBModel\n",
     "model = LGBModel(\n",
@@ -168,7 +269,7 @@
     "strategy_obj = TopkDropoutStrategy(**STRATEGY_CONFIG)\n",
     "# 执行回测\n",
     "report_normal, positions_normal = backtest_daily(\n",
-    "    start_time=\"20210101\", end_time=\"20211231\", strategy=strategy_obj\n",
+    "    start_time=\"2018-01-01\", end_time=\"2018-12-31\", strategy=strategy_obj\n",
     ")\n",
     "# 分析回测结果\n",
     "analysis = dict()\n",
@@ -177,6 +278,15 @@
     "analysis_df = pd.concat(analysis)  # type: pd.DataFrame\n",
     "print(analysis_df)"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "df.index[:,'datetime']"
+   ]
   }
  ],
  "metadata": {
