{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/Maciel/FinCUGE-Instruction\n",
    "def custom_FinCUGE(from_dir, to_dir):\n",
    "    from datasets import load_dataset, concatenate_datasets\n",
    "    import os\n",
    "    dataset = load_dataset(from_dir)  \n",
    "    for split_name in dataset:\n",
    "        dataset[split_name] = dataset[split_name].map(lambda example: {\"split\": split_name})\n",
    "    combined_data = concatenate_datasets([dataset[split_name] for split_name in dataset])\n",
    "    os.makedirs(to_dir, exist_ok=True)\n",
    "    df = combined_data.to_pandas()\n",
    "    df.to_json(os.path.join(to_dir,\"FinCUGE.jsonl\"), orient='records',force_ascii=False, lines=True)\n",
    "\n",
    "def extract_finna_in_FinCUGE_as_sharegpt(from_dir, to_dir):\n",
    "    import pandas as pd  \n",
    "    import os\n",
    "    df = pd.read_json(f\"{from_dir}/FinCUGE.jsonl\", lines=True)\n",
    "    df['messages'] = df.apply(lambda row: [\n",
    "                                dict(role='system',content=row['instruction']),\n",
    "                                dict(role='user',content=row['input']),\n",
    "                                dict(role='assistant',content=row['output'])\n",
    "                            ], axis=1)\n",
    "    df[(df['split'] == 'train') & (df['task'] == 'FINNA')][['messages']].to_json(os.path.join(to_dir,\"FinCUGE_FINNA_train.jsonl\"), orient='records',force_ascii=False, lines=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
