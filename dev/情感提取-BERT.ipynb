{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.models import *\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLSDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        Args:\n",
    "            texts (list): 包含文本的列表\n",
    "            labels (list): 文本对应的标签列表\n",
    "            tokenizer (PreTrainedTokenizer): 分词器实例\n",
    "            max_length (int): 文本最大长度，超过此长度将会截断\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取数据样本，并将文本转为 BERT 可用的输入格式\n",
    "        Args:\n",
    "            idx (int): 索引值\n",
    "        Returns:\n",
    "            dict: 包含 `input_ids`, `attention_mask`, `labels` 的字典\n",
    "        \"\"\"\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 对文本进行编码\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # 获取编码结果并移除不必要的维度\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "df = pd.read_json(\"../data/cleaned/Dataset-of-financial-news-sentiment-classification.jsonl\", lines=True)\n",
    "train_df = df.query(\"split == 'train'\")\n",
    "train_ds = CLSDataset(\n",
    "    tokenizer = tokenizer,\n",
    "    texts = train_df['text'].to_list(),\n",
    "    labels = train_df['label'].to_list(),\n",
    "    max_length = 512,\n",
    ")\n",
    "\n",
    "train_size = int(0.7 * len(train_ds))  # 70% 的训练数据\n",
    "val_size = len(train_ds) - train_size   # 剩余的 30% 作为验证数据\n",
    "train_subset, val_subset = random_split(train_ds, [train_size, val_size]) \n",
    "\n",
    "batch_size = 16  # 设置批量大小\n",
    "train_dl = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.classifier.parameters(), lr=2e-5)  # 只更新分类头的参数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 开启训练\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "mpl.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题\n",
    "plt.figure(dpi=500)  # 设置图形的 DPI (每英寸点数)\n",
    "\n",
    "# 训练和评估模型\n",
    "train_losses = []  # 用于存储每个 epoch 的训练平均 loss\n",
    "val_losses = []    # 用于存储每个 epoch 的验证平均 loss\n",
    "train_accuracies = []  # 用于存储每个 epoch 的训练精确度\n",
    "val_accuracies = []    # 用于存储每个 epoch 的验证精确度\n",
    "\n",
    "# plt.ion()  # 开启交互模式\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_train_loss, train_accuracy = model.train(train_dl, criterion, optimizer)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    avg_val_loss, val_accuracy = model.eval(val_dl, criterion)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,3))\n",
    "    fig.subplots_adjust(hspace=0.3)  # 调整子图间隔\n",
    "    # 更新损失图\n",
    "    ax1.plot(train_losses, label='Training Loss', color='blue')\n",
    "    ax1.plot(val_losses, label='Validation Loss', color='orange')\n",
    "    ax1.set_xlim(0, epoch + 1)  # 动态调整 x 轴\n",
    "    ax1.set_ylim(0, max(max(train_losses), max(val_losses, default=0), 1e-10))  # 动态调整 y 轴\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "\n",
    "    # 更新准确度图\n",
    "    ax2.plot(train_accuracies, label='Training Accuracy', color='green')\n",
    "    ax2.plot(val_accuracies, label='Validation Accuracy', color='red')\n",
    "    ax2.set_xlim(0, epoch + 1)  # 动态调整 x 轴\n",
    "    ax2.set_ylim(0, 1)  # 精确度范围在 [0, 1]\n",
    "    ax2.legend(loc='lower right')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    \n",
    "    plt.pause(1e-9)  # 暂停以更新图形\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "          f\"Average Training Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Training Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Average Validation Loss: {avg_val_loss:.4f}, \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "save_dir = '../resources/ckpts/finbert'\n",
    "model.save(save_dir)\n",
    "# 保存训练指标\n",
    "metrics = dict(\n",
    "    base='finbert',\n",
    "    epochs=list(range(1, num_epochs + 1)),\n",
    "    train_losses=train_losses,\n",
    "    val_losses=val_losses,\n",
    "    train_accuracies=train_accuracies,\n",
    "    val_accuracies=val_accuracies\n",
    ")\n",
    "\n",
    "metrics_json_path = os.path.join(save_dir, 'training_metrics.json')\n",
    "with open(metrics_json_path, 'w') as json_file:\n",
    "    json.dump(metrics, json_file, ensure_ascii=True)\n",
    "print(f\"Training metrics saved to {metrics_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 推理\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.models import *\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_dir = \"../resources/open_models/FinBert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = BaseModel.from_name(\"bert_classifier\")(model_dir,2)\n",
    "\n",
    "ckpt_dir = '../resources/ckpts/finbert'\n",
    "model.load(ckpt_dir)\n",
    "\n",
    "seqs = [\"盛运环保2月13日晚间发布公告称，截至目前，共有37.48亿元到期债务未清偿。\", \"真好啊\"]\n",
    "input_tokens = tokenizer(seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "model.pred(input_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
